[{"content":"预测建筑物的能源消耗 ASHRAE（American Society of Heating, Refrigerating and Air-Conditioning Engineers），中文名称“美国采暖、制冷与空调工程师学会”，于1894年在美国纽约成立，是由暖通空调（HVAC）工程师所组成的学会，全球拥有超过54,000名成员。协会及其成员专注于建筑系统、能源效率、室内空气质量、制冷和行业内的可持续性。通过调研、标准编写、出版和继续教育，ASHRAE发展至现在的规模。\n问：夏天给大楼降温需要多少钱？\n答：非常多！政府正在进行投资，以降低能源成本，减少排放。但是问题是，这些改进是否真的有效？\n在这次竞赛中，我们通过预测冷水表、电表、热水表和蒸汽表的读数来对这些节能投资进行更好的估计。数据来自近三年来1000栋建筑中的各表读数。大型投资者和金融机构将更倾向于在这一领域投资，以提高建筑能源使用效率。\n我们将这个notebook分为不同的步骤，你可以使用下面的链接来浏览此notebook。\n Step 1: 导入数据 Step 2: 探索性数据分析 Step 3: 数据预处理 Step 4: LightGBM Step 5: 结果预测  在该项目中包含了如下的问题：\n 问题 1: 回顾课上内容并查阅资料，归纳总结数据预处理需要的步骤。 问题 2: 思考此处为何要进行对数转换。 问题 3: 查阅资料，总结LightGBM与CatBoost的差异。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #导入必要的库 import pandas as pd import numpy as np import os import gc import copy import warnings import lightgbm as lgb from lightgbm import LGBMRegressor from sklearn.metrics import mean_squared_log_error from sklearn.model_selection import StratifiedKFold, KFold from tqdm.notebook import tqdm import matplotlib.pyplot as plt import seaborn as sns warnings.filterwarnings(\u0026#39;ignore\u0026#39;) pd.set_option(\u0026#34;max_columns\u0026#34;, 500) %matplotlib inline   1. 导入数据 ASHRAE给出的数据包含大量的特征数据，包括仪表读数，天气和建筑的数据等等。该问题为典型的监督学习问题。比赛举办方提供了6个csv文件，包括5个数据集与1个提交样本。其中数据集的字段含义为：\n[train/test].csv\n building_id：建筑原数据的外键 meter : 仪表的id码, {0: 电表 , 1: 冷水表, 2: 蒸汽表, 3: 热水表}，不是每栋建筑都有全部类型的仪表 timestamp：读表的时间 meter_reading：目标变量, 用千瓦时（或等效值）表示的能耗。这是带有测量误差的真实数据，其中site0的电表读数出现问题，单位是千英热  building_meta.csv\n site_id: 天气文件的外键 building_id: training.csv对应的外键 primary_use: 基于EnergyStar property type definitions的建筑物活动的主要类别的指标（education, office…) square_feet: 建筑物的总建筑面积 year_built: 建筑完成的年份 floor_count: 建筑物层数  weather_[train/test].csv：气象站提供的气象数据,尽可能接近现场。\n site_id: 天气文件的外键 air_temperature: 气温，单位为摄氏度 cloud_coverage: 天空中被云层覆盖的部分，单位为oktas dew_temperature: 露点温度，单位为摄氏度 precip_depth_1_hr: 降水深度，单位为毫米 sea_level_pressure: 海平面压力，单位为毫巴/公顷 wind_direction: 风向，使用的是指南针方向（0-360） wind_speed: 风速，单位为米每秒  1 2 3 4 5  train = pd.read_csv(\u0026#34;../input/ashrae-energy-prediction/train.csv\u0026#34;, parse_dates=[\u0026#34;timestamp\u0026#34;]) test = pd.read_csv(\u0026#34;../input/ashrae-energy-prediction/test.csv\u0026#34;, parse_dates=[\u0026#34;timestamp\u0026#34;]) building = pd.read_csv(\u0026#39;../input/ashrae-energy-prediction/building_metadata.csv\u0026#39;) weather_train = pd.read_csv(\u0026#39;../input/ashrae-energy-prediction/weather_train.csv\u0026#39;, parse_dates=[\u0026#34;timestamp\u0026#34;]) weather_test = pd.read_csv(\u0026#34;../input/ashrae-energy-prediction/weather_test.csv\u0026#34;, parse_dates=[\u0026#34;timestamp\u0026#34;])   1 2 3 4  df = pd.DataFrame( weather_train[\u0026#39;site_id\u0026#39;].value_counts() ) df   2. 探索性数据分析  根据主办方提供的数据，\u0026ldquo;meter\u0026quot;代表仪表的类型，对应关系为 {0: 电表 , 1: 冷水表, 2: 蒸汽表, 3: 热水表} 观察各个建筑的仪表读数，可以发现，其中一些建筑的读数在某些区间出现了持续为0的异常情况,也有读数异常的高的值 可以通过修改site,meter_type,primary_use三个参数选择想要绘制的数据  关联train表格和building表格用于作图\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  train_plot = train.merge(building, on=\u0026#39;building_id\u0026#39;, how=\u0026#39;left\u0026#39;) site = 0 #建筑物的地点 meter_type = 1 #仪表的类型 primary_use = \u0026#39;Education\u0026#39; #建筑物的用途 r = int( np.ceil( len( train_plot[ (train_plot[\u0026#39;site_id\u0026#39;] == site) \u0026amp; (train_plot[\u0026#39;primary_use\u0026#39;] == primary_use) \u0026amp; (train_plot[\u0026#39;meter\u0026#39;] == meter_type) ][\u0026#39;building_id\u0026#39;].value_counts(dropna=False).index.to_list() ) / 2 ) )   1 2 3 4 5 6 7  s = enumerate( train_plot[ (train_plot[\u0026#39;site_id\u0026#39;] == site) \u0026amp; (train_plot[\u0026#39;primary_use\u0026#39;] == primary_use) \u0026amp; (train_plot[\u0026#39;meter\u0026#39;] == meter_type) ][\u0026#39;building_id\u0026#39;].value_counts(dropna=False).index.to_list() )   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  fig, axes = plt.subplots(r,2,figsize=(14, 36), dpi=100) for i, building_id in s: train_plot[ (train_plot[\u0026#39;site_id\u0026#39;] == site) \u0026amp; (train_plot[\u0026#39;primary_use\u0026#39;] == primary_use) \u0026amp; (train_plot[\u0026#39;meter\u0026#39;] == meter_type) \u0026amp; (train_plot[\u0026#39;building_id\u0026#39;] == building_id) ][ [\u0026#39;timestamp\u0026#39;, \u0026#39;meter_reading\u0026#39;] ].set_index(\u0026#39;timestamp\u0026#39;).resample(\u0026#39;H\u0026#39;).mean()[\u0026#39;meter_reading\u0026#39;].plot( ax=axes[i%r][i//r], alpha=0.8, label=\u0026#39;By hour\u0026#39;, color=\u0026#39;tab:blue\u0026#39; ).set_ylabel(\u0026#39;Mean meter reading\u0026#39;, fontsize=13); train_plot[ (train_plot[\u0026#39;site_id\u0026#39;] == site) \u0026amp; (train_plot[\u0026#39;primary_use\u0026#39;] == primary_use) \u0026amp; (train_plot[\u0026#39;meter\u0026#39;] == meter_type) \u0026amp; (train_plot[\u0026#39;building_id\u0026#39;] == building_id ) ][ [\u0026#39;timestamp\u0026#39;, \u0026#39;meter_reading\u0026#39;] ].set_index(\u0026#39;timestamp\u0026#39;).resample(\u0026#39;D\u0026#39;).mean()[\u0026#39;meter_reading\u0026#39;].plot( ax=axes[i%r][i//r], alpha=1, label=\u0026#39;By day\u0026#39;, color=\u0026#39;tab:orange\u0026#39; ).set_xlabel(\u0026#39;\u0026#39;); axes[i%r][i//r].legend(); axes[i%r][i//r].set_title(\u0026#39;building_id: \u0026#39; + str(building_id ), fontsize=13); plt.subplots_adjust(hspace=0.45) del train_plot,fig,axes,r gc.collect();   3. 数据预处理 问题 1: 回顾课上内容并查阅资料，归纳总结数据预处理需要的步骤。\n回答:\n3.1 数据类型转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def compress_dataframe(df): \u0026#39;\u0026#39;\u0026#39;将所有数据的类型都转换为数值型\u0026#39;\u0026#39;\u0026#39; result = df.copy() for col in result.columns: col_data = result[col] dn = col_data.dtype.name if dn == \u0026#34;object\u0026#34;: result[col] = pd.to_numeric(col_data.astype(\u0026#34;category\u0026#34;).cat.codes, downcast=\u0026#34;integer\u0026#34;) elif dn == \u0026#34;bool\u0026#34;: result[col] = col_data.astype(\u0026#34;int8\u0026#34;) elif dn.startswith(\u0026#34;int\u0026#34;) or (col_data.round() == col_data).all(): result[col] = pd.to_numeric(col_data, downcast=\u0026#34;integer\u0026#34;) else: result[col] = pd.to_numeric(col_data, downcast=\u0026#39;float\u0026#39;) return result   3.2 缺失值填充与特征扩展 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  def set_time(df): df.timestamp = (df.timestamp - pd.to_datetime(\u0026#34;2016-01-01\u0026#34;)).dt.total_seconds() // 3600 #这里将timestamp转换成了16年1月1日0点开始计算的小时数‘//’代表除法运算后取整 return df # 根据分析得出各个site来自哪个时区，来修正时间 # https://www.kaggle.com/patrick0302/locate-cities-according-weather-temperature site_GMT_offsets = [-5, 0, -7, -5, -8, 0, -5, -5, -5, -6, -7, -5, 0, -6, -5, -5] #转换天气数据表格中的时间,并填充缺失值 def weather_set_time(df,time_zone): df.timestamp = (df.timestamp - pd.to_datetime(\u0026#34;2016-01-01\u0026#34;)).dt.total_seconds() // 3600 GMT_offset_map = {site: offset for site, offset in enumerate(site_GMT_offsets)} df.timestamp = df.timestamp + df.site_id.map(GMT_offset_map) #根据时区的不同，统一时间 site_dfs = [] for site_id in df.site_id.unique(): # 确保包括所有可能的小时数 site_df = df[df.site_id == site_id].set_index(\u0026#34;timestamp\u0026#34;).reindex(time_zone) site_df.site_id = site_id for col in [c for c in site_df.columns if c != \u0026#34;site_id\u0026#34;]: site_df[f\u0026#34;had_{col}\u0026#34;] = ~site_df[col].isna() site_df[col] = site_df[col].interpolate(limit_direction=\u0026#39;both\u0026#39;, method=\u0026#39;linear\u0026#39;) # 这里使用中位数来填充缺失值 site_df[col] = site_df[col].fillna(df[col].median()) site_dfs.append(site_df) df = pd.concat(site_dfs).reset_index() # make timestamp back into a regular column for col in df.columns: if df[col].isna().any(): df[f\u0026#34;had_{col}\u0026#34;] = ~df[col].isna() #如果某列其中有缺失值，就增加一列新的特征：had_xxx 表示这一行在xxx这一列是否有记录 return df #增加星期，月份，时间的特征 def _add_time_features(X): return X.assign(tm_day_of_week=((X.timestamp // 24) % 7), tm_hour_of_day=(X.timestamp % 24)) building = compress_dataframe(building.fillna(-1)).set_index(\u0026#34;building_id\u0026#34;) train = compress_dataframe(set_time(train)) test = compress_dataframe(set_time(test)).set_index(\u0026#34;row_id\u0026#34;) weather_train = compress_dataframe(weather_set_time(weather_train,range(8784))).set_index([\u0026#34;site_id\u0026#34;, \u0026#34;timestamp\u0026#34;]) weather_test = compress_dataframe(weather_set_time(weather_test,range(8784,26304))).set_index([\u0026#34;site_id\u0026#34;, \u0026#34;timestamp\u0026#34;])   3.3 关联数据 1 2 3 4  def combined_data(df,weather): df = compress_dataframe(df.join(building, on=\u0026#34;building_id\u0026#34;).join(weather, on=[\u0026#34;site_id\u0026#34;, \u0026#34;timestamp\u0026#34;]).fillna(-1)) return df.drop(columns=[\u0026#34;meter_reading\u0026#34;]),df.meter_reading   3.4 异常值处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  def make_is_bad_zero(Xy_subset, min_interval=48, summer_start=3000, summer_end=7500): #夏天，3000/24=125，7500/24=312.5,第125天到第312.5天为夏天。 meter = Xy_subset.meter_id.iloc[0] is_zero = Xy_subset.meter_reading == 0 #返回读数为0的电表的indices if meter == 0: #电表的度数不应该为0，所以电表（meter为0）读数为0的行从training dataframe中drop掉 return is_zero transitions = (is_zero != is_zero.shift(1))#出现0和非0变化的位置 all_sequence_ids = transitions.cumsum()#到各位置出现的变化的和，是一个pd.Seires ids = all_sequence_ids[is_zero].rename(\u0026#34;ids\u0026#34;)#将其中读数为0的提取出来 if meter in [2, 3]: # 蒸汽和热水有可能在夏天被关闭 keep = set(ids[(Xy_subset.timestamp \u0026lt; summer_start) | (Xy_subset.timestamp \u0026gt; summer_end)].unique())#不在夏天的indices is_bad = ids.isin(keep) \u0026amp; (ids.map(ids.value_counts()) \u0026gt;= min_interval) #将不在夏天却被关闭的蒸汽和热水表提取出来，至少被关闭了48小时以上的 elif meter == 1: time_ids = ids.to_frame().join(Xy_subset.timestamp).set_index(\u0026#34;timestamp\u0026#34;).ids#将ids和timestamp对应起来 is_bad = ids.map(ids.value_counts()) \u0026gt;= min_interval#关闭时间大于48小时的 # 冷水在冬天可能被关闭 jan_id = time_ids.get(0, False)#一月份的开始的id dec_id = time_ids.get(8283, False)#十二月份开始的id if (jan_id and dec_id and jan_id == time_ids.get(500, False) and dec_id == time_ids.get(8783, False)): #如果一月500小时和十二月500小时的读表都为0的话 is_bad = is_bad \u0026amp; (~(ids.isin(set([jan_id, dec_id])))) #将这一部分的的行从is_bad中删除 else: raise Exception(f\u0026#34;Unexpected meter type: {meter}\u0026#34;) result = is_zero.copy() result.update(is_bad) return result def find_bad_zeros(X, y): \u0026#34;\u0026#34;\u0026#34;返回仅包含应该删除的行的Index\u0026#34;\u0026#34;\u0026#34; Xy = X.assign(meter_reading=y, meter_id=X.meter) is_bad_zero = Xy.groupby([\u0026#34;building_id\u0026#34;, \u0026#34;meter\u0026#34;]).apply(make_is_bad_zero) return is_bad_zero[is_bad_zero].index.droplevel([0, 1]) def find_bad_sitezero(X): \u0026#34;\u0026#34;\u0026#34;返回Site 0 读数异常的行的index.\u0026#34;\u0026#34;\u0026#34; return X[(X.timestamp \u0026lt; 3378) \u0026amp; (X.site_id == 0) \u0026amp; (X.meter == 0)].index def find_bad_building1099(X, y): \u0026#34;\u0026#34;\u0026#34;返回建筑1099的读数异常高的行的index .\u0026#34;\u0026#34;\u0026#34; return X[(X.building_id == 1099) \u0026amp; (X.meter == 2) \u0026amp; (y \u0026gt; 3e4)].index def find_bad_rows(X, y): return find_bad_zeros(X, y).union(find_bad_sitezero(X)).union(find_bad_building1099(X, y))   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  X, y = combined_data(train,weather_train) bad_rows = find_bad_rows(X, y) #输出异常值的index pd.Series(bad_rows.sort_values()).to_csv(\u0026#34;rows_to_drop.csv\u0026#34;, header=False, index=False) X = X.drop(index=bad_rows) y = y.reindex_like(X) X = _add_time_features(X) X = compress_dataframe(X) X = X.drop(columns=\u0026#34;timestamp\u0026#34;) # drop掉原本的timestamp del bad_rows,train,weather_train gc.collect();   3.5 评价函数 由于需要预测连续值，因此需要采用回归模型。由于该项目是Kaggle赛题，测试集是使用均方根对数误差 RMSLE（Root Mean Squared Logarithmic Error, RMSLE)评测的，因此这里只能使用RMSLE。RMSLE的计算公式为：\n$${\\rm RMSLE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(p_i + 1) - \\log(a_i+1))^2 }$$\n其中\n $n$（public/private）数据集中的样本总数, $p_i$ 是目标的预测值 $a_i$ 第i个目标的真实值. $\\log(x)$ 是自然对数  我们只需要对目标值进行$y = \\log(y+1)$的变换，就可以使用常见的RMSE作为评价函数，我们使用numpy中的log1p就可以实现。\n注意：进行预测的时候需要使用$y = e^y-1$将目标值转换回去，可以使用 y = np.exp1m(y)。\n1 2  #对目标值进行变换 y = np.log1p(y)   问题 2: 思考此处为何要进行对数转换。\n回答:\n4. LightGBM 4.1 模型参数 LightGBM 主要调节的参数包括：\n learning_rate：迭代步长,学习率； num_leaves：LightGBM使用leaf-wise的算法，在调节树的复杂度时，使用num_leaves，较小导致欠拟合，较大导致过拟合； subsample：0-1之间，控制每棵树随机采样的比例，减小这个参数的值，算法会更加保守，避免过拟合。但如果这个值设置得过小，可能会导致欠拟合； lambda_l2：L2正则化系数，用来控制过拟合； num_trees：迭代步数。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  params = { \u0026#39;task\u0026#39;: \u0026#39;train\u0026#39;, \u0026#39;boosting_type\u0026#39;: \u0026#39;gbdt\u0026#39;, \u0026#39;objective\u0026#39;: \u0026#39;regression\u0026#39;, \u0026#39;metric\u0026#39;: \u0026#39;rmse\u0026#39;, \u0026#39;num_leaves\u0026#39;: 40, \u0026#39;subsample\u0026#39;:0.8, \u0026#39;learning_rate\u0026#39;: 0.03, \u0026#39;verbose\u0026#39;: 1, \u0026#39;lambda_l2\u0026#39;:3 } num_trees = 1000 #设置分类变量 categorical_features=[\u0026#39;building_id\u0026#39;, \u0026#39;site_id\u0026#39;, \u0026#39;primary_use\u0026#39;, \u0026#39;had_air_temperature\u0026#39;, \u0026#39;had_cloud_coverage\u0026#39;, \u0026#39;had_dew_temperature\u0026#39;, \u0026#39;had_precip_depth_1_hr\u0026#39;,\u0026#39;had_sea_level_pressure\u0026#39;, \u0026#39;had_wind_direction\u0026#39;, \u0026#39;had_wind_speed\u0026#39;, \u0026#39;tm_day_of_week\u0026#39;, \u0026#39;tm_hour_of_day\u0026#39;]   4.2 模型训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  n_splits = 3 for val in X[\u0026#39;meter\u0026#39;].unique(): X1 = X[X[\u0026#39;meter\u0026#39;] == val].drop(columns=[\u0026#39;meter\u0026#39;]) kf = StratifiedKFold(n_splits=n_splits,random_state=42) #使用StratifiedKFold，让指定列在每一个fold中的分布相同，这里设置分为3个fold t = 0 for train_index, test_index in kf.split(X1, X1[\u0026#39;tm_hour_of_day\u0026#39;]): #让每个fold中[\u0026#39;tm_hour_of_day\u0026#39;]的分布相同 train_features = X1.iloc[train_index] train_target = y[X1.iloc[train_index].index] test_features = X1.iloc[test_index] test_target = y[X1.iloc[test_index].index] d_train = lgb.Dataset(train_features, train_target, categorical_feature=categorical_features) d_eval = lgb.Dataset(test_features,test_target, categorical_feature=categorical_features) print(\u0026#34;Building model meter :\u0026#34;,val,\u0026#39;fold:\u0026#39;,t) md = lgb.train(params, d_train, num_boost_round=num_trees, valid_sets=(d_train, d_eval), early_stopping_rounds=200,verbose_eval=20) md.save_model(\u0026#39;lgb_val{}_fold{}.bin\u0026#39;.format(val,t)) t += 1 del X1 del d_train, d_eval, train_features, test_features, md gc.collect();   问题 3: 查阅资料，总结LightGBM与CatBoost的差异。\n回答:\n5. 结果预测 1 2 3 4 5 6  X = compress_dataframe(test.join(building, on=\u0026#34;building_id\u0026#34;).join(weather_test, on=[\u0026#34;site_id\u0026#34;, \u0026#34;timestamp\u0026#34;]).fillna(-1)) X = compress_dataframe(_add_time_features(X)) X = X.drop(columns=\u0026#34;timestamp\u0026#34;) # drop掉原本的timestamp del test, weather_test gc.collect();   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #输出预测结果 result = np.zeros(len(X)) for val in X[\u0026#39;meter\u0026#39;].unique(): ix = np.nonzero((X[\u0026#39;meter\u0026#39;] == val).to_numpy()) for i in tqdm(range(n_splits)): #加载刚才保存的模型 model = lgb.Booster(model_file=\u0026#39;lgb_val{}_fold{}.bin\u0026#39;.format(val, i)) result[ix] += model.predict(X.iloc[ix].drop(columns=[\u0026#39;meter\u0026#39;]), num_iteration=model.best_iteration)/n_splits del model gc.collect(); predictions = pd.DataFrame({ \u0026#34;row_id\u0026#34;: X.index, \u0026#34;meter_reading\u0026#34;: np.clip(np.expm1(result), 0, None) }) # float_format设置保留四位小数，减少文件大小，为文件上传节省时间 predictions.to_csv(\u0026#34;submission.csv\u0026#34;, index=False, float_format=\u0026#34;%.4f\u0026#34;)   1    ","date":"2021-07-23T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/kaggle-ashrae-great-energy-predictor-iii/","title":"Kaggle - ASHRAE, Great Energy Predictor III"},{"content":"Overview 1 2 3 4 5 6 7  df.head(x) df.info() df.describe() df.shape df.values df.columns df.index   1 2  df.sort_values(by=\u0026#34;col\u0026#34;).tail(n) # n largest, e.t. df.nlargest(n, \u0026#34;col\u0026#34;)   1 2 3  df.sample(n) # Return n random samples df.sample(frac=0.3) # Return a random sample of 30 percent df.sample(frac=1) # Shuffle   1 2  df.corr() df.diff()   Sort 1 2 3 4 5 6 7 8 9 10 11  df.sort_values( by=\u0026#34;col_name\u0026#34;, axis=0, ascending=True, inplace=False ) df.sort_values( by=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;, \u0026#34;col3\u0026#34;], ascending=[True, False, True] # sort col1 by ascending; sort col2 by descending; sort col3 by ascending )   1 2 3 4  df.sort_index( level=[\u0026#34;outter_index\u0026#34;, \u0026#34;inner_index\u0026#34;], ascending=False )   Set index 1 2 3 4 5 6 7  df.set_index(\u0026#34;col\u0026#34;) df.set_index(\u0026#34;outter_index\u0026#34;, \u0026#34;inner_index\u0026#34;) df.reset_index() df.reset_index(drop=False) df = pd.read_csv(\u0026#34;xxxx.csv\u0026#34;, index_col=[\u0026#34;col\u0026#34;])   Subset and Slice ※ By row 1 2 3 4 5 6 7 8 9 10 11  # Subset by row df[df[\u0026#34;col\u0026#34;] \u0026gt; 0] df[ (df.col1 \u0026gt; 0) \u0026amp; (df.col2 \u0026gt;0) ] df[ df.col.isin([\u0026#34;xxx\u0026#34;, \u0026#34;yyy\u0026#34;]) ]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # With loc method ## The first input to .loc[] accessor allows you to select the rows it returns. df.loc[ [\u0026#34;outer_index1\u0026#34;, \u0026#34;outer_index_2\u0026#34;] ] df.loc[ [ (\u0026#34;outer_index_1\u0026#34;, \u0026#34;inner_index_1\u0026#34;), (\u0026#34;outer_index_2\u0026#34;, \u0026#34;inner_index_2\u0026#34;), (\u0026#34;outer_index_3\u0026#34;, \u0026#34;inner_index_3\u0026#34;), ] ] df.loc[ \u0026#34;outer_index_i\u0026#34; : \u0026#34;outer_index_j\u0026#34; ] df.loc[ (\u0026#34;outer_index_i\u0026#34;, \u0026#34;inner_index_i\u0026#34;): (\u0026#34;outer_index_j\u0026#34;, \u0026#34;inner_index_j\u0026#34;) ]   1 2  # With iloc method df[df[\u0026#34;y\u0026#34;]==+1][np.dot(df[df[\u0026#34;y\u0026#34;]==+1].iloc[:,0:df.shape[1]-1], w) \u0026lt;= 0] # subset by row and then by row   1 2 3 4 5 6 7  # With query method  # df.query(\u0026#34;SQL Statements string\u0026#34;) df.query( \u0026#34;col1 == \u0026#39;xxx\u0026#39; or (col1 == \u0026#39;yyy\u0026#39; and col2 \u0026lt; 90)\u0026#34; ) df.query(\u0026#39;date \u0026gt;= \u0026#34;1991-01-01\u0026#34;\u0026#39;) # date could be DateFrame index name.   By col 1 2 3 4 5 6 7  # Subset \u0026amp; Slice by col df[\u0026#34;col\u0026#34;] df.col df[df.col == df.col.max()].col # equal to df.col.max() df[ [\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;] ]   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # With loc method df_sort_id.loc[ [ (\u0026#34;outer_index_1\u0026#34;, \u0026#34;inner_index_1\u0026#34;), (\u0026#34;outer_index_2\u0026#34;, \u0026#34;inner_index_2\u0026#34;), (\u0026#34;outer_index_3\u0026#34;, \u0026#34;inner_index_3\u0026#34;), ] , [\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;] ] df_sort_id.loc[ (\u0026#34;Julia\u0026#34;, \u0026#34;1\u0026#34;): (\u0026#34;Julia\u0026#34;, \u0026#34;3\u0026#34;) , \u0026#34;col_i\u0026#34;: \u0026#34;col_j\u0026#34; ] df.loc[ df.col1 == \u0026#34;xxx\u0026#34;, # the first input of .loc select the rows \u0026#34;col2\u0026#34; # the second input of .loc select the columns ]   1 2 3  # Add a col df[\u0026#34;newcol\u0026#34;] = scalar or list df.insert(0, \u0026#34;newcol\u0026#34;, scalar or list) # 0 is the location of the new column   Aggregate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  df.col.mean() df[[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;]].mean() def pct30(col): return col.quantile(0.3) df.col.agg(min) df[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;].agg([min, max, np.mean, np.median, pct30]) df[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;].agg([cumsum, cummin, cumprod]) df.agg( { \u0026#34;col1\u0026#34;: \u0026#34;sum\u0026#34;, \u0026#34;col2\u0026#34;: \u0026#34;mean\u0026#34;, # There is no need to call the numpy module at this time. \u0026#34;col3\u0026#34;: \u0026#34;median\u0026#34;, \u0026#34;col4\u0026#34;: \u0026#34;count\u0026#34; } )   1 2  df.mean(axis=\u0026#34;columns\u0026#34;) # calculate for every rows df.mean(axis=\u0026#34;index\u0026#34;) # calculate for every columns   Duplicate Value 1 2 3 4 5 6 7 8 9  df.drop_duplicates( subset=\u0026#34;col\u0026#34; ) df.drop_duplicates( subset=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;] ) df.col.unique()   Counting 1 2 3 4 5 6 7 8  df.col.value_counts( sort=True, normalize=False ) df.col.value_counts() # e.t. df.groupby(\u0026#34;col\u0026#34;).count()   1 2 3 4 5  # count missing value of each columns df.isna() df.isna().any() df.isna().sum() df.isna().sum().plot(kind=\u0026#34;bar\u0026#34;)   Group Groupby 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # Groupby method df.groupby( \u0026#34;col\u0026#34; ) df.groupby( [\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;] ) # e.t. df.groupby( [\u0026#34;col1\u0026#34;, df[\u0026#34;col2\u0026#34;]] ) df.groupby(\u0026#34;col1\u0026#34;).agg(\u0026#34;sum\u0026#34;)[\u0026#34;col2\u0026#34;].plot(kind=\u0026#34;bar\u0026#34;) # e.t. df.groupby(\u0026#34;col1\u0026#34;).agg(\u0026#34;sum\u0026#34;).plot(kind=\u0026#34;bar\u0026#34;, y=\u0026#34;col2\u0026#34;)   Argument level = 0 separates rows with the same (outest) index.\n1 2 3 4  ind = [1, 2, 3, 1, 2, 3, 4] s = pd.Series([1, 2, 3, 10, 20, 30, 40], index=ind) sg = s.groupby(level=0) print(sg.first(), sg.last())   1 1 2 2 3 3 4 40 dtype: int64 1 10 2 20 3 30 4 40 dtype: int64 1 2 3 4 5  df1_2_3 = pd.concat( [df1, df2, df3], keys=[\u0026#39;7Jul\u0026#39;, \u0026#39;8Aug\u0026#39;, \u0026#39;9Sep\u0026#39;] ) print(df1_2_3.sample(5))    iid cid invoice_date total bill_ctry 8Aug 18 220 6 2011-08-22 5.94 Czech Republic 7Jul 28 371 8 2013-07-02 1.98 Belgium 8Aug 28 378 46 2013-08-02 1.98 Ireland 9Sep 27 386 27 2013-09-02 1.98 USA 23 309 22 2012-09-26 3.98 USA # \u0026lt;-- there is a Multi indexs 1 2 3 4  sumdf = df_1_2_3.groupby(level=0).agg(sum) print(sumdf) sumdf.plot(kind=\u0026#34;bar\u0026#34;) plt.show()    iid cid total 7Jul 7385 961 190.1 8Aug 7630 1170 198.1 9Sep 7417 961 196.2 Pivot 1 2 3 4 5 6 7 8 9 10 11 12 13  # Pivot table df.pivot_table( values=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;], index=[\u0026#34;col3\u0026#34;, \u0026#34;col4\u0026#34;], columns=[\u0026#34;col5\u0026#34;, \u0026#34;col6\u0026#34;], aggfunc=\u0026#39;mean\u0026#39;, fill_value=None, margins=False, dropna=True, margins_name=\u0026#39;All\u0026#39; ) df.pivot_table(\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;, \u0026#34;col3\u0026#34;) # values = col1, index = col2, columns = col3   Melt melt method will unpivot a table from wide to long format. This is often a much more computer-friendly format. Imagine a situation where you have merged many columns, making your table very wide. The merge() method can then be used to reshape that table into a more computer-friendly format.\n Recall that we call each row of the table an observation and each column a variable. The melt method integrates certain columns (name) into a variable column and the values of those columns into the value column.\n The first input argument to the method is id_vars. These are columns to be used as identifier variables. We can also think of them as columns in our original dataset that we do not want to change.\n1 2 3 4 5 6 7 8 9  df = pd.DataFrame( { \u0026#34;a\u0026#34; : np.random.randint(0,5, 20), \u0026#34;b\u0026#34; : np.random.randint(0,5, 20), \u0026#34;c\u0026#34; : np.random.randint(0,5, 20), \u0026#34;d\u0026#34; : np.random.randint(0,5, 20), } ) print(df.melt(id_vars=\u0026#34;a\u0026#34;).sample(5))    a variable value 56 4 d 2 17 3 b 3 27 4 c 2 47 4 d 2 10 0 b 1 1  print(df.melt(id_vars=[\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;]).sample(5))    a b variable value 12 3 1 c 1 19 2 1 c 0 4 3 1 c 1 32 3 1 d 1 5 3 1 c 3 The argument value_vars with the melt() will allow us to control which columns are unpivoted. If you set this argument, the others columns (except for id_vars and value_vars) will be ignored.\n1  print(df.melt(id_vars=\u0026#34;a\u0026#34;, value_vars=[\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;]).sample(10))    a variable value 2 3 b 2 32 3 c 1 18 2 b 3 16 4 b 2 3 2 b 2 37 3 c 1 21 2 c 1 19 2 b 1 34 4 c 0 28 3 c 1 The var_name argument will allow us to set the name of the variable column in the output. Similarly, the value_name argument will allow us to set the name of the value column in the output.\n1  print(df.melt(id_vars=\u0026#34;a\u0026#34;, value_vars=[\u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;], var_name=\u0026#34;bc\u0026#34;, value_name=\u0026#34;va\u0026#34;).sample(5))    a bc va 13 2 b 3 7 4 b 4 36 4 c 1 38 2 c 0 9 3 b 3 Plot Histograms We can create a histogram of the variable by selecting the column and calling .hist().\nWe can adjust the number of bars, or bins, using the bins argument. Plots can also be layered on top of one another. We can use plt.legend(), passing in a list of labels, and then call show. We can use hist\u0026rsquo;s alpha argument, which takes a number. 0 means completely transparent that is, invisible, and 1 means completely opaque.\n1 2 3 4 5 6 7  # Histogram of conventional avg_price  avo[avo[\u0026#34;type\u0026#34;] == \u0026#34;conventional\u0026#34;][\u0026#34;avg_price\u0026#34;].hist(bins= 30, alpha=0.5) # Histogram of organic avg_price avo[avo[\u0026#34;type\u0026#34;] == \u0026#34;organic\u0026#34;][\u0026#34;avg_price\u0026#34;].hist(bins=30, alpha=0.5) # Add a legend plt.legend([\u0026#34;conventional\u0026#34;, \u0026#34;organic\u0026#34;])   You can also plot histograms for multiple variables at a time as follows: df[[\u0026quot;col1\u0026quot;, \u0026quot;col2\u0026quot;]].hist()\n1  avo[[\u0026#34;avg_price\u0026#34;, \u0026#34;nb_sold\u0026#34;]].hist()   Bar plots Bar plots can reveal relationships between a categorical variable and a numeric variable, like lang and rand1. we group by lang, select the rand1 column, and take the mean, giving us the average rand1 values of each lang.\nNow we can create a bar plot from the mean using the .plot() method, setting “kind” equal to “bar”. To add a title to our plot, we can use the title argument of the plot method. We may want to rotate the x-axis labels to make the text easier to read. This can be done by passing an angle in degrees with the “rot” argument\n1 2 3 4 5  # Get the total number of avocados sold of each size nb_sold_by_size = avo.groupby(by=\u0026#34;size\u0026#34;)[\u0026#34;nb_sold\u0026#34;].sum() # Create a bar plot of the number of avocados sold by size nb_sold_by_size.plot(kind=\u0026#34;bar\u0026#34;, rot=45)   You can set the color of the graph by setting the color argument. Color accepts scalar or lists.\n1 2 3  is_recession = [\u0026#39;r\u0026#39; if s==\u0026#39;recession\u0026#39; else \u0026#39;g\u0026#39; for s in gdp_recession[\u0026#39;econ_status\u0026#39;]] gdp_recession.plot(kind=\u0026#34;bar\u0026#34;, y=\u0026#34;gdp\u0026#34;, x=\u0026#34;date\u0026#34;, color=is_recession, rot=90) plt.show()   Line plots Line plots are great for visualizing changes in numeric variables over time. We can use the .plot() method again, but this time, we pass in three arguments: date as x, rand2 as y, and “kind” equals “line”\n1 2 3 4 5  # Get the total number of avocados sold on each date nb_sold_by_date = avo.groupby(by=\u0026#34;date\u0026#34;)[\u0026#34;nb_sold\u0026#34;].sum() # \u0026lt;-- note groupby date # Create a line plot of the number of avocados sold by date nb_sold_by_date.plot(kind=\u0026#34;line\u0026#34;, rot=45)   You can also draw multiple lines by setting a list of columns for the y argument:\n1 2  df.plot(y=[\u0026#34;close_jpm\u0026#34;, \u0026#34;close_wells\u0026#34;, \u0026#34;close_bac\u0026#34;]) plt.show()   Scatter plots Scatter plots are great for visualizing relationships between two numeric variables. we call the .plot() method with x equal to rand2, y equal to rand3, and “kind” equal to “scatter.”\n1 2 3 4 5 6 7  # Scatter plot of nb_sold vs avg_price with title avo.plot( x=\u0026#34;nb_sold\u0026#34;, y=\u0026#34;avg_price\u0026#34;, kind=\u0026#34;scatter\u0026#34;, title=\u0026#34;Number of avocados sold vs. average price\u0026#34; )   10. Merge ※ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # Inner Join df1_df2 = df1.merge(df2, on=\u0026#34;col\u0026#34;, suffixes=(\u0026#34;_l\u0026#34;, \u0026#34;_r\u0026#34;)) df1_df2 = df1.merge(df2, on=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;]) df1_df2 = df1.merge(df2, left_on=\u0026#34;col1\u0026#34;, right_on=\u0026#34;col2\u0026#34;) # The columns to be merged in the two tables have different names # Left Join df1_2 = df1.merge(df2, on=\u0026#34;col\u0026#34;, how=\u0026#34;left\u0026#34;) # default argument how is \u0026#34;inner\u0026#34; # Right Join df1_2 = df1.merge(df2, on=\u0026#34;col\u0026#34;, how=\u0026#34;right\u0026#34;) # Outer Join df1_2 = df1.merge(df2, on=\u0026#34;col\u0026#34;, how=\u0026#34;outer\u0026#34;) # Symmetric Difference df1_2 = df1.merge(df2, on=\u0026#34;col\u0026#34;, how=\u0026#34;outer\u0026#34;) m = (df1_2[\u0026#34;col1_x\u0026#34;].isna()) | (df1_2[\u0026#34;col1_y\u0026#34;].isna()) df1_2[m] # Self Join df_1s = df1.merge(df1, left_on=\u0026#34;c1\u0026#34;, right_on=\u0026#34;c3\u0026#34;, suffixes=(\u0026#34;_x\u0026#34;, \u0026#34;_y\u0026#34;))   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Merge on Index df1.merge(df2, left_index=True, right_index=True) df1.merge(df2, on=\u0026#34;index_name\u0026#34;) df1.merge( df2, left_on=\u0026#34;left_index_name\u0026#34;, left_index=True, right_on=\u0026#34;right_index_name\u0026#34;, right_index=True, ) df1.merge( df2, left_on=\u0026#34;col_name\u0026#34;, right_on=\u0026#34;right_index_name\u0026#34;, right_index=True, )   1 2 3 4 5  # Merge multiple DataFrame df1_df2_df3 = df1.merge(df2, on=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;]).merge(df3, on=\u0026#34;col3\u0026#34;, suffixes=(\u0026#34;_2\u0026#34;, \u0026#34;_3\u0026#34;)) # e.t. (equal to) df1_df2_df3 = df1.merge(df2, on=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;])\\ # \u0026lt;-- note this backslash .merge(df3, on=\u0026#34;col3\u0026#34;, suffixes=(\u0026#34;_2\u0026#34;, \u0026#34;_3\u0026#34;))   1 2 3 4 5 6 7 8  # Merge with other operation df_1_2_3 = df_1.merge(df_2, on=\u0026#34;col1\u0026#34;).merge(df_3, on=\u0026#34;col2\u0026#34;) df_1_2_3.groupby(\u0026#34;col3\u0026#34;).agg({\u0026#39;col4\u0026#39;: \u0026#39;sum\u0026#39;}).plot(kind=\u0026#34;bar\u0026#34;) # e.t. df_1_2_3.groupby(\u0026#34;col3\u0026#34;).col4.agg(sum).plot(kind=\u0026#34;bar\u0026#34;) # e.t. df_1_2_3.groupby(\u0026#34;col3\u0026#34;).agg(sum).plot(kind=\u0026#34;bar\u0026#34;, y=\u0026#34;col4\u0026#34;)   11. Advanced Merge Semi Join A semi join filters the left table down to those observations that have a match in the right table. It is similar to an inner join where only the intersection between the tables is returned, but unlike an inner join, only the columns from the left table are shown. Finally, no duplicate rows from the left table are returned, even if there is a one-to-many relationship.\nSemi Join Three Steps:\n Merge the left and right tables on key column using an inner join; Search if the key column in the left table is in the merged tables using the .isin() method creating a Boolean Series; Subset the rows of left table.  1 2 3 4 5 6 7 8  # 1. df_merged = df1.merge(df2, on=\u0026#34;col1\u0026#34;) # 2. bs = df1[\u0026#34;col2\u0026#34;].isin(df_merged[\u0026#34;col2\u0026#34;]) # bs means boolean series # 3. df3 = df1[bs]   Anti Join An anti join returns the observations in the left table that do not have a matching observation in the right table. It also only returns the columns from the left table.\nWith indicator set to True, the merge method adds a column called \u0026ldquo;_merge\u0026rdquo; to the output. This column tells the source of each row. For example, if rows found a match in both tables, the _merge column shows both; if rows can only be found in the left table, the _merge column shows left_only. Obviously, right_only will not appear in a left join.\n1 2 3 4 5 6 7 8 9 10 11  # 1. df_merge = df1.merge(df2, on=\u0026#34;col1\u0026#34;, how=\u0026#34;left\u0026#34;, indicater=True) # 2. ls = df_merge.loc[ df_merge[\u0026#34;_merge\u0026#34;]==\u0026#34;left_only\u0026#34;, \u0026#34;col1\u0026#34; ] # 3. df3 = df1[df1[\u0026#34;col1\u0026#34;].isin(ls)]   Concatenate So far, we have only discussed how to merge two tables, which mainly grows them horizontally. Now we concern how to grow them vertically.\n1 2 3  pd.concat( [df1, df2, df3] )   Notice the column headers are the same. The result is a vertically combined table. Notice each table\u0026rsquo;s index value was retained.\n1 2 3 4  pd.concat( [df1, df2, df3], ignore_index=True )   If the index contains no valuable information, then we can ignore it in the concat method by setting ignore_index to True. The result is that the index will go from 0 to n-1.\nNow, suppose we wanted to associate specific keys with each of the pieces of our three original tables. We can provide a list of labels to the keys argument. Make sure that ignore_index argument is False, since you can\u0026rsquo;t add a key and ignore the index at the same time. This results in a table with a multi-index, with the label on the first level.\n1 2 3 4 5  pd.concat( [df1, df2, df3], ignore_index=False, keys=[\u0026#34;df1\u0026#34;, \u0026#34;df2\u0026#34;, \u0026#34;df3\u0026#34;] )   When we need to combine tables that have different column names, the concat method by default will include all of the columns in the different tables it\u0026rsquo;s combining. If we only want the matching columns between tables, we set the join argument to \u0026ldquo;inner\u0026rdquo;. Its default value is equal to \u0026ldquo;outer\u0026rdquo;\n1 2 3 4  pd.concat( [df1, df2, df3], join=\u0026#34;inner\u0026#34; )   Append is a simplified concat method. It supports the ignore_index argument. However, it does not support keys or join. Join is always set to outer.\n1 2 3 4  df1.append( [df2, df3], ignore_index=True )   Verifying Integrity Both the merge and concat methods have special features that allow us to verify the structure of our data. The validate and verify_integrity arguments of the merge and concat methods respectively will allow us to verify the data.\nWhen merging two tables, we might expect the tables to have a one-to-one relationship. However, one of the columns we are merging on may have a duplicated value, which will turn the relationship into a one-to-many.\nIf we provide the validate argument one of these key strings:\n one_to_one one_to_many many_to_one many_to_many  it will validate the relationship between the two tables. For example, if we specify we want a one-to-one relationship, but it turns out the relationship is not one-to-one, then an error is raised.\n1 2 3 4 5 6 7 8 9 10 11 12 13  df1 = pd.DataFrame( { \u0026#34;a\u0026#34;: np.arange(5), \u0026#34;b\u0026#34;: list(\u0026#34;adfgh\u0026#34;) } ) df2 = pd.DataFrame( { \u0026#34;a\u0026#34;: [0, 1, 2, 3, 3], \u0026#34;b\u0026#34;: list(\u0026#34;tvdsv\u0026#34;) } ) df1.merge(df2, on=\u0026#34;a\u0026#34;, validate=\u0026#34;one_to_one\u0026#34;)   MergeError: Merge keys are not unique in right dataset; not a one-to-one merge When concatenating tables vertically, we might unintentionally create duplicate records if a record exists in both tables.\n Notice, the recode represent index, not columns values.\n concat method has the argument verify_integrity, which by default is False. However, if set to True, it will check if there are duplicate values in the index and raise an error if there are. It will only check the index values and not the columns.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  df1 = pd.DataFrame( { \u0026#34;a\u0026#34;: np.random.rand(5), \u0026#34;b\u0026#34;: np.random.rand(5), \u0026#34;c\u0026#34;: np.random.rand(5), }, index=np.arange(5) ) df2 = pd.DataFrame( { \u0026#34;a\u0026#34;: np.random.rand(5), \u0026#34;b\u0026#34;: np.random.rand(5), \u0026#34;c\u0026#34;: np.random.rand(5), }, index=np.arange(4,9) ) print(df1, \u0026#39;\\n\u0026#39;, df2)    a b c 0 0.131960 0.559110 0.803359 1 0.862007 0.349336 0.594149 2 0.805661 0.313103 0.937367 3 0.893554 0.633904 0.475403 4 0.381487 0.096156 0.219184 a b c 4 0.469545 0.142471 0.906317 5 0.035282 0.481996 0.207780 6 0.241841 0.355997 0.599351 7 0.684347 0.592812 0.833834 8 0.036764 0.347563 0.895287 1 2 3 4  pd.concat( [df1, df2], verify_integrity=True )   ValueError: Indexes have overlapping values: Int64Index([4], dtype='int64') .merge_ordered() The merge_ordered method are similar to the standard merge method with an outer join, but the results are sorted. The sorted results make this a useful method for ordered or time-series data.\nIt has many of the same arguments we have already covered with the merge method:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  pd.merge_ordered( df1, df2, # \u0026lt;-- no bracket  on=\u0026#34;col\u0026#34;, suffixes(\u0026#34;_l\u0026#34;, \u0026#34;_r\u0026#34;) ) pd.merge_ordered( df1, df2, left_on=\u0026#34;col1\u0026#34;, right_on=\u0026#34;col2\u0026#34;, how=\u0026#34;left\u0026#34;) pd.merge_ordered( df1, df2, on=[\u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;] # Note the difference with `on=[\u0026#34;col2\u0026#34;, \u0026#34;col1\u0026#34;]` )   # on=[\u0026quot;date\u0026quot;, \u0026quot;country\u0026quot;] date country gdp series_code_x pop series_code_y 0 1990-01-01 Australia 158051.132 NYGDPMKTPSAKD 17065100 SP.POP.TOTL 1 1990-01-01 Sweden 79837.846 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 2 1990-04-01 Australia 158263.582 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 3 1990-04-01 Sweden 80582.286 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 4 1990-07-01 Australia 157329.279 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 5 1990-07-01 Sweden 79974.360 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 6 1990-09-01 Australia 158240.678 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 7 1990-09-01 Sweden 80106.497 NYGDPMKTPSAKD 8558835 SP.POP.TOTL 8 1991-01-01 Australia 156195.954 NYGDPMKTPSAKD 17284000 SP.POP.TOTL 9 1991-01-01 Sweden 79524.242 NYGDPMKTPSAKD 8617375 SP.POP.TOTL # on=[\u0026quot;country\u0026quot;, \u0026quot;date\u0026quot;] date country gdp series_code_x pop series_code_y 0 1990-01-01 Australia 158051.132 NYGDPMKTPSAKD 17065100 SP.POP.TOTL 1 1990-04-01 Australia 158263.582 NYGDPMKTPSAKD 17065100 SP.POP.TOTL 2 1990-07-01 Australia 157329.279 NYGDPMKTPSAKD 17065100 SP.POP.TOTL 3 1990-09-01 Australia 158240.678 NYGDPMKTPSAKD 17065100 SP.POP.TOTL 4 1991-01-01 Australia 156195.954 NYGDPMKTPSAKD 17284000 SP.POP.TOTL 5 1991-04-01 Australia 155989.033 NYGDPMKTPSAKD 17284000 SP.POP.TOTL 6 1991-07-01 Australia 156635.858 NYGDPMKTPSAKD 17284000 SP.POP.TOTL 7 1991-09-01 Australia 156744.057 NYGDPMKTPSAKD 17284000 SP.POP.TOTL 8 1992-01-01 Australia 157916.081 NYGDPMKTPSAKD 17495000 SP.POP.TOTL 9 1992-04-01 Australia 159047.827 NYGDPMKTPSAKD 17495000 SP.POP.TOTL We can fill in the missing data by setting the fill_method argument to \u0026ldquo;ffill\u0026rdquo; for forward fill. It will interpolate missing data by filling the missing values with the previous value (the upper row).\n1 2 3 4 5  pd.merge_ordered( df1, df2, on=\u0026#34;col\u0026#34;, fill_method=\u0026#34;ffill\u0026#34; )   .merge_asof() The merge_asof() method is similar to an ordered left join. It has similar features as merge_ordered(). However, unlike an ordered left join, merge_asof() will match on the nearest value columns rather than equal values.\nFor each row in the left DataFrame, merge_asof() select the last row in the right DataFrame where the value for the key is less than or equal the value for the left key. This brings up an important point - whatever columns you merge on must be sorted. (left and right key columns must be sorted)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  df1 = pd.DataFrame( { \u0026#34;a\u0026#34;: [1, 3, 4, 7, 5], \u0026#34;b\u0026#34;:np.arange(5) } ) df2 = pd.DataFrame( { \u0026#34;a\u0026#34;: [1, 2, 3, 8, 5], \u0026#34;b\u0026#34;:np.arange(5) } ) df_1_2 = pd.merge_asof( df1.sort_values(by=\u0026#34;a\u0026#34;), df2.sort_values(by=\u0026#34;a\u0026#34;), on=\u0026#34;a\u0026#34; ) print(df1.sort_values(by=\u0026#34;a\u0026#34;),\u0026#39;\\n\u0026#39;, df2.sort_values(by=\u0026#34;a\u0026#34;), \u0026#39;\\n\u0026#39;,df_1_2)    a b 0 1 0 1 3 1 2 4 2 4 5 4 3 7 3 a b 0 1 0 1 2 1 2 3 2 4 5 4 3 8 3 a b_x b_y 0 1 0 0 1 3 1 2 2 4 2 2 3 5 4 4 4 7 3 4 Setting the direction argument as \u0026ldquo;forward\u0026rdquo; will change the behavior of the method to select the row in the right table. The default value for the direction argument is \u0026ldquo;backward\u0026rdquo;. Setting the direction argument as nearest to match rows with the nearest times in either direction.\n1 2 3 4 5  pd.merge_asof( df1, df2, on=\u0026#34;col1\u0026#34;, direction=\u0026#34;forward\u0026#34; )   ","date":"2020-08-14T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/feature-engineering-cleaning/","title":"Feature Engineering (Cleaning)"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n Importing data from the Internet Importing flat files from the web ","date":"2020-05-01T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/importing-data-in-python-ii/","title":"Importing Data in Python II"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n 1. Importing data from flat files We\u0026rsquo;ll discuss how to import data from 3 kind of data sources\n flat files such as dot txts and dot csvs; files native to other software such as Excel spreadsheets, Stata, SAS and MATLAB files; relational databases such as SQLite \u0026amp; PostgreSQL.  1.1 Importing flat files using open() To check out any plain text file, you can use Python’s basic open() function to open a connection to the file. To do so, you pass the filename to the function open() and also pass it the argument mode=\u0026quot;r\u0026quot;, which makes sure that we can only read it (we wouldn\u0026rsquo;t want to accidentally write to it!), assign the text from the file to a variable by applying the method read() to the connection to the file. After you do this, make sure that you close the connection to the file using the close() method.\n1 2 3 4 5  file = open(\u0026#34;moby_dick.txt\u0026#34;, mode=\u0026#34;r\u0026#34;) print(file.read()[0:200]) print(file.closed) # Check whether the file is closed file.close() print(file.closed)   CHAPTER 1. Loomings. Call me Ishmael. Some years ago--never mind how long precisely--having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail abou False True  If you wanted to open a file in order to write to it, you would pass it the argument mode=\u0026quot;w\u0026quot;.\n using a with statement. This allows you to create a context in which you can execute commands with the file open. Once out of this context, the file will be closed, for this reason, it is called a Context Manager.\n1 2 3 4 5 6  with open(\u0026#39;moby_dick.txt\u0026#39;) as file: print(file.readline()) print(file.readline()) print(file.readline()) print(file.readline()) print(file.readline())   CHAPTER 1. Loomings. Call me Ishmael. Some years ago--never mind how long precisely--having little or no money in my purse, and nothing particular to interest me on shore, I thought I would sail about a little and see the watery part of 1.2 Importing flat files using NumPy If all the data are numerical, you can use the package numpy to import the data as a numpy array with the NumPy functions loadtxt( ). We call loadtxt() and pass it the filename as the first argument, along with the delimiter as the 2nd argument. Note that the default delimiter is any white space so we’ll usually need to specify it explicitly.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import numpy as np file = \u0026#39;digits.csv\u0026#39; digits = np.loadtxt(file, delimiter=\u0026#34;,\u0026#34;) print(type(digits), digits.shape) fig, ax = plt.subplots(5,5) for i in range(5): for j in range(5): im = digits[np.random.randint(0,100), 1:] im_sq = np.reshape(im, (28, 28)) ax[i][j].imshow( im_sq, cmap=\u0026#39;Greys\u0026#39;, interpolation=\u0026#39;nearest\u0026#39; ) plt.show()   \u0026lt;class 'numpy.ndarray'\u0026gt; (100, 785) You can skip the first row by calling loadtxt with the argument skiprows=1; You can select the 1st and 3rd columns of the data, by setting usecols=[0,2]. You can also import different datatypes into NumPy arrays: for example, setting the argument dtype=\u0026quot;str\u0026quot; will ensure that all entries are imported as strings.\n1 2 3 4 5  import numpy as np file = \u0026#39;digits_header.txt\u0026#39; data = np.loadtxt(file, delimiter=\u0026#34;\\t\u0026#34;, skiprows=1, usecols=[0,2]) print(data[:5])   [[1. 0.] [0. 0.] [1. 0.] [4. 0.] [0. 0.]] Notice that loadtxt tends to break down when we have mixed datatypes, for example, columns consisting of floats and columns consisting of strings. And you should import in different datatypes respectively.\n1 2 3 4 5 6 7 8 9 10 11  file = \u0026#39;seaslug.txt\u0026#39; data = np.loadtxt(file, delimiter=\u0026#39;\\t\u0026#39;, dtype=str) print(data[0]) data_float = np.loadtxt(file, delimiter=\u0026#34;\\t\u0026#34;, dtype=float, skiprows=1) print(data_float[9]) plt.scatter(data_float[:, 0], data_float[:, 1]) plt.xlabel(\u0026#39;time (min.)\u0026#39;) plt.ylabel(\u0026#39;percentage of larvae\u0026#39;) plt.show()   ['Time' 'Percent'] [0. 0.357] Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, genfromtxt( ), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n1 2 3 4 5 6 7  data = np.genfromtxt( \u0026#39;titanic.csv\u0026#39;, delimiter=\u0026#39;,\u0026#39;, names=True, dtype=None ) data[0:10]   array([( 1, 0, 3, b'male', 22., 1, 0, b'A/5 21171', 7.25 , b'', b'S'), ( 2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C'), ( 3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282', 7.925 , b'', b'S'), ( 4, 1, 1, b'female', 35., 1, 0, b'113803', 53.1 , b'C123', b'S'), ( 5, 0, 3, b'male', 35., 0, 0, b'373450', 8.05 , b'', b'S'), ( 6, 0, 3, b'male', nan, 0, 0, b'330877', 8.4583, b'', b'Q'), ( 7, 0, 1, b'male', 54., 0, 0, b'17463', 51.8625, b'E46', b'S'), ( 8, 0, 3, b'male', 2., 3, 1, b'349909', 21.075 , b'', b'S'), ( 9, 1, 3, b'female', 27., 0, 2, b'347742', 11.1333, b'', b'S'), (10, 1, 2, b'female', 14., 1, 0, b'237736', 30.0708, b'', b'C')], dtype=[('PassengerId', '\u0026lt;i8'), ('Survived', '\u0026lt;i8'), ('Pclass', '\u0026lt;i8'), ('Sex', 'S6'), ('Age', '\u0026lt;f8'), ('SibSp', '\u0026lt;i8'), ('Parch', '\u0026lt;i8'), ('Ticket', 'S18'), ('Fare', '\u0026lt;f8'), ('Cabin', 'S15'), ('Embarked', 'S1')]) In addition to genfromtxt, the numpy module provides several convenience functions derived from genfromtxt. These functions work the same way as the original, but they have different default values.\n  recfromtxt Returns a standard numpy.recarray (if usemask=False) or a MaskedRecords array (if usemaske=True). The default dtype is dtype=None, meaning that the types of each column will be automatically determined.\n  recfromcsv Like recfromtxt, but with a default delimiter=\u0026quot;,\u0026quot;.\n  1 2 3  file = \u0026#39;titanic.csv\u0026#39; d= np.recfromcsv(file) print(d[:3])   [(1, 0, 3, b'male', 22., 1, 0, b'A/5 21171', 7.25 , b'', b'S') (2, 1, 1, b'female', 38., 1, 0, b'PC 17599', 71.2833, b'C85', b'C') (3, 1, 3, b'female', 26., 0, 0, b'STON/O2. 3101282', 7.925 , b'', b'S')] 1.3 Importing flat files using Pandas If we wish to import a CSV in the most basic case all we need to do is to call the function read_csv( ) and supply it with a single argument, the name of the file, it will return a DataFrame object of the file.\n As Hadley Wickham tweeted, \u0026ldquo;A matrix has rows and columns. A data frame has observations and variables.\u0026rdquo;\n 1 2 3 4 5  file = \u0026#39;digits.csv\u0026#39; # Read the first 5 rows of the file except header into a DataFrame: data data=pd.read_csv(file, nrows=5, header=None) data_array=np.array(data) print(type(data_array))   \u0026lt;class 'numpy.ndarray'\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  import matplotlib.pyplot as plt file = \u0026#39;titanic_corrupt.txt\u0026#39; data = pd.read_csv( file, sep=\u0026#34;\\t\u0026#34;, # \u0026lt;-- the pandas version of delim comment=\u0026#34;#\u0026#34;, # \u0026lt;-- indicates remainder of line should not be parsed. na_values=\u0026#34;Nothing\u0026#34; # \u0026lt;-- takes str (in this case, \u0026#34;Nothing\u0026#34;) to recognize as NA/NaN ) data_origin = pd.read_csv(file) print(data.head()) print(data_origin.head()) pd.DataFrame.hist(data[[\u0026#39;Age\u0026#39;]]) plt.xlabel(\u0026#39;Age (years)\u0026#39;) plt.ylabel(\u0026#39;count\u0026#39;) plt.show()   PassengerId Survived Pclass Sex Age ... Parch Ticket Fare Cabin Embarked 0 1 0 3 male 22.0 ... 0 A/5 21171 7.250 NaN S 1 2 1 1 female 38.0 ... 0 PC 17599 NaN NaN NaN # \u0026lt;-- Notice here 2 3 1 3 female 26.0 ... 0 STON/O2. 3101282 7.925 NaN S 3 4 1 1 female 35.0 ... 0 113803 53.100 C123 S 4 5 0 3 male 35.0 ... 0 373450 8.050 NaN S PassengerId\\tSurvived\\tPclass\\tSex\\tAge\\tSibSp\\tParch\\tTicket\\tFare\\tCabin\\tEmbarked 0 1\\t0\\t3\\tmale\\t22.0\\t1\\t0\\tA/5 21171\\t7.25\\tNo... 1 2\\t1\\t1\\tfemale\\t38.0\\t1\\t0\\tPC 17599#to\\t71.2... # \u0026lt;-- Notice here \u0026quot;#\u0026quot; 2 3\\t1\\t3\\tfemale\\t26.0\\t0\\t0\\tSTON/O2. 3101282\\... 3 4\\t1\\t1\\tfemale\\t35.0\\t1\\t0\\t113803\\t53.1\\tC12... 4 5\\t0\\t3\\tmale\\t35.0\\t0\\t0\\t373450\\t8.05\\t\\tS 2. Importing data from other file types 2.1 Importing Pickle and Excel file Pickle Files is a file type native to Python, which can store data-types in python such as dictionaries, tuples, lists etc. It can serialize objects so that they can be saved into a file and loaded again later. when opening such a file, you can specify that it is read only and is a binary file, by passing the string \u0026lsquo;rb\u0026rsquo; as the second argument of open.\n1 2 3 4 5 6 7 8 9 10 11  d = dict(name=\u0026#39;Bob\u0026#39;, age=20, score=88) print(d) f = open(\u0026#39;dump.pkl\u0026#39;, \u0026#39;wb\u0026#39;) # wirte pickle.dump(d,f) f.close() # read g = open(\u0026#39;./dump.pkl\u0026#39;, \u0026#39;rb\u0026#39;) e=pickle.load(g) g.close() print(e)   {'name': 'Bob', 'age': 20, 'score': 88} {'name': 'Bob', 'age': 20, 'score': 88} 1  ! hexdump -x ./dump.pkl   0000000 0480 2495 0000 0000 0000 7d00 2894 048c 0000010 616e 656d 8c94 4203 626f 8c94 6103 6567 0000020 4b94 8c14 7305 6f63 6572 4b94 7558 002e 000002f An Excel working book generally consists of a number of working sheets, and each working sheets has a mass of working cells. There are many ways (like openpyxl and pyexcel module) to import Excel files and we\u0026rsquo;ll use pandas to do so because it produces dataframes natively.\nWe can use the function Excelfile to assign an Excel file to a variable data. As an Excel file consists of sheets, the first thing to do is figure out what the sheets are. This is straightforward with the data.sheet_names attribute.\n1 2  data = pd.ExcelFile(\u0026#34;/Users/wanghaoming/Documents/gpa.xlsx\u0026#34;) data.sheet_names   ['Sheet1', 'Sheet2', 'Sheet3', 'Sheet4', 'Sheet5', 'Sheet6'] To then load a particular sheet as a dataframe, we need only apply the method parse() to the object data with a single argument, which is either the name as a string or the index as a float of the sheet.\n1 2 3 4 5 6  df6 = data.parse( sheet_name=5, usecols=\u0026#34;A:F\u0026#34;, nrows=12 ) print(df6)    课程名称 学分 成绩 课程名称.1 学分.1 成绩.1 0 实变函数论 3 97 金融衍生品定价Ⅰ 4 93 1 投资学 4 96 金融经济学 4 93 2 概率论（理科） 4 96 高等数学Ⅱ 5 93 3 货币金融学 4 96 高等代数Ⅰ 4 93 4 金融随机分析Ⅱ 3 95 商业银行经营管理 4 92 5 衍生金融工具 4 95 随机过程 4 91 6 金融随机分析Ⅰ 4 94 高等数学Ⅰ 5 91 7 固定收益证券 4 94 统计学 4 91 8 国际金融学 4 94 优化理论 3 90 9 偏微分方程 3 94 金融风险管理 4 90 10 财政学 4 94 会计学 4 90 11 计量经济学 4 93 公司金融 4 80  pd.ExcelFile.parse() is equivalent to pd.read_excel method.\n 2.2 Importing SAS/Stata files The most common SAS files have the extension .sas7bdat and .sas7bcat, which are dataset files and catalog files respectively. We can import the former as DataFrames using the function SAS7BDAT (upper case) from the package sas7bdat (lower case). We can bind the variable file to a connection to the file \u0026lsquo;xxx.sas7bdat\u0026rsquo; in a context manager. Within this context, We can assign to a variable df_sas the result of applying method to_data_frame to file.\n1 2 3 4 5 6 7 8 9  from sas7bdat import SAS7BDAT with SAS7BDAT(\u0026#39;sales.sas7bdat\u0026#39;) as file: df_sas = file.to_data_frame() print(df_sas.head()) pd.DataFrame.hist(df_sas[[\u0026#39;P\u0026#39;]]) plt.ylabel(\u0026#39;count\u0026#39;) plt.show()    The other way to import sas (xport and sas7bdat) file is pd.read_sas.\n Stata files have extension .dta and we can import them using pandas. We don\u0026rsquo;t even need to initialize a context manager in this case. We merely pass the filename to the function pd.read_stata and assign it to a variable.\n1 2 3 4 5 6 7 8 9  import pandas as pd df = pd.read_stata(\u0026#39;disarea.dta\u0026#39;) print(df.head()) pd.DataFrame.hist(df[[\u0026#39;disa10\u0026#39;]]) plt.xlabel(\u0026#39;Extent of disease\u0026#39;) plt.ylabel(\u0026#39;Number of countries\u0026#39;) plt.show()   2.3 Importing HDF5 files  \u0026ldquo;In the Python world, consensus is rapidly converging on Hierarchical Data Format version 5, or \u0026lsquo;HDF5,\u0026rsquo; as the standard mechanism for storing large quantities of numerical data.\u0026rdquo; \u0026mdash;- 2013 O\u0026rsquo;Reilly book Python and HDF5 by Andrew Collette,\n Intro to HDF5 i. Group \u0026amp; Dataset The Hierarchical Data Format version 5 (HDF5) format can be thought of as a file system contained and described within one single file. Think about the files and folders stored on your computer. You might have a data directory with some temperature data for multiple field sites. These temperature data are collected every minute and summarized on an hourly, daily and weekly basis. Within one HDF5 file, you can store a similar set of data organized in the same way that you might organize files and folders on your computer. However in a HDF5 file, what we call \u0026ldquo;directories\u0026rdquo; or \u0026ldquo;folders\u0026rdquo; on our computers, are called groups and what we call files on our computer are called datasets.\n Group: A folder like element within an HDF5 file that might contain other groups or datasets within it. Dataset: The actual data contained within the HDF5 file. Datasets are often (but don\u0026rsquo;t have to be) stored within groups in the file.  ii. Metadata HDF5 format is self describing. This means that each file, group and dataset can have associated metadata that describes exactly what the data are. One key benefit of having metadata that are attached to each file, group and dataset, is that this facilitates automation without the need for a separate (and additional) metadata document. Using a programming language, like R or Python, we can grab information from the metadata that are already associated with the dataset, and which we might need to process the dataset.\niii. Compressed \u0026amp; Subsetting The HDF5 format is a compressed format. The size of all data contained within HDF5 is optimized which makes the overall file size smaller. Even when compressed, however, HDF5 files often contain big data and can thus still be quite large. A powerful attribute of HDF5 is data slicing, by which a particular subsets of a dataset can be extracted for processing. This means that the entire dataset doesn\u0026rsquo;t have to be read into memory (RAM); very helpful in allowing us to more efficiently work with very large (gigabytes or more) datasets!\niv. Heterogeneous HDF5 files can store many different types of data within in the same file. For example, one group may contain a set of datasets to contain integer (numeric) and text (string) data. Or, one dataset can contain heterogeneous data types (e.g., both text and numeric data even images in one dataset).\nv. Summary Points  Self-Describing: The datasets with an HDF5 file are self describing. This allows us to efficiently extract metadata without needing an additional metadata document. Supporta Heterogeneous Data: Different types of datasets can be contained within one HDF5 file. Supports Large, Complex Data: HDF5 is a compressed format that is designed to support large, heterogeneous, and complex datasets. Supports Data Slicing: \u0026ldquo;Data slicing\u0026rdquo;, or extracting portions of the dataset as needed for analysis, means large files don\u0026rsquo;t need to be completely read into the computers memory or RAM.  h5py package We import the package h5py and then import the file using h5py.File function, remembering to use \u0026lsquo;r\u0026rsquo; in order to specify read only.\nYou can explore HDF5\u0026rsquo;s hierarchical structure as you would that of a Python dictionary using the method keys. Each of keys is an HDF group. You can think of these groups as directories too.\n1 2 3 4 5 6 7 8  import numpy as np import h5py file = \u0026#34;LIGO_data.hdf5\u0026#34; data = h5py.File(file, \u0026#34;r\u0026#34;) print(type(data)) for key in data.keys(): print(key)   \u0026lt;class 'h5py._hl.files.File'\u0026gt; meta quality strain 1 2 3 4 5 6 7 8 9 10 11 12 13  group = data[\u0026#39;strain\u0026#39;] for key in group.keys(): print(key) strain = data[\u0026#39;strain\u0026#39;][\u0026#39;Strain\u0026#39;].value num_samples = 10000 time = np.arange(0, 1, 1/num_samples) plt.plot(time, strain[:num_samples]) plt.xlabel(\u0026#39;GPS Time (s)\u0026#39;) plt.ylabel(\u0026#39;strain\u0026#39;) plt.show()   Strain 2.4 Importing MATLAB files The standard library scipy.io has functions loadmat and savemat, which allow us to read and write .mat files, respectively.\nA .mat file is simply a collection of many objects like strings, floats, vectors and arrays. This means when importing a .mat file in Python, we should expect to see a number of different variables and objects.\nWe first import scipy.io and then load the .mat file. Then a dictionary object results returns. How this dictionary relates to a MATLAB workspace is straightforward: the keys of the Python dictionary are the MATLAB variable names and the values of the Python dictionary are the objects that are assigned to the variables.\n1 2 3 4  import scipy.io mat = scipy.io.loadmat(\u0026#34;albeck_gene_expression.mat\u0026#34;) print(type(mat))   \u0026lt;class 'dict'\u0026gt; 1 2 3 4 5 6 7 8 9 10  print(mat.keys()) print(type(mat[\u0026#34;CYratioCyt\u0026#34;])) print(mat[\u0026#34;CYratioCyt\u0026#34;].shape) data = mat[\u0026#39;CYratioCyt\u0026#39;][25, 5:] fig = plt.figure() plt.plot(data) plt.xlabel(\u0026#39;time (min.)\u0026#39;) plt.ylabel(\u0026#39;normalized fluorescence (measure of expression)\u0026#39;) plt.show()   dict_keys(['__header__', '__version__', '__globals__', 'rfpCyt', 'rfpNuc', 'cfpNuc', 'cfpCyt', 'yfpNuc', 'yfpCyt', 'CYratioCyt']) \u0026lt;class 'numpy.ndarray'\u0026gt; (200, 137) 3. Relational databases in Python 3.1 Creating a database engine in Python Intro to Relational database Relational database is a type of database that is based upon the Relational model of data, first described by Ted Codd in the late 1960s.\nA database consists of tables. A table generally represents one entity type. Notice that the table looks a great deal like a dataframe. In a relational database table, each row or record represents an instance of the entity type. Each column represents an attribute of each instance. In this sense, a table is entirely analogous to a dataframe. It is essential that each row contain a unique identifier, known as a primary key, that we can use to explicitly access the row in question.\nThe really cool thing about relational databases is not merely that you have a bunch of tables, but that the tables are linked. Some column in a table corresponds precisely to the primary keys in other tables. This is cool because it means that you don\u0026rsquo;t need to store all the details in one table, it saves an incredible amount of space.\nBuild engine We\u0026rsquo;ll use an SQLite database as an example because SQLite is fast and simple while still containing enough functionality to introduce the necessary concepts of querying a database. There are many packages we could use to access an SQLite database such as sqlite3 and SQLAlchemy. We\u0026rsquo;ll use SQLAlchemy as it works with many other Relational Database Management Systems, such as Postgres and MySQL.\nTo connect to database, we need to import the relevant funtion create_engine from the package sqlalchemy. We then use the function create_engine to fire up an SQL engine that will communicate our queries to the database. The only required argument of create_engine is a string that indicates the type of database you\u0026rsquo;re connecting to and the name of the database.\n1 2 3  from sqlalchemy import create_engine engine = create_engine(\u0026#34;sqlite:///Chinook.sqlite\u0026#34;)   We would like to know the names of the tables it contains. To do this, apply the method table_names to the object engine. This will return a list of the table names.\n1 2 3 4 5  from sqlalchemy import create_engine engine = create_engine(\u0026#34;sqlite:///Chinook.sqlite\u0026#34;) table_names = engine.table_names() print(table_names)   ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track'] 3.2 Querying relational databases in Python The workflow of SQL querying will be as follows.\n import the required packages and functions; create the engine; Create the engine object using the function create_engine(). connect to it; To connect to the database after creating the engine, you create a connection object by applying the method connect( ) to the engine object. query the database ; To query the DB, apply the method execute() to the connection object and pass it the relevant SQL query. The query SELECT * FROM Table_Name, where Table_name is the name of any of the tables in the database, returns all columns of all rows of the Table of interest. save the results to a dataframe; query manipulation creates a sqlalchemy results object. To turn the results object into a dataframe, we apply the method fetchmany(size=None) or fetchall( ) to result object and save it as a dataframe using the pandas function DataFrame(). Don\u0026rsquo;t forget setting dataframe columns name by df.columns = rs.keys() close the connection. To close the connection, execute close() method on connection object.  1 2 3 4 5 6 7 8 9 10 11  from sqlalchemy import create_engine import pandas as pd # step 1. import package engine = create_engine(\u0026#39;sqlite:///Chinook.sqlite\u0026#39;) # step2. create engine con = engine.connect() # step3. create connection rs = con.execute(\u0026#34;select * from Album\u0026#34;) # step4. query df = pd.DataFrame(rs.fetchall()) # step5. save result  df.columns = rs.keys() con.close() # step6. close connection print(df.head())    AlbumId Title ArtistId 0 1 For Those About To Rock We Salute You 1 1 2 Balls to the Wall 2 2 3 Restless and Wild 2 3 4 Let There Be Rock 1 4 5 Big Ones 3 You can also leverage the context manager construct to open a connection, which will save you the trouble of closing the connection.\n1 2 3 4 5 6 7 8  engine = create_engine(\u0026#39;sqlite:///Chinook.sqlite\u0026#39;) with engine.connect() as con: rs = con.execute(\u0026#34;select LastName, Title from Employee\u0026#34;) df = pd.DataFrame(rs.fetchmany(size=3)) df.columns = rs.keys() print(len(df)) print(df.head())   3 LastName Title 0 Adams General Manager 1 Edwards Sales Manager 2 Peacock Sales Support Agent 1 2 3 4 5 6 7 8 9 10 11 12 13  def query_sql(dbtype, dbname, query): engine = create_engine(dbtype+\u0026#34;:///\u0026#34;+dbname) with engine.connect() as con: rs = engine.execute(query) df = pd.DataFrame(rs.fetchall()) df.columns = rs.keys() return df df = query_sql( dbtype=\u0026#34;sqlite\u0026#34;, dbname=\u0026#34;Chinook.sqlite\u0026#34;, query=\u0026#34;select * from Employee where ReportsTo=2.0 order by BirthDate\u0026#34; ) print(df.head())   FirstName Title ReportsTo ... Country PostalCode Phone Fax Email 0 4 Park Margaret Sales Support Agent 2 ... Canada T2P 5G3 +1 (403) 263-4423 +1 (403) 263-4289 margaret@chinookcorp.com 1 5 Johnson Steve Sales Support Agent 2 ... Canada T3B 1Y7 1 (780) 836-9987 1 (780) 836-9543 steve@chinookcorp.com 2 3 Peacock Jane Sales Support Agent 2 ... Canada T2P 5M5 +1 (403) 262-3443 +1 (403) 262-6712 jane@chinookcorp.com 3.3 Querying relational databases directly with pandas You can actually query datebase in 2 line, utilizing the pandas function read_sql_query and passing it 2 arguments. The first argument will be the query you wish to make, the 2nd argument the engine you want to connect to.\n1 2 3 4 5 6  from sqlalchemy import create_engine import pandas as pd engine = create_engine(\u0026#34;sqlite:///Chinook.sqlite\u0026#34;) df = pd.read_sql_query(\u0026#34;select * from Album\u0026#34;, engine) print(df.head())    AlbumId Title ArtistId 0 1 For Those About To Rock We Salute You 1 1 2 Balls to the Wall 2 2 3 Restless and Wild 2 3 4 Let There Be Rock 1 4 5 Big Ones 3 1 2 3 4 5 6 7 8  from sqlalchemy import create_engine import pandas as pd engine = create_engine(\u0026#34;sqlite:///Chinook.sqlite\u0026#34;) query = \u0026#34;select * from Employee where EmployeeId \u0026gt;= 6 order by BirthDate\u0026#34; df = pd.read_sql_query(query, engine) print(df.head())   EmployeeId LastName FirstName Title ReportsTo ... Country PostalCode Phone Fax Email 0 8 Callahan Laura IT Staff 6 ... Canada T1H 1Y8 +1 (403) 467-3351 +1 (403) 467-8772 laura@chinookcorp.com 1 7 King Robert IT Staff 6 ... Canada T1K 5N8 +1 (403) 456-9986 +1 (403) 456-8485 robert@chinookcorp.com 2 6 Mitchell Michael IT Manager 1 ... Canada T3B 0C5 +1 (403) 246-9887 +1 (403) 246-9899 michael@chinookcorp.com Recall SQL inner join syntax:\n1  select*fromtable1innerjointable2ontable1.col1=table2.col2  1 2 3 4 5 6  with engine.connect() as con: rs = con.execute(\u0026#34;select Title, Name from Album inner join Artist on Album.ArtistID=Artist.ArtistID\u0026#34;) df = pd.DataFrame(rs.fetchall()) df.columns = rs.keys() print(df.head())    Title Name 0 For Those About To Rock We Salute You AC/DC 1 Balls to the Wall Accept 2 Restless and Wild Accept 3 Let There Be Rock AC/DC 4 Big Ones Aerosmith 1 2 3 4 5 6  df = pd.read_sql_query( \u0026#34;select * from PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId where Milliseconds \u0026lt; 250000\u0026#34;, engine ) print(df.head())    PlaylistId TrackId TrackId Name AlbumId ... GenreId Composer Milliseconds Bytes UnitPrice 0 1 3390 3390 One and the Same 271 ... 23 None 217732 3559040 0.99 1 1 3392 3392 Until We Fall 271 ... 23 None 230758 3766605 0.99 2 1 3393 3393 Original Fire 271 ... 23 None 218916 3577821 0.99 3 1 3394 3394 Broken City 271 ... 23 None 228366 3728955 0.99 4 1 3395 3395 Somedays 271 ... 23 None 213831 3497176 0.99 ","date":"2020-04-26T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/importing-data-in-python-i/","title":"Importing Data in Python I"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n [toc]\nSeaborn Introduction Distribution plot The pandas library supports simple plotting of data, which is very convenient when data is already likely to be in a pandas DataFrame.\n1 2 3 4  df[\u0026#39;Award_Amount\u0026#39;].plot.hist() plt.show() plt.clf() # \u0026lt;-- Clear out the pandas histogram   Seaborn generally does more statistical analysis on data and can provide more sophisticated insight into the data. (v.s. the seaborn distplot.)\n1 2 3 4  sns.distplot(df[\u0026#39;Award_Amount\u0026#39;]) plt.show() plt.clf()   Now we will customize distribution plots in Seaborn. The Seaborn API supports customizing the type of plot by using different arguments. We can use the same distplot() function to create a standard histogram and customize the number of bins. Trying different combinations of the kde and rug lot can yield important insights.\n1 2 3 4 5  sns.distplot(df[\u0026#39;Award_Amount\u0026#39;], kde=False, # \u0026lt;-- Kernel Density Estimate curve, default True bins=20) plt.show()   There are many functions in Seaborn that build upon each other. The distplot() function we have been discussing relies on using additional Seaborn functions such as the kdeplot() and rugplot(). By understanding this relationship, you can further customize Seaborn plots by passing additional arguments to the underlying functions. For example, we can tell the underlying kde() function to shade the plot by passing the kde_kws dictionary.\n1 2 3 4 5 6  sns.distplot(df[\u0026#39;Award_Amount\u0026#39;], hist=False, rug=True, kde_kws={\u0026#39;shade\u0026#39;:True}) plt.show()   Regression Plots Now we will transition to another basic visualization process by plotting linear regression lines.\nThe regplot() function is the basis function for building regression plots in Seaborn. We explicitly define the x and y variables as well as the source of the data.\n1 2 3 4 5 6  sns.regplot( x=\u0026#34;insurance_losses\u0026#34;, y=\u0026#34;premiums\u0026#34;, data=df ) plt.show()    As mentioned earlier, you can turn off the confidence interval by setting argument ci =False.\n One of the confusing points about Seaborn is that it may seem like there is more than one way to do the same plot. We have looked at distplot() and briefly discussed kde() plots as a building block for the more robust distplot(). In a similar manner, the lower level regplot() and higher level lmplot() are related. You can specify hue or col (row) in lmplot() to visualize category regression plot.\n   lower level func higher level func     kde(), rug() distplot()   countplot(), \u0026hellip; catplot()   scatterplot, \u0026hellip; relplot()   regplot() lmplot()    1 2 3 4 5 6 7 8  sns.lmplot( x=\u0026#34;insurance_losses\u0026#34;, y=\u0026#34;premiums\u0026#34;, data=df, ci=False ) plt.show()   1 2 3 4 5 6  sns.lmplot(data=df, x=\u0026#34;insurance_losses\u0026#34;, y=\u0026#34;premiums\u0026#34;, hue=\u0026#34;Region\u0026#34;) plt.show()   1 2 3 4 5 6  sns.lmplot(data=df, x=\u0026#34;insurance_losses\u0026#34;, y=\u0026#34;premiums\u0026#34;, row=\u0026#34;Region\u0026#34;) plt.show()   Customizing Seaborn Plots Seaborn styles Seaborn has several default built in themes that are more appealing than the default matplotlib styles. In order to set a default theme, use the sns.set() function.\n1 2 3 4  sns.set() df[\u0026#39;fmr_2\u0026#39;].plot.hist() plt.show() plt.clf()   1 2 3 4 5  sns.set_style(\u0026#34;whitegrid\u0026#34;) sns.distplot(df[\u0026#34;fmr_2\u0026#34;]) plt.show() plt.clf()   A common use case is to remove the lines around the axes called spines. Seaborn\u0026rsquo;s despine() function removes one or more of the spines on a chart. The default is to remove the top and right lines but more can be removed by passing arguments to the despine() function.\n1 2 3 4 5 6 7 8  sns.set_style(\u0026#39;white\u0026#39;)= sns.lmplot(data=df, x=\u0026#39;pop2010\u0026#39;, y=\u0026#39;fmr_2\u0026#39;) sns.despine() plt.show() plt.clf()   Colors in Seaborn Since Seaborn is built on top of matplotlib, it is able to interpret and apply matplotlib color codes. By using the familiar sns.set() function with color_codes=True, any matplotlib color codes, like color='g', will be appropriately mapped to the Seaborn palette.\n1 2 3 4  sns.set(color_codes=True) sns.distplot(df[\u0026#39;fmr_3\u0026#39;], color=\u0026#39;m\u0026#39;) plt.show()   You can set a palette of colors that can be cycled through in a plot, which can be helpful when there are many items that must be encoded with color. Seaborn has six default palettes in sns.palettes.SEABORN_PALETTES including deep, muted, pastel, bright, dark, and colorblind. Seaborn offers several convenience functions for working with palettes:\n sns.set_palette() method set current palette. sns.color_palette(p) function return palette p\u0026rsquo;s (R,G,B) tuples (default return the current palette\u0026rsquo;s (R,G,B) tuples). The second parameter specifies how many colors the palette contains. sns.palplot() function display palette with (R,G,B) tuples (in a Jupyter notebook).  1 2 3 4 5 6 7 8  t=0 for p in sns.palettes.SEABORN_PALETTES: t += 1 sns.set_palette(p) print(p) print(sns.color_palette()) if t == 4: break   deep [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.8666666666666667, 0.5176470588235295, 0.3215686274509804), (0.3333333333333333, 0.6588235294117647, 0.40784313725490196), (0.7686274509803922, 0.3058823529411765, 0.3215686274509804), (0.5058823529411764, 0.4470588235294118, 0.7019607843137254), (0.5764705882352941, 0.47058823529411764, 0.3764705882352941), (0.8549019607843137, 0.5450980392156862, 0.7647058823529411), (0.5490196078431373, 0.5490196078431373, 0.5490196078431373), (0.8, 0.7254901960784313, 0.4549019607843137), (0.39215686274509803, 0.7098039215686275, 0.803921568627451)] deep6 [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.3333333333333333, 0.6588235294117647, 0.40784313725490196), (0.7686274509803922, 0.3058823529411765, 0.3215686274509804), (0.5058823529411764, 0.4470588235294118, 0.7019607843137254), (0.8, 0.7254901960784313, 0.4549019607843137), (0.39215686274509803, 0.7098039215686275, 0.803921568627451)] muted [(0.2823529411764706, 0.47058823529411764, 0.8156862745098039), (0.9333333333333333, 0.5215686274509804, 0.2901960784313726), (0.41568627450980394, 0.8, 0.39215686274509803), (0.8392156862745098, 0.37254901960784315, 0.37254901960784315), (0.5843137254901961, 0.4235294117647059, 0.7058823529411765), (0.5490196078431373, 0.3803921568627451, 0.23529411764705882), (0.8627450980392157, 0.49411764705882355, 0.7529411764705882), (0.4745098039215686, 0.4745098039215686, 0.4745098039215686), (0.8352941176470589, 0.7333333333333333, 0.403921568627451), (0.5098039215686274, 0.7764705882352941, 0.8862745098039215)] muted6 [(0.2823529411764706, 0.47058823529411764, 0.8156862745098039), (0.41568627450980394, 0.8, 0.39215686274509803), (0.8392156862745098, 0.37254901960784315, 0.37254901960784315), (0.5843137254901961, 0.4235294117647059, 0.7058823529411765), (0.8352941176470589, 0.7333333333333333, 0.403921568627451), (0.5098039215686274, 0.7764705882352941, 0.8862745098039215)] 1 2 3 4 5 6 7 8 9  t=0 for p in sns.palettes.SEABORN_PALETTES: t += 1 sns.set_palette(p) print(p) sns.palplot(sns.color_palette()) plt.show() if t == 4: break   1 2 3 4  sns.palplot( sns.color_palette(\u0026#34;Purples\u0026#34;, 8) ) plt.show()   There are three main types of color palettes.\n Circular color palettes are used for categorical data that is not ordered. Sequential palettes are useful when the data has a consistent range from high to low values. Diverging color palette is best used when both the high and the low values are interesting.  1 2 3 4  cp = [\u0026#34;Paired\u0026#34;, \u0026#34;Blues\u0026#34;, \u0026#34;BrBG\u0026#34;] for i in cp: print(i) print(sns.color_palette(i))   Paired [(0.6509803921568628, 0.807843137254902, 0.8901960784313725), (0.12156862745098039, 0.47058823529411764, 0.7058823529411765), (0.6980392156862745, 0.8745098039215686, 0.5411764705882353), (0.2, 0.6274509803921569, 0.17254901960784313), (0.984313725490196, 0.6039215686274509, 0.6), (0.8901960784313725, 0.10196078431372549, 0.10980392156862745), (0.9921568627450981, 0.7490196078431373, 0.43529411764705883), (1.0, 0.4980392156862745, 0.0), (0.792156862745098, 0.6980392156862745, 0.8392156862745098), (0.41568627450980394, 0.23921568627450981, 0.6039215686274509), (1.0, 1.0, 0.6), (0.6941176470588235, 0.34901960784313724, 0.1568627450980392)] Blues [(0.8584083044982699, 0.9134486735870818, 0.9645674740484429), (0.7309496347558632, 0.8394771241830065, 0.9213225682429834), (0.5356862745098039, 0.746082276047674, 0.8642522106881968), (0.32628988850442137, 0.6186236063052672, 0.802798923490965), (0.16696655132641292, 0.48069204152249134, 0.7291503267973857), (0.044059976931949255, 0.3338869665513264, 0.6244521337946944)] BrBG [(0.6313725490196078, 0.3951557093425605, 0.09573241061130335), (0.8572856593617839, 0.7257977700884274, 0.4471357170319107), (0.9636293733179546, 0.9237985390234525, 0.8185313341022683), (0.8299115724721262, 0.9294886582083814, 0.9152633602460593), (0.4615916955017304, 0.7748558246828146, 0.7299500192233758), (0.0878892733564014, 0.479123414071511, 0.44775086505190315)] 1 2 3 4 5  cp = [\u0026#34;Paired\u0026#34;, \u0026#34;Blues\u0026#34;, \u0026#34;BrBG\u0026#34;] for i in cp: print(i) sns.palplot(sns.color_palette(i)) plt.show()   Customizing with matplotlib Since Seaborn is based on matplotlib, there is a wide variety of options for further modifying your Seaborn plots. By using matplotlib\u0026rsquo;s axes objects, you can customize almost any element of your plot.\nThe most important concept is to add additional code to create the subplots using matplotlib\u0026rsquo;s plt.subplots() functions and pass the resulting axes object to the Seaborn function. Seaborn will then plot the data on the given axes.\n1 2 3 4 5 6 7 8 9 10 11  fig, ax = plt.subplots() sns.set_palette(\u0026#34;Reds\u0026#34;) sns.distplot(df[\u0026#39;fmr_3\u0026#39;], ax=ax) ax.set( xlabel=\u0026#34;3 Bedroom Fair Market Rent\u0026#34;, ylabel=\u0026#34;rate\u0026#34;, xlim=(0,4000), title=\u0026#34;Title\u0026#34; ) plt.show()   You can use ax.axvline() or ax.axhline() to create a line in the plot, and then call ax.legned() to show it.\n1 2 3 4 5 6 7 8 9 10  fig, ax = plt.subplots() sns.distplot(df[\u0026#39;fmr_1\u0026#39;], ax=ax) ax.set(xlabel=\u0026#34;1 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500), title=\u0026#34;US Rent\u0026#34;) ax.axvline(x=df[\u0026#39;fmr_1\u0026#39;].median(), color=\u0026#39;g\u0026#39;, label=\u0026#39;Median\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=2) ax.axvline(x=df[\u0026#39;fmr_1\u0026#39;].mean(), color=\u0026#39;r\u0026#39;, label=\u0026#39;Mean\u0026#39;, linestyle=\u0026#39;-\u0026#39;, linewidth=2) ax.axhline(y=0.002, color=\u0026#39;b\u0026#39;, label=\u0026#39;y*\u0026#39;, linestyle=\u0026#39;:\u0026#39;, linewidth=2) ax.legend() plt.show()   1 2 3 4 5 6 7 8  fig, ax = plt.subplots() sns.set(color_codes=True) sns.distplot(df[\u0026#39;fmr_1\u0026#39;], ax=ax, color=\u0026#34;r\u0026#34;) sns.distplot(df[\u0026#39;fmr_2\u0026#39;], ax=ax, color=\u0026#34;c\u0026#34;) ax.set(xlabel=\u0026#34;1 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500)) plt.show()   1 2 3 4 5 6 7 8 9  fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True) # \u0026lt;-- Make the Y-axis of the two subgraphs consistent sns.distplot(df[\u0026#39;fmr_1\u0026#39;], ax=ax0) ax0.set(xlabel=\u0026#34;1 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500)) sns.distplot(df[\u0026#39;fmr_2\u0026#39;], ax=ax1) ax1.set(xlabel=\u0026#34;2 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500)) plt.show()   You can also make this by\n1 2 3 4 5 6 7 8 9  fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True) sns.distplot(df[\u0026#39;fmr_1\u0026#39;], ax=ax[0]) ax[0].set(xlabel=\u0026#34;1 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500)) sns.distplot(df[\u0026#39;fmr_2\u0026#39;], ax=ax[1]) ax[1].set(xlabel=\u0026#34;2 Bedroom Fair Market Rent\u0026#34;, xlim=(100,1500)) plt.show()   Additional Plot Types Categorical Plot Types Seaborn supports many plot types with categorical data. Seaborn breaks categorical data plots into three groups.\n  The first group includes the stripplot() and swarmplot(), which show all the individual observations on the plot.\n  The second category contains the boxplot(), as well as the violinplot() and lvplot(). These plots show an abstract representation of the categorical data.\n  The final group of plots show statistical estimates of the categorical variables. The barplot() and pointplot() contain useful summaries of data. The countplot() shows the number of instances of each observation.\n  stripplot( ) shows every observation in the dataset. Sometimes, the data\u0026rsquo;s distribution is too busy, and we can set parameters jitter = True to scatter data rather than gather it in a single line.\n1 2 3 4 5  sns.stripplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;,) plt.show()   1 2 3 4 5 6  sns.stripplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;, jitter=True) plt.show()   We can plot a more sophisticated visualization of all the data using a swarmplot( ). This plot uses a complex algorithm to place the observations in a manner where they do not overlap. swarmplot() does not scale well to large datasets.\n1 2 3 4 5 6  sns.swarmplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;, hue=\u0026#39;Region\u0026#39;) plt.show()   boxplot( ) is the most common plots show abstract representations of the data. This plot is used to show several measures related to the distribution of data, including the median, upper and lower quartiles, as well as outliers.\n1 2 3 4 5 6  sns.boxplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;) plt.show() plt.clf()   The violinplot( ) is a combination of a kernel density plot and a box plot and can be suitable for providing an alternative view of the distribution of data.\n1 2 3 4 5 6 7  sns.violinplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;, palette=\u0026#39;husl\u0026#39;) plt.show() plt.clf()   lvplot() stands for Letter Value plot. The API is the same as the boxplot() and violinplot() but can scale more effectively to large datasets.\n1 2 3 4 5 6 7 8  sns.lvplot(data=df, x=\u0026#39;Award_Amount\u0026#39;, y=\u0026#39;Model Selected\u0026#39;, palette=\u0026#39;Paired\u0026#39;, hue=\u0026#39;Region\u0026#39;) plt.show() plt.clf()   The barplot( ) shows an estimate of the value as well as a confidence interval. The pointplot( ) is similar to the barplot() in that it shows a summary measure and confidence interval. the countplot( ) displays the number of instances of each variable.\nRegression Plots regplot( ), like most of the Seaborn functions we have reviewed, requires the definition of the data and the x and y variables and you include a marker for the observations by setting marker=\u0026quot;+\u0026quot;. If a value greater than 1 is passed to the order parameter of regplot(), then Seaborn will attempt a polynomial fit using underlying NumPy functions.\nThe residplot( ) plot is a very useful plot for understanding the appropriateness of a regression model. Ideally, the residual values in the plot should be plotted randomly across the horizontal line.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  fig, ax = plt.subplots(nrows=1, ncols=2) sns.regplot(data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;SAT_AVG_ALL\u0026#34;, marker=\u0026#39;^\u0026#39;, color=\u0026#39;g\u0026#39;, ax=ax[0]) ax[0].set(title=\u0026#34;Regression plot\u0026#34;) sns.residplot(data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;SAT_AVG_ALL\u0026#34;, color=\u0026#39;g\u0026#39;, ax=ax[1]) ax[1].set(title=\u0026#34;Residual plot\u0026#34;) plt.show()   Seaborn also supports regression plots with categorical variables. you can use the jitter parameter makes it easier to see the individual distribution of the categorical variable. In some cases, even with the jitter, it may be difficult to see if there are any trends based on the value of the variable. Using an x_estimator=func for the x value can apply this function to each unique value of x and plot the resulting estimate.\nWhen there are continuous variables, it can be helpful to break them into different bins by setting parameter x_bins. When this parameter is used, it implies that the default of x_estimator is numpy.mean.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  fig, ax = plt.subplots(nrows=2, ncols=2) sns.regplot( data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;PCTPELL\u0026#34;, ax=ax[0][0] ) sns.regplot( data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;PCTPELL\u0026#34;, x_bins=5, ax=ax[0][1] ) sns.regplot( data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;PCTPELL\u0026#34;, x_bins=5, order=2, ax=ax[1][0] ) sns.residplot( data=df, y=\u0026#39;Tuition\u0026#39;, x=\u0026#34;PCTPELL\u0026#34;, order=2, ax=ax[1][1] ) ax[0][0].set(title=\u0026#34;Reg plot\u0026#34;) ax[0][1].set(title=\u0026#34;Reg bins plot\u0026#34;) ax[1][0].set(title=\u0026#34;2 orders Reg bins plot\u0026#34;) ax[1][1].set(title=\u0026#34;2 orders Resid plot\u0026#34;) plt.show()   Matrix plots Seaborn\u0026rsquo;s heatmap( ) function expects the data to be in a matrix. You can use pd.crosstab() or pd.pivot_table() to create this matirx.\n pd.crosstab(s1, s2) is a special kind of pd.pivot_table, it is a shortcut to count the number of (s1_i, s2_j).\n The display of the heatmap can be customized in multiple ways to present the most information as clearly as possible. First, we use annot equals True to turn on annotations in the individual cells. The fmt=d ensures that the results are displayed as integers. Next, we use a custom cmap to change the shading we use. By setting cbar equals False, the color bar is not displayed. we can use center to center the colormap at the value we want. Finally, passing a variable to linewidths puts some small spacing between the cells so that the values are simpler to view.\n1 2 3 4 5 6 7 8 9  pd_crosstab = pd.crosstab(df[\u0026#34;Group\u0026#34;], df[\u0026#34;YEAR\u0026#34;]) sns.heatmap(pd_crosstab, cbar=True, cmap=\u0026#34;BuGn\u0026#34;, linewidths=0.3, annot=True) plt.yticks(rotation=0) plt.xticks(rotation=90) plt.show() plt.clf()   One common usage for a heatmap is to visually represent the correlation between variables. pandas DataFrames have a corr() function that calculates the correlation between the values in the columns. The output of this function is ideally structured to be displayed as a heatmap.\nCreating Plots on Data Aware Grids FacetGrid, factorplot and lmplot One of Seaborn\u0026rsquo;s most powerful features is its ability to combine multiple smaller plots into a larger visualization that can help identify trends in data with many variables.\n One very important requirement for Seaborn to create these plots is that the data must be in tidy format. This means that each row of the data is a single observation and the columns contain the variables.\n There are two step processes to use FacetGrid( ) make multi subplots.\n Call sns.FacetGrid() to initialize the grid axes.  1 2 3 4 5 6 7 8  g = sns.FacetGrid( data, row=None, col=None, hue=None, palette=None, row_order=None, col_order=None, hue_order=None, hue_kws=None, col_wrap=None, sharex=True, sharey=True, height=3, aspect=1, dropna=True, legend_out=True, despine=True, margin_titles=False, xlim=None, ylim=None, subplot_kws=None, gridspec_kws=None, size=None )    Call g.map() to specify plot type, data, color and style.  1 2 3 4 5  # single variable plot g.map(plt.hist, \u0026#34;total_bill\u0026#34;, bins=bins, color=\u0026#34;r\u0026#34;) # double variables plot g.map(plt.scatter, \u0026#34;total_bill\u0026#34;, \u0026#34;tip\u0026#34;, edgecolor=\u0026#34;w\u0026#34;, marker=\u0026#34;.\u0026#34;)    1 2 3 4 5 6 7 8 9 10 11  g2 = sns.FacetGrid( df, row=\u0026#34;Degree_Type\u0026#34;, row_order=[ \u0026#39;Graduate\u0026#39;, \u0026#39;Bachelors\u0026#39;, \u0026#39;Associates\u0026#39;, \u0026#39;Certificate\u0026#39; ] ) g2.map(sns.pointplot, \u0026#39;SAT_AVG_ALL\u0026#39;) plt.show() plt.clf()   Seaborn\u0026rsquo;s FacetGrid() is very powerful and flexible but involves multiple steps to create. The factorplot() function returned value is also a FacetGrid but the process for creating one is much simpler.\n1 2 3 4 5 6 7 8  sns.factorplot(data=df, x=\u0026#39;SAT_AVG_ALL\u0026#39;, kind=\u0026#39;point\u0026#39;, row=\u0026#39;Degree_Type\u0026#39;, row_order=[\u0026#39;Graduate\u0026#39;, \u0026#39;Bachelors\u0026#39;, \u0026#39;Associates\u0026#39;, \u0026#39;Certificate\u0026#39;]) plt.show() plt.clf()   1 2 3 4 5 6 7  sns.factorplot(data=df, x=\u0026#39;Tuition\u0026#39;, kind=\u0026#39;box\u0026#39;, row=\u0026#39;Degree_Type\u0026#39;) plt.show() plt.clf()   1 2 3 4 5 6 7 8  seaborn.lmplot( x, y, data, hue=None, col=None, row=None, palette=None, hue_order=None, col_order=None, row_order=None, col_wrap=None, height=5, aspect=1, markers=\u0026#39;o\u0026#39;, sharex=True, sharey=True, legend=True, legend_out=True, x_estimator=None, x_bins=None, x_ci=\u0026#39;ci\u0026#39;, scatter=True, fit_reg=True, ci=95, n_boot=1000, units=None, order=1, logistic=False, lowess=False, robust=False, logx=False, x_partial=None, y_partial=None, truncate=False, x_jitter=None, y_jitter=None, scatter_kws=None, line_kws=None, size=None )   The lmplot( ) function combines regplot() and FacetGrid. It is intended as a convenient interface to fit regression models across conditional subsets of a dataset. When thinking about how to assign variables to different facets, a general rule is that it makes sense to use hue for the most important comparison, followed by col and row.\n1 2 3 4 5 6 7 8 9 10 11  g = sns.FacetGrid( df, col=\u0026#34;Ownership\u0026#34;, row=\u0026#39;Degree_Type\u0026#39;, row_order=[\u0026#39;Graduate\u0026#39;, \u0026#39;Bachelors\u0026#39;], hue=\u0026#39;WOMENONLY\u0026#39;, col_order=inst_ord ) g.map(plt.scatter, \u0026#39;SAT_AVG_ALL\u0026#39;, \u0026#34;Tuition\u0026#34;) plt.show() plt.clf()   1 2 3 4 5 6 7 8 9 10 11  sns.lmplot(data=df, x=\u0026#39;SAT_AVG_ALL\u0026#39;, y=\u0026#39;Tuition\u0026#39;, col=\u0026#34;Ownership\u0026#34;, row=\u0026#39;Degree_Type\u0026#39;, row_order=[\u0026#39;Graduate\u0026#39;, \u0026#39;Bachelors\u0026#39;], hue=\u0026#39;WOMENONLY\u0026#39;, col_order=inst_ord) plt.show() plt.clf()    Notice, factorplot(), lmplot(), relplot(), catplot().\n PairGrid and pairplot 1 2 3 4 5 6  PairGrid( data, hue=None, hue_order=None, palette=None, hue_kws=None, vars=None, x_vars=None, y_vars=None, diag_sharey=True, height=2.5, aspect=1, despine=True, dropna=True, size=None )   PairGrid and pairplot are similar to the FacetGrid, factorplot, and lmplots, exercise because they allow us to see interactions across different columns of data.\nThe PairGrid plot allows us to build plots that show the relationships between two data elements. The process for creating a PairGrid is similar to a FacetGrid in that we must create the grid.Notice that we define the variables instead of the row and column parameters. Three cases:\n seaborn will create row and column respectively for each of variable you specify in vars arguments. seaborn will create row for variable you specify in x_vars arguments, and column for variable in y_vars arguments. seaborn will create row and column respectively for each of volumns in the dateframe if you don\u0026rsquo;t specify vars argument.  Then map a plot type to the grid. You can use the map_diag() function to define the plotting function for the main diagonal. The map_offdiag() function defines the other diagonal.\n1 2 3 4 5 6 7 8  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) g = sns.PairGrid(iris, hue=\u0026#34;species\u0026#34;) g.map_diag(plt.hist, histtype=\u0026#34;step\u0026#34;) g.map_offdiag(plt.scatter) g.add_legend() plt.show() plt.clf()   you can also use map_upper(), map_lower() to specify different plot type on the both sides of the diagonal.\n1 2 3 4 5 6 7 8  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) g = sns.PairGrid(iris) g.map_upper(plt.scatter) g.map_lower(sns.kdeplot, cmap=\u0026#34;Blues_d\u0026#34;) g.map_diag(sns.kdeplot) plt.show() plt.clf()   1 2 3 4 5 6 7  seaborn.pairplot( data, hue=None, hue_order=None, palette=None, vars=None, x_vars=None, y_vars=None, kind=\u0026#39;scatter\u0026#39;, diag_kind=\u0026#39;auto\u0026#39;, markers=None, height=2.5, aspect=1, dropna=True, plot_kws=None, diag_kws=None, grid_kws=None, size=None )   Pairplot is a high-level interface for PairGrid that is intended to make it easy to draw a few common styles. You should use PairGrid directly if you need more flexibility. Two arguments:\n kind：{‘scatter’, ‘reg’}, optional Kind of plot for the non-identity relationships. diag_kind：{‘auto’, ‘hist’, ‘kde’}, optional Kind of plot for the diagonal subplots.  1 2 3 4 5 6 7 8 9 10 11 12 13  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) sns.pairplot( iris, hue=\u0026#34;species\u0026#34;, palette=\u0026#34;husl\u0026#34;, markers=[\u0026#34;o\u0026#34;, \u0026#34;+\u0026#34;, \u0026#34;v\u0026#34;], diag_kind=\u0026#34;kde\u0026#34;, diag_kws={\u0026#39;alpha\u0026#39;:.5, \u0026#34;shade\u0026#34;:True}, kind=\u0026#34;reg\u0026#34; ) plt.show() plt.clf()   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  sns.pairplot( data=df, vars=[\u0026#34;insurance_losses\u0026#34;, \u0026#34;premiums\u0026#34;], kind=\u0026#39;reg\u0026#39;, palette=\u0026#39;BrBG\u0026#39;, diag_kind = \u0026#39;kde\u0026#39;, diag_kws={ \u0026#34;shade\u0026#34;:True, \u0026#34;alpha\u0026#34;:.5 }, hue=\u0026#39;Region\u0026#39; ) plt.show() plt.clf()   JointGrid and jointplot 1 2 3 4 5  seaborn.JointGrid( x, y, data=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, size=None )   JoinGrid creates grid for drawing a bivariate plot with marginal univariate plots. Initialize the figure but don’t draw any plots onto it:\n1 2 3 4 5  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) g = sns.JointGrid(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips) plt.show() plt.clf()   Add plots using default parameters:\n1 2 3 4 5 6  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) g = sns.JointGrid(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips) g.plot(sns.regplot, sns.distplot) plt.show() plt.clf()   Draw the join and marginal plots separately:\n1 2 3 4 5 6 7 8  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) g = sns.JointGrid(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips) g.plot_joint(plt.scatter, color=\u0026#34;.5\u0026#34;, edgecolor=\u0026#34;white\u0026#34;) g.plot_marginals(sns.distplot, kde=False, color=\u0026#34;.5\u0026#34;) plt.show() plt.clf()   or\n1 2 3 4 5 6 7 8 9 10 11  import numpy as np tips = sns.load_dataset(\u0026#34;tips\u0026#34;) g = sns.JointGrid(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips) g.plot_joint(plt.scatter, color=\u0026#34;m\u0026#34;, edgecolor=\u0026#34;white\u0026#34;) g.ax_marg_x.hist(tips[\u0026#34;total_bill\u0026#34;], color=\u0026#34;b\u0026#34;, alpha=.6, bins=np.arange(0, 60, 4)) g.ax_marg_y.hist(tips[\u0026#34;tip\u0026#34;], color=\u0026#34;r\u0026#34;, alpha=.6, orientation=\u0026#34;horizontal\u0026#34;, bins=np.arange(0, 12, .5)) plt.show() plt.clf()   Add an annotation with a statistic summarizing the bivariate relationship:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  from scipy import stats tips = sns.load_dataset(\u0026#34;tips\u0026#34;) g = sns.JointGrid(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips) g.plot_joint(plt.scatter) g.plot_marginals(sns.kdeplot, shade=True) rsquare = lambda a, b: stats.pearsonr(a, b)[0] ** 2 g.annotate( rsquare, template=\u0026#34;{stat}: {val:.2f}\u0026#34;, stat=\u0026#34;$R^2$\u0026#34;, loc=\u0026#34;upper left\u0026#34;, fontsize=12 ) plt.show() plt.clf()    1 2 3 4 5 6 7  seaborn.jointplot( x, y, data=None, kind=\u0026#39;scatter\u0026#39;, stat_func=None, color=None, height=6, ratio=5, space=0.2, dropna=True, xlim=None, ylim=None, joint_kws=None, marginal_kws=None, annot_kws=None, **kwargs )   jointplot( ) function provides a convenient interface to the JointGrid class, with several canned plot kinds. This is intended to be a fairly lightweight wrapper; if you need more flexibility, you should use JointGrid directly.\nDraw a default jointplot, i.e. scatterplot with marginal histograms:\n1 2  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) sns.jointplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips)   Add (3 order) regression and kernel density fits\n1 2 3 4 5 6 7 8 9 10 11 12  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) sns.jointplot( \u0026#34;total_bill\u0026#34;, \u0026#34;tip\u0026#34;, data=tips, kind=\u0026#34;reg\u0026#34;, order=3, xlim=(0,50) ) plt.show() plt.clf()   the corresponding residual plot:\n1 2 3 4 5 6 7 8 9 10 11 12  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) sns.jointplot( \u0026#34;total_bill\u0026#34;, \u0026#34;tip\u0026#34;, data=tips, kind=\u0026#34;resid\u0026#34;, order=3, xlim=(0,50) ) plt.show() plt.clf()   Replace the scatterplot with a joint histogram using hexagonal bins:\n1 2 3 4 5  tips = sns.load_dataset(\u0026#34;tips\u0026#34;) sns.jointplot(\u0026#34;total_bill\u0026#34;, \u0026#34;tip\u0026#34;, data=tips, kind=\u0026#34;hex\u0026#34;) plt.show() plt.clf()   Replace the scatterplots and histograms with density estimates and align the marginal Axes tightly with the joint Axes:\n1 2 3 4 5  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) sns.jointplot(\u0026#34;sepal_width\u0026#34;, \u0026#34;petal_length\u0026#34;, data=iris, kind=\u0026#34;kde\u0026#34;, space=0, color=\u0026#34;g\u0026#34;) plt.show() plt.clf()   Draw a scatterplot, then add a joint density estimate:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) ( sns.jointplot( \u0026#34;sepal_length\u0026#34;, \u0026#34;sepal_width\u0026#34;, data=iris, color=\u0026#34;b\u0026#34;, kind=\u0026#34;scatter\u0026#34; ).plot_joint( sns.kdeplot, n_levels=10, cmap=\u0026#34;RdBu\u0026#34; ) ) plt.show() plt.clf()   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  iris = sns.load_dataset(\u0026#34;iris\u0026#34;) (sns.jointplot( \u0026#34;sepal_length\u0026#34;, \u0026#34;sepal_width\u0026#34;, data=iris, color=\u0026#34;b\u0026#34;, kind=\u0026#34;kde\u0026#34; ).plot_joint( sns.kdeplot, n_levels=10, cmap=\u0026#34;RdBu\u0026#34; ) ) plt.show() plt.clf()      Grid class high-level function     FacetGrid factorplot(), lmplot(), relplot(), catplot()   PairGrid pairplot   JointGrid jointplot, jointplot.plot_joint    Union Frame The final section of this blog will bring all of the concepts together and give a framework for deciding when to use each Seaborn plot.\nUnivariate Distribution Analysis One of the first steps in analyzing numerical data is looking at its distribution. Seaborn\u0026rsquo;s distplot() combines many of the features of the rugplot(), kdeplot(), and plt.histplot() into a single function. The distplot() function is the best place to start when trying to do distribution analysis with Seaborn.\nRegression Analysis A regression plot is an example of a plot that shows the relationship between two variables. matplotlib\u0026rsquo;s scatter() plot is a very simple method to compare the interaction of two variables on the x and y-axis. The lmplot() combines many of these features of the underlying regplot() and residplot() in addition to the ability to plot the data on a FacetGrid(). In many instances, lmplot() is the best function to use for determining linear relationships between data.\nCategorical Plots Seaborn has many types of categorical plots as well. In most scenarios, it makes sense to use one of the categorical plots such as the boxplot() or violinplot() to examine the distribution of the variables. Then, follow up with the statistical estimation plots such as the point, bar, or countplot. If you need to facet the data across rows or columns, use a factorplot().\nRelation The pairplot() and jointplot() visualizations are going to be most useful after you have done some preliminary analysis of regressions or distributions of the data. Once you are familiar with the data, the pairplot() and jointplot() can be very useful in understanding how two or more variables interact with each other.\n","date":"2020-04-23T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/data-visualization-iii-seaborn/","title":"Data Visualization III (Seaborn)"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n [toc]\nIntroduction to Seaborn Using pandas with Seaborn 1 2 3  # Import Matplotlib and Seaborn import matplotlib.pyplot as plt import seaborn as sns   To create a count plot with a pandas DataFrame column instead of a list of data, set x (or y) equal to the name of the column in the DataFrame. Then, we\u0026rsquo;ll set the data parameter equal to DataFrame. Finally calling \u0026ldquo;plt.show()\u0026rdquo;.\n1 2 3 4 5 6  df = pd.read_csv(\u0026#34;xxxx.csv\u0026#34;) sns.countplot( x=\u0026#34;Spiders\u0026#34;, # column name data=df ) plt.show()    Notice that because we\u0026rsquo;re using a named column in the DataFrame, Seaborn automatically adds the name of the column as the x-axis label at the bottom.\n Adding a third variable with hue we\u0026rsquo;ll be using Seaborn\u0026rsquo;s built-in tips dataset. You can access it by using the \u0026ldquo;load_dataset\u0026rdquo; function in Seaborn and passing in the name of the dataset. These are the first five rows of the tips dataset.\n1 2  df=sns.load_dataset(\u0026#34;tips\u0026#34;) df.head()    total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 Let\u0026rsquo;s explore the relationship between the \u0026ldquo;total_bill\u0026rdquo; and \u0026ldquo;tip\u0026rdquo; columns using a scatter plot.\n1 2 3 4 5 6  sns.scatterplot( x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=df, ) plt.show()   If you want to add a third variable to plots by adding color, you can set the \u0026ldquo;hue\u0026rdquo; parameter equal to the DataFrame column name or a list, and then Seaborn will automatically color each point by groups.\n1 2 3 4 5 6 7  sns.scatterplot( x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=df, ) plt.show()   The \u0026ldquo;hue_order\u0026rdquo; parameter takes in a list of values and will set the order of the values in the plot accordingly. You can control the colors assigned to each value using the \u0026ldquo;palette\u0026rdquo; parameter. This parameter takes in a dictionary. This dictionary should map the variable values to the colors you want to represent the value.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  hc = { \u0026#34;Yes\u0026#34;: \u0026#34;c\u0026#34;, \u0026#34;No\u0026#34;: \u0026#34;g\u0026#34; } sns.scatterplot( x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=df, hue_order=[\u0026#34;No\u0026#34;, \u0026#34;Yes\u0026#34;], palette=hc ) plt.show()   Here is the list of Matplotlib colors and their names. Note that you can use a single-letter Matplotlib abbreviation instead of the full name.\nhue is available in most of Seaborn\u0026rsquo;s plot types. For example, countplot\n1 2 3 4 5 6 7 8 9 10  palette_colors = {\u0026#34;Rural\u0026#34;: \u0026#34;green\u0026#34;, \u0026#34;Urban\u0026#34;: \u0026#34;blue\u0026#34;} sns.countplot( x=\u0026#34;school\u0026#34;, data=student_data, hue=\u0026#34;location\u0026#34;, palette=palette_colors ) plt.show()    The other way to add the third variable into a plot is calling arguments col or row in sns.relplot() or sns.catplot() method.\n Relational Plot relational plots and subplots Sometimes we suspect that the relationship may be different within certain subgroups. In the last chapter, we started to look at subgroups by using the \u0026ldquo;hue\u0026rdquo; parameter to visualize each subgroup using a different color on the same plot.\nNow we\u0026rsquo;ll try out a different method relplot() (relationship plot) to creat a separate plot per subgroup. We call the \u0026ldquo;relplot()\u0026rdquo; method and use the \u0026ldquo;kind\u0026rdquo; parameter to specify what kind of relational plot to use - scatter plot or line plot.\nBy setting \u0026ldquo;col\u0026rdquo; equal to \u0026ldquo;smoker\u0026rdquo;, we get a separate scatter plot groups by \u0026ldquo;smoker\u0026rdquo;, arranged horizontally in columns. You can use the \u0026ldquo;col_wrap\u0026rdquo; parameter to specify how many subplots you want per row. If you want to arrange these vertically in rows instead, you can use the \u0026ldquo;row\u0026rdquo; parameter instead of \u0026ldquo;col\u0026rdquo;. We can also change the order of the subplots by using the \u0026ldquo;col_order\u0026rdquo; and \u0026ldquo;row_order\u0026rdquo; parameters and giving it a list of ordered values.\n1 2 3 4 5 6 7 8 9 10  sns.relplot( x=\u0026#34;G1\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;scatter\u0026#34;, col=\u0026#34;schoolsup\u0026#34;, col_order=[\u0026#34;yes\u0026#34;, \u0026#34;no\u0026#34;] ) plt.show()   1 2 3 4 5 6 7 8 9  sns.relplot( x=\u0026#34;absences\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;scatter\u0026#34;, row=\u0026#34;study_time\u0026#34; ) plt.show()   It is possible to use both \u0026ldquo;col\u0026rdquo; and \u0026ldquo;row\u0026rdquo; at the same time. Here, we set \u0026ldquo;col\u0026rdquo; equal to smoking status and \u0026ldquo;row\u0026rdquo; equal to the time of day (lunch or dinner). Now we have a subplot for each combination of these two categorical variables.\n1 2 3 4 5 6 7 8 9 10 11 12  sns.relplot( x=\u0026#34;G1\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;scatter\u0026#34;, col=\u0026#34;schoolsup\u0026#34;, col_order=[\u0026#34;yes\u0026#34;, \u0026#34;no\u0026#34;], row=\u0026#34;famsup\u0026#34;, row_order=[\u0026#39;yes\u0026#39;, \u0026#39;no\u0026#39;] ) plt.show()   Customizing scatter plots Seaborn allows you to add more information to scatter plots by varying the size, the style, and the transparency of the points.\n All of these options can be used in both the \u0026ldquo;scatterplot()\u0026rdquo; and \u0026ldquo;relplot()\u0026rdquo; functions, but we\u0026rsquo;ll continue to use \u0026ldquo;relplot()\u0026rdquo; since it\u0026rsquo;s more flexible and allows us to create subplots.\n We want each point on the scatter plot to be sized based on the number of variable with larger number having bigger points on the plot. To do this, we\u0026rsquo;ll set the \u0026ldquo;size\u0026rdquo; parameter equal to the variable name from the dataset.\nWe can make it easier by using the \u0026ldquo;size\u0026rdquo; parameter in combination with the \u0026ldquo;hue\u0026rdquo; parameter. To do this, set \u0026ldquo;hue\u0026rdquo; equal to the variable name.\n1 2 3 4 5 6 7 8 9 10  sns.relplot( x=\u0026#34;horsepower\u0026#34;, y=\u0026#34;mpg\u0026#34;, data=mpg, kind=\u0026#34;scatter\u0026#34;, size=\u0026#34;cylinders\u0026#34;, hue=\u0026#34;cylinders\u0026#34; ) plt.show()    Notice that because \u0026ldquo;size\u0026rdquo; is a quantitative variable, Seaborn will automatically color the points the same color with different depth, instead of different colors per category value like we saw in previous plots.\n We use \u0026ldquo;hue\u0026rdquo; to create different colored points based on groups. Setting \u0026ldquo;style\u0026rdquo; equal to allows us to better distinguish these subgroups by plotting points with a different point style in addition to a different color.\n1 2 3 4 5 6 7 8 9 10  sns.relplot( x=\u0026#34;acceleration\u0026#34;, y=\u0026#34;mpg\u0026#34;, data=mpg, hue=\u0026#34;origin\u0026#34;, style=\u0026#34;origin\u0026#34;, kind=\u0026#34;scatter\u0026#34; ) plt.show()   Setting the \u0026ldquo;alpha\u0026rdquo; parameter to a value between 0 and 1 will vary the transparency of the points in the plot, with 0 being completely transparent and 1 being completely non-transparent.\nLine plots In Seaborn, we have two types of relational plots: scatter plots and line plots. Line plots are the visualization of choice when we need to track the same thing over time.\nBy specifying \u0026ldquo;kind\u0026rdquo; equals \u0026ldquo;line\u0026rdquo;, we can create a line plot. We can also track subgroups over time with line plots. Setting the \u0026ldquo;style\u0026rdquo; and \u0026ldquo;hue\u0026rdquo; parameters equal to the variable name creates different lines for each group that vary in both line style and color.\n1 2 3 4 5 6 7 8 9 10 11  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg, kind=\u0026#34;line\u0026#34;, ci=None, style=\u0026#34;origin\u0026#34;, hue=\u0026#34;origin\u0026#34; ) plt.show()   1 2 3 4 5 6 7 8 9 10 11 12  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg, kind=\u0026#34;line\u0026#34;, ci=None, col=\u0026#34;origin\u0026#34;, hue=\u0026#34;origin\u0026#34;, style=\u0026#34;origin\u0026#34; ) plt.show()   Setting the \u0026ldquo;markers\u0026rdquo; parameter equal to \u0026ldquo;True\u0026rdquo; will display a marker for each data point. The marker will vary based on the subgroup you\u0026rsquo;ve set using the \u0026ldquo;style\u0026rdquo; parameter. If you don\u0026rsquo;t want the line styles to vary by subgroup, set the \u0026ldquo;dashes\u0026rdquo; parameter equal to \u0026ldquo;False\u0026rdquo;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg, kind=\u0026#34;line\u0026#34;, ci=None, col=\u0026#34;origin\u0026#34;, hue=\u0026#34;origin\u0026#34;, style=\u0026#34;origin\u0026#34;, markers=True, dashes=False ) plt.show()   Line plots can also be used when you have more than one observation per x-value. If a line plot is given multiple observations per x-value, it will aggregate them into a single summary measure. By default, it will display the mean. This is the scatter plot\n1 2 3 4 5 6 7  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg\u0026#34;, data=mpg, ) plt.show()   and the line plot\n1 2 3 4 5 6 7 8  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg\u0026#34;, data=mpg, kind=\u0026#34;line\u0026#34; ) plt.show()    Notice that Seaborn will automatically calculate a confidence interval for the mean, displayed by the shaded region.\n Set the \u0026ldquo;ci\u0026rdquo; parameter equal to the string \u0026ldquo;sd\u0026rdquo; to make the shaded area represent the standard deviation instead of the confidence interval for the mean which shows the spread of the distribution of observations at each x value. We can also turn off the confidence interval by setting the \u0026ldquo;ci\u0026rdquo; parameter equal to \u0026ldquo;None\u0026rdquo;.\n1 2 3 4 5 6 7 8 9  sns.relplot( x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg\u0026#34;, data=mpg, kind=\u0026#34;line\u0026#34;, ci=\u0026#34;sd\u0026#34; ) plt.show()   Categorical Plot Count plots and bar plots Count plots and bar plots are two types of visualizations that Seaborn calls \u0026ldquo;categorical plots\u0026rdquo;.\nWe call catplot() method and use the \u0026ldquo;kind\u0026rdquo; parameter to specify what kind of categorical plot to use. \u0026ldquo;catplot()\u0026rdquo; offers the same flexibility that \u0026ldquo;relplot()\u0026rdquo; does, which means it will be easy to create subplots if we need to using the same \u0026ldquo;col\u0026rdquo; and \u0026ldquo;row\u0026rdquo; parameters.\n1 2 3 4  sns.catplot(x=\u0026#34;Internet usage\u0026#34;, data=survey_data, kind=\u0026#34;count\u0026#34;, row=\u0026#34;Age Category\u0026#34;) plt.show()   Use the \u0026ldquo;order\u0026rdquo; parameter which accepts a list can specific ordering of categories. This works for all types of categorical plots.\nBar plots look similar to count plots, but instead of the count of observations in each category, they show the mean of a quantitative variable among observations in each category. To create this bar plot, we use \u0026ldquo;catplot\u0026rdquo;. Specify the categorical variable on the x-axis, the quantitative variable on the y-axis, and set the \u0026ldquo;kind\u0026rdquo; parameter equal to \u0026ldquo;bar\u0026rdquo;.\n Of course, you can also change the orientation of the bars in bar plots and count plots by switching the x and y parameters.\n 1 2 3 4 5 6 7 8 9 10 11  category_order = [\u0026#34;\u0026lt;2 hours\u0026#34;, \u0026#34;2 to 5 hours\u0026#34;, \u0026#34;5 to 10 hours\u0026#34;, \u0026#34;\u0026gt;10 hours\u0026#34;] sns.catplot(x=\u0026#34;study_time\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;bar\u0026#34;, order=category_order) plt.show()   Notice also that Seaborn automatically shows 95% confidence intervals for these means. we can turn off these confidence intervals by setting the \u0026ldquo;ci\u0026rdquo; parameter equal to \u0026ldquo;None\u0026rdquo;.\nBox plot A box plot shows the distribution of quantitative data. The colored box represents the 25th to 75th percentile, and the line in the middle of the box represents the median. The whiskers give a sense of the spread of the distribution, and the floating points represent outliers.\nWe can use the \u0026ldquo;catplot()\u0026rdquo; function to crate a box plot. We\u0026rsquo;ll put the categorical variable on the x-axis and the quantitative variable on the y-axis, and specify kind=\u0026quot;box\u0026quot;.\n As a reminder, \u0026ldquo;catplot\u0026rdquo; allows you to change the order of the categories with a list by \u0026ldquo;order\u0026rdquo; parameter.\n 1 2 3 4 5 6 7 8 9 10 11 12  study_time_order = [\u0026#34;\u0026lt;2 hours\u0026#34;, \u0026#34;2 to 5 hours\u0026#34;, \u0026#34;5 to 10 hours\u0026#34;, \u0026#34;\u0026gt;10 hours\u0026#34;] sns.catplot( x=\u0026#34;study_time\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;box\u0026#34;, order=study_time_order ) plt.show()   You can omit the outliers using the specify sym=\u0026quot;\u0026quot;. \u0026ldquo;sym\u0026rdquo; can also be used to change the appearance of the outliers instead of omitting them.\nYou can change the way the whiskers using the \u0026ldquo;whis\u0026rdquo; parameter. You can have the whiskers define specific lower and upper percentiles by passing in a list of the lower and upper values such as whis=[5, 95] or whis=[0, 100].\n1 2 3 4 5 6 7 8 9 10 11  sns.catplot( x=\u0026#34;internet\u0026#34;, y=\u0026#34;G3\u0026#34;, data=student_data, kind=\u0026#34;box\u0026#34;, sym=\u0026#34;\u0026#34;, whis=[0, 100], # \u0026lt;-- Min \u0026amp; Max hue=\u0026#34;location\u0026#34; ) plt.show()   Point plots Point plots show the mean of a quantitative variable for the observations in each category, plotted as a single point.\nBoth line plots and point plots show the mean of a quantitative variable and 95% confidence intervals for the mean. However, there is a key difference. Line plots are relational plots, so both the x- and y-axis are quantitative variables. In a point plot, one axis - usually the x-axis - is a categorical variable, making it a categorical plot.\nSince Point plot is a categorical plot, we use \u0026ldquo;catplot\u0026rdquo; and set \u0026ldquo;kind\u0026rdquo; equal to \u0026ldquo;point\u0026rdquo;. To remove the lines connecting each point, set the \u0026ldquo;join\u0026rdquo; parameter equal to False. You can also add “caps” to the end of the confidence intervals, set the “capsize” parameter equal to the desired width of the caps. Finally, you can turn the confidence intervals off by setting the \u0026ldquo;ci\u0026rdquo; parameter equal to None.\n1 2 3 4 5 6  sns.catplot(x=\u0026#34;famrel\u0026#34;, y=\u0026#34;absences\u0026#34;, data=student_data, kind=\u0026#34;point\u0026#34;, capsize=0.2) plt.show()   To have the points and confidence intervals be calculated for the median instead of the mean, set \u0026ldquo;estimator=np.median.\n1 2 3 4 5 6 7 8 9 10  from numpy import median sns.catplot(x=\u0026#34;romantic\u0026#34;, y=\u0026#34;absences\u0026#34;, data=student_data, kind=\u0026#34;point\u0026#34;, hue=\u0026#34;school\u0026#34;, ci=None, estimator=median) plt.show()   Customizing Seaborn Plots Changing plot style and color Seaborn has five preset figure styles which change the background and axes of the plot. You can refer to them by name: \u0026ldquo;white\u0026rdquo; (default), \u0026ldquo;dark\u0026rdquo;, \u0026ldquo;whitegrid\u0026rdquo;, \u0026ldquo;darkgrid\u0026rdquo;, and \u0026ldquo;ticks\u0026rdquo;. To set one of these as the global style for all of your plots, use the \u0026ldquo;sns.set_style()\u0026rdquo; method.\nYou can change the color of the main elements of the plot with Seaborn\u0026rsquo;s \u0026ldquo;sns.set_palette()\u0026rdquo; method. Seaborn has many preset color palettes that you can refer to by name, or you can create your own custom palette with list.\nSeaborn has a group of preset palettes called diverging palettes that are great to use if your visualization deals with a scale where the two ends of the scale are opposites and there is a neutral midpoint.\nAnother group of palettes are called sequential palettes. These are a single color (or two colors blended) moving from light to dark values. Sequential palettes are great for emphasizing a variable on a continuous scale.\nYou can also create your own custom palettes by passing in a list of color names.\n1 2 3 4 5 6 7 8 9 10 11 12  sns.set_style(\u0026#34;whitegrid\u0026#34;) sns.set_palette(\u0026#34;RdBu\u0026#34;) category_order = [\u0026#34;Never\u0026#34;, \u0026#34;Rarely\u0026#34;, \u0026#34;Sometimes\u0026#34;, \u0026#34;Often\u0026#34;, \u0026#34;Always\u0026#34;] sns.catplot(x=\u0026#34;Parents Advice\u0026#34;, data=survey_data, kind=\u0026#34;count\u0026#34;, order=category_order) plt.show()   1 2 3 4 5 6 7 8  sns.set_style(\u0026#34;darkgrid\u0026#34;) color = [\u0026#34;#39A7D0\u0026#34;, \u0026#34;#36ADA4\u0026#34;] sns.set_palette(color) sns.catplot(x=\u0026#34;Gender\u0026#34;, y=\u0026#34;Age\u0026#34;, data=survey_data, kind=\u0026#34;box\u0026#34;) plt.show()   Finally, you can change the scale of your plot by using the \u0026ldquo;sns.set_context()\u0026rdquo; method. The scale options from smallest to largest are \u0026ldquo;paper\u0026rdquo; (default), \u0026ldquo;notebook\u0026rdquo;, \u0026ldquo;talk\u0026rdquo;, and \u0026ldquo;poster\u0026rdquo;.\nAdding titles and labels In this section, we will focus on the title, label and x axis tick label in the plot.\nSeaborn\u0026rsquo;s plot functions create two different types of objects: FacetGrids and AxesSubplots. To figure out which type of object you\u0026rsquo;re working with, first assign the plot output to a variable such as g, and call the function type(g) .\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  g1 = sns.relplot(x=\u0026#34;weight\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg, kind=\u0026#34;scatter\u0026#34;) g2 = sns.catplot(x=\u0026#34;weight\u0026#34;, data=mpg, kind=\u0026#34;count\u0026#34;) g3 = sns.scatterplot(x=\u0026#34;weight\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg) g4 = sns.countplot(x=\u0026#34;weight\u0026#34;, data=mpg) print(type(g1), type(g2), type(g3), type(g4)   \u0026lt;class 'seaborn.axisgrid.FacetGrid'\u0026gt; \u0026lt;class 'seaborn.axisgrid.FacetGrid'\u0026gt; \u0026lt;class 'matplotlib.axes._subplots.AxesSubplot'\u0026gt; \u0026lt;class 'matplotlib.axes._subplots.AxesSubplot'\u0026gt; Recall that \u0026ldquo;relplot()\u0026rdquo; and \u0026ldquo;catplot()\u0026rdquo; both support making subplots. This means that they are creating FacetGrid objects. In contrast, single-type plot functions like \u0026ldquo;scatterplot()\u0026rdquo; and \u0026ldquo;countplot()\u0026rdquo; return a single AxesSubplot object.\n A FacetGrid consists of one or more AxesSubplots, which is how it supports subplots.\n To add a title to a FacetGrid object, first assign the plot to the variable \u0026ldquo;g\u0026rdquo;. And then, you can set the title using \u0026ldquo;g.fig.suptitle()\u0026rdquo;. To adjust the height of the title, you can use the \u0026ldquo;y\u0026rdquo; parameter whose default value is 1.\n1 2 3 4 5 6 7  g = sns.relplot(x=\u0026#34;weight\u0026#34;, y=\u0026#34;horsepower\u0026#34;, data=mpg, kind=\u0026#34;scatter\u0026#34;) g.fig.suptitle(\u0026#34;Car Weight vs. Horsepower\u0026#34;, y=1) plt.show()   1 2 3 4 5 6 7 8  sns.set_palette(\u0026#34;Blues\u0026#34;) g = sns.catplot(x=\u0026#34;Gender\u0026#34;, y=\u0026#34;Age\u0026#34;, data=survey_data, kind=\u0026#34;box\u0026#34;, hue=\u0026#34;Interested in Pets\u0026#34;) g.fig.suptitle(\u0026#34;Age of Those Interested in Pets vs. Not\u0026#34;) plt.show()   To add a title to an AxesSubplot object, call the method “g.set_titles()”. You can also use the “y” parameter here to adjust the height of the title. Notice that a FacetGrid consists of one or more AxesSubplots, thus you can set title on each of subplot in a plot.\nSince g is a FacetGrid object, using \u0026ldquo;g.fig.suptitle()\u0026rdquo; will add a title to the figure as a whole. To alter the subplot titles, call \u0026ldquo;g.set_titles()\u0026rdquo; repeatly to set the titles for each AxesSubplot. If you want to use the variable name in the title, you can use {col_name} to reference the column value.\n1 2 3 4 5 6 7 8 9 10  g = sns.relplot(x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg_mean\u0026#34;, data=mpg_mean, col=\u0026#34;origin\u0026#34;, kind=\u0026#34;line\u0026#34;) g.fig.suptitle(\u0026#34;Average MPG Over Time\u0026#34;) g.set_titles(\u0026#34;EU\u0026#34;) g.set_titles(\u0026#34;JP\u0026#34;) g.set_titles(\u0026#34;US\u0026#34;) plt.show()   or\n1 2 3 4 5 6 7 8  g = sns.relplot(x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg_mean\u0026#34;, data=mpg_mean, col=\u0026#34;origin\u0026#34;, kind=\u0026#34;line\u0026#34;) g.fig.suptitle(\u0026#34;Average MPG Over Time\u0026#34;) g.set_titles(\u0026#34;{col_name}\u0026#34;) plt.show()   To add axis labels, assign the plot to a variable and then call the \u0026ldquo;set\u0026rdquo; function. Set the parameters \u0026ldquo;xlabel\u0026rdquo; and \u0026ldquo;ylabel\u0026rdquo; to set the desired x-axis and y-axis labels, respectively. This works with both FacetGrid and AxesSubplot objects.\n1 2 3 4 5 6 7 8 9 10 11  g = sns.lineplot(x=\u0026#34;model_year\u0026#34;, y=\u0026#34;mpg_mean\u0026#34;, data=mpg_mean, hue=\u0026#34;origin\u0026#34;) g.set_title(\u0026#34;Average MPG Over Time\u0026#34;) g.set( xlabel=\u0026#34;Car Model Year\u0026#34;, ylabel=\u0026#34;Average MPG\u0026#34; ) plt.show()   1 2 3 4 5 6 7 8 9 10 11 12  sns.set_style(\u0026#34;darkgrid\u0026#34;) sns.set_palette(\u0026#34;RdBu_r\u0026#34;) g = sns.catplot(x=\u0026#34;Village - town\u0026#34;, y=\u0026#34;Likes Techno\u0026#34;, data=survey_data, kind=\u0026#34;bar\u0026#34;, col=\u0026#34;Gender\u0026#34;) g.fig.suptitle(\u0026#34;Percentage of Young People Who Like Techno\u0026#34;, y=1.02) g.set_titles(\u0026#34;{col_name}\u0026#34;) g.set(xlabel=\u0026#34;Location of Residence\u0026#34;, ylabel=\u0026#34;% Who Like Techno\u0026#34;) plt.show()   Sometimes your tick labels may overlap, one way to address this is by rotating the tick labels. To do this, after we create the plot, we call the matplotlib function \u0026ldquo;plt.xticks()\u0026rdquo; and set \u0026ldquo;rotation=90\u0026rdquo;. This works with both FacetGrid and AxesSubplot objects.\n1 2 3 4 5 6 7 8 9 10  sns.catplot(x=\u0026#34;origin\u0026#34;, y=\u0026#34;acceleration\u0026#34;, data=mpg, kind=\u0026#34;point\u0026#34;, join=False, capsize=0.1) plt.xticks(rotation=90) plt.show()   ","date":"2020-04-20T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/data-visualization-ii-seaborn/","title":"Data Visualization II (Seaborn)"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n Introduction to Matplotlib Intro to data visualization with matplotlib we will use the main object-oriented interface. This interface is provided through the pyplot submodule. The plt.subplots() command, when called without any inputs, creates two different objects: a Figure object and an Axes object.\n1 2  import matplotlib.pyplot as plt fig, ax = plt.subplots()   The Figure object is a container that holds everything that you see on the page. Meanwhile, the Axes is the part of the page that holds the data. It is the canvas on which we will draw with our data.\nTo add the data to the Axes, we call a ax.plot() command. If you want, you can add more data to the plot by this way. Finally, we call the plt.show() function to show the effect of the plotting command.\n1 2 3 4 5 6 7 8  import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.plot(x=df.col1, y=df.col2) ax.plot(x=df.col1, y=df.col3) ax.plot(df2[\u0026#34;col1\u0026#34;], df2[\u0026#34;col2\u0026#34;]) # you can also add data to a figure from different tables. plt.show()   Here is what all of the code to create this figure would then look like.\n First, we create the Figure and the Axes objects. We call the Axes method plot to add first the df.col2, and then the df.col3 to the Axes. Finally, we ask Matplotlib to show us the figure.  Customizing Plots The plot method takes an optional keyword argument, marker, which lets you indicate what kind of markers you\u0026rsquo;d like. To see all the possible marker styles, you can visit this page in the Matplotlib online documentation.\nYou can change the appearance of these connecting lines by adding the linestyle keyword argument. Like marker shapes, there are a few linestyles you can choose from, listed in this page.\nYou can even go so far as to eliminate the lines altogether, by passing the string \u0026ldquo;None\u0026rdquo; as input to this keyword argument.\nyou can also add the color argument. For example, here we\u0026rsquo;ve chosen to show this data in red, indicated by the letter \u0026ldquo;r\u0026rdquo;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # Plot Seattle data, setting data appearance ax.plot( seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;], color=\u0026#34;b\u0026#34;, marker=\u0026#34;o\u0026#34;, linestyle=\u0026#34;--\u0026#34; ) # Plot Austin data, setting data appearance ax.plot( austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;], color=\u0026#34;r\u0026#34;, marker=\u0026#34;v\u0026#34;, linestyle=\u0026#34;--\u0026#34; ) plt.show()   The Axes object has several methods that start with the word set. These are methods that you can use to change certain properties of the object, before calling show to display it.\nFor example, there is a set_xlabel method that you can use to set the value of the label of the x-axis.\nSimilarly, a set_ylabel method customizes the label that is associated with the y-axis.\nFinally, you can also add a title to your Axes using the set_title method.\n1 2 3 4 5 6 7 8  ax.plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;]) ax.plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;]) ax.set_xlabel(\u0026#34;Time (months)\u0026#34;) ax.set_ylabel(\u0026#34;Precipitation (inches)\u0026#34;) ax.set_title(\u0026#34;Weather patterns in Austin and Seattle\u0026#34;) plt.show()   Small Multiples In some cases, adding more data to a plot can make the plot too busy, obscuring patterns rather than revealing them. One way to overcome this kind of mess is to use what are called small multiples. These are multiple small plots that show similar data across different conditions.\nIn Matplotlib, small multiples are called sub-plots. That is also the reason that the function that creates these is called subplots.\nPreviously, we called this function with no inputs. This creates one subplot. Now, we\u0026rsquo;ll give it some inputs. Small multiples are typically arranged on the page as a grid with rows and columns. Here, we are creating a Figure object with 2 rows of subplots, and 2 columns. This is what this would look like before we add any data to it.\n1 2  fig, ax = plt.sublpots(2, 2) plt.show()   In this case, the variable ax is no longer only one Axes object. Instead, it is an numpy.ndarray of Axes objects with a shape of 2 by 2.\n1 2  print(ax.shape) print(type(ax))   (2, 2) \u0026lt;class 'numpy.ndarray'\u0026gt; To add data, we would now have to index into this object and call the plot method on an element of the array.\n1 2 3 4 5 6 7 8  fig, ax = plt.subplots(2, 2) ax[0, 0].plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;]) ax[0, 1].plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-TAVG-NORMAL\u0026#34;]) ax[1, 0].plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;]) ax[1, 1].plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-TAVG-NORMAL\u0026#34;]) plt.show()   There is a special case for situations where you have only one row or only one column of plots. In this case, the resulting array will be one-dimensional and you will only have to provide one index to access the elements of this array.\n1 2  fig, ax = plt.subplots(3, 1) ax.shape   (3,) To make sure that all the subplots have the same range of y-axis values, we initialize the figure and its subplots with the key-word argument sharey set to True. This means that both subplots will have the same range of y-axis values.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fig, ax = plt.subplots(2, 1, sharey=True) ax[0].plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;], color = \u0026#34;b\u0026#34;) ax[0].plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-25PCTL\u0026#34;], color = \u0026#34;b\u0026#34;, linestyle = \u0026#34;--\u0026#34;) ax[0].plot(seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-PRCP-75PCTL\u0026#34;], color = \u0026#34;b\u0026#34;, linestyle = \u0026#34;--\u0026#34;) ax[1].plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-NORMAL\u0026#34;], color = \u0026#34;r\u0026#34;) ax[1].plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-25PCTL\u0026#34;], color = \u0026#34;r\u0026#34;, linestyle = \u0026#34;--\u0026#34;) ax[1].plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-PRCP-75PCTL\u0026#34;], color = \u0026#34;r\u0026#34;, linestyle = \u0026#34;--\u0026#34;) ax[0].set_ylabel(\u0026#34;Seattle\u0026#34;) ax[1].set_ylabel(\u0026#34;Austin\u0026#34;) ax[1].set_xlabel(\u0026#34;MONTH\u0026#34;) plt.show()   Plotting time-series Plotting time-series data If we want pandas to recognize column with YYYY-MM-DD format as time-series, we\u0026rsquo;ll need to tell it to parse the this column as a date by parse_dates argument in read_csv method. To use the full power of pandas indexing facilities, we\u0026rsquo;ll also designate the date column as our index by using the index_col argument in read_csv method.\n1 2 3 4 5 6 7  (base) wanghaoming@localhost ~ % head -6 ~/Downloads/climate_change.csv date,co2,relative_temp 1958-03-06,315.71,0.1 1958-04-06,317.45,0.01 1958-05-06,317.5,0.08 1958-06-06,,-0.05 1958-07-06,315.86,0.06   1 2 3 4 5  climate_change = pd.read_csv( \u0026#34;~/Downloads/climate_change.csv\u0026#34;, parse_dates=[\u0026#34;date\u0026#34;], index_col=\u0026#34;date\u0026#34; )   Matplotlib automatically chooses to show the time on the x-axis with intervals of 10 years or years or month depending on the length of data.\n1 2 3 4 5 6 7 8 9 10 11  fig, ax = plt.subplots() ax.plot( climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;] ) ax.set_xlabel(\u0026#34;Time\u0026#34;) ax.set_ylabel(\u0026#34;Relative temperature (Celsius)\u0026#34;) plt.show()   1 2 3 4 5 6  fig, ax = plt.subplots() seventies = climate_change[\u0026#34;1970-01-01\u0026#34;: \u0026#34;1979-12-31\u0026#34;] ax.plot(seventies.index, seventies[\u0026#34;co2\u0026#34;]) plt.show()   Plotting time-series with different variables You could plot two time-series in separate sub-plots. Here, we\u0026rsquo;re going to plot them in the same sub-plot, using two different y-axis scales.\nWe start by adding the first variable to the Axes. Then, we use the twinx method to create a twin of this Axes. This means that the two Axes share the same x-axis, but the y-axes are separate.\nWe add the other variable to this second Axes object and show the figure. There is one y-axis scale on the left, and another y-axis scale to the right.\n1 2 3 4 5 6 7 8  fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[\u0026#34;co2\u0026#34;], color=\u0026#34;b\u0026#34;) ax2 = ax.twinx() ax2.plot(climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;], color=\u0026#34;r\u0026#34;) plt.show()   We set color argument in our calls to plot and set_ylabel method from the origin Axes twin Axes object. In the resulting figure, each variable has its own color and the y-axis labels clearly tell us which scale belongs to which variable.\nWe can also make encoding by color more distinct by setting y-axis ticks and the y-axis tick labels. This is done by adding a call to the tick_params method. This method takes either y or x as its first argument, pointing to the fact that we are modifying the parameters of the y-axis or x-axis ticks and tick labels. To change their color, we use the colors key-word argument.\n1 2 3 4 5 6 7 8 9 10 11 12 13  fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[\u0026#34;co2\u0026#34;], color=\u0026#34;b\u0026#34;) ax.set_ylabel(\u0026#34;CO2\u0026#34;, color=\u0026#34;b\u0026#34;) ax.tick_params(\u0026#34;y\u0026#34;, colors=\u0026#34;b\u0026#34;) # \u0026lt;-- Notice \u0026#34;s\u0026#34; ax.set_xlabel(\u0026#34;Year\u0026#34;) ax2 = ax.twinx() ax2.plot(climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;], color=\u0026#34;r\u0026#34;) ax2.set_ylabel(\u0026#34;Relative Temp\u0026#34;, color=\u0026#34;r\u0026#34;) ax2.tick_params(\u0026#34;y\u0026#34;, colors=\u0026#34;r\u0026#34;) plt.show()   We can implement this as a function that we can reuse. Using our function, we don\u0026rsquo;t have to repeat these calls, and the code is simpler.\n1 2 3 4 5  def plot_timeseries(axes, x, y, color, xlabel, ylabel): axes.plot(x, y, color=color) axes.set_xlabel(xlabel) axes.set_ylabel(ylabel, color=color) axes.tick_params(\u0026#39;y\u0026#39;, colors=color)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  fig, ax = plt.subplots() plot_timeseries( ax, climate_change.index, climate_change[\u0026#34;co2\u0026#34;], \u0026#34;blue\u0026#34;, \u0026#34;Time (years)\u0026#34;, \u0026#34;CO2 levels\u0026#34; ) ax2 = ax.twinx() plot_timeseries( ax2, climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;], \u0026#34;red\u0026#34;, \u0026#34;Time (years)\u0026#34;, \u0026#34;Relative temperature (Celsius)\u0026#34; ) plt.show()   Annotating time-series data Annotations are usually small pieces of text that refer to a particular part of the visualization, focusing our attention on some feature of the data and explaining this feature.\nWe call a method of the Axes object called annotate. This function takes the annotation text as input, and the xy coordinate that we would like to annotate. The annotate method takes an optional xy text argument that selects the xy position of the text.\n1 2 3 4 5 6 7 8 9 10  fig, ax = plt.subplots() ax.plot(climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;]) ax.annotate( \u0026#34;\u0026gt;1 degree\u0026#34;, xy=(pd.Timestamp(\u0026#39;2015-10-06\u0026#39;), 1), xytext=(pd.Timestamp(\u0026#39;2010-10-06\u0026#39;), 0) ) plt.show()   To connect between the annotation text and the annotated data, we can add an arrow. The key-word argument of annotate method to do this is called arrowprops. This argument takes as input a dictionary that defines the properties of the arrow that we would like to use.\nIf we pass an empty dictionary into the key-word argument, the arrow will have the default properties. We can also customize the appearance of the arrow, by dictionary key \u0026ldquo;arrowstyle\u0026rdquo; and \u0026ldquo;color\u0026rdquo;. Look more customizing method here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  fig, ax = plt.subplots() plot_timeseries( ax, climate_change.index, climate_change[\u0026#34;co2\u0026#34;], \u0026#39;blue\u0026#39;, \u0026#34;Time (years)\u0026#34;, \u0026#34;CO2 levels\u0026#34; ) ax2 = ax.twinx() plot_timeseries( ax2, climate_change.index, climate_change[\u0026#34;relative_temp\u0026#34;], \u0026#39;red\u0026#39;, \u0026#34;Time (years)\u0026#34;, \u0026#34;Relative temp (Celsius)\u0026#34; ) ax2.annotate( \u0026#34;\u0026gt;1 degree\u0026#34;, xy=(pd.Timestamp(\u0026#39;2015-10-06\u0026#39;), 1), xytext=(pd.Timestamp(\u0026#39;2008-10-06\u0026#39;), -0.2), arrowprops = { \u0026#34;arrowstyle\u0026#34;: \u0026#34;-\u0026gt;\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;gray\u0026#34; } ) plt.show()   Quantitative comparisons and statistical visualizations Quantitative comparisons: bar-charts We will use a dataset that contains information about the number of medals won by a few countries in the 2016 Olympic Games.\n1 2 3 4 5 6 7  (base) wanghaoming@localhost ~ % head -6 ~/Downloads/medals_by_country_2016.csv ,Bronze,Gold,Silver United States,67,137,52 Germany,67,47,43 Great Britain,26,64,55 Russia,35,50,28 China,35,44,30   We tell pandas to create a DataFrame from a file that contains the data and to use the first column as the index for the DataFrame.\n1  medals = pd.read_csv(\u0026#34;~/Downloads/medals_by_country_2016.csv\u0026#34;, index_col=0)   We create a Figure and an Axes object and call the Axes bar method to create a bar chart. The labels of the x-axis ticks can be rotated by using the set_xticklabels method of the Axes.\n1 2 3 4 5 6 7  fig, ax = plt.subplots() ax.bar(medals.index, medals[\u0026#34;Gold\u0026#34;]) ax.set_xticklabels(medals.index, rotation=90) # \u0026lt;-- Notice here ax.set_ylabel(\u0026#34;Number of medals\u0026#34;) plt.show()   To add others information into the same plot, we\u0026rsquo;ll create a stacked bar chart. We add another call to the bar method to add the other data. We add the bottom key-word argument to tell Matplotlib that the bottom of this data should be at the height of the previous data.\nWe also need to add the label key-word argument to each call of the bar method with the label for the bars plotted in this call. Then add a call to the Axes legend method before calling show.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  fig, ax = plt.subplots() ax.bar(medals.index, medals[\u0026#34;Gold\u0026#34;], label=\u0026#34;Gold\u0026#34;) ax.bar( medals.index, medals[\u0026#34;Silver\u0026#34;], bottom=medals[\u0026#34;Gold\u0026#34;] , label=\u0026#34;Silver\u0026#34; ) ax.bar( medals.index, medals[\u0026#34;Bronze\u0026#34;], bottom=medals[\u0026#34;Gold\u0026#34;] + medals[\u0026#34;Silver\u0026#34;], # \u0026lt;-- Notice here label=\u0026#34;Bronze\u0026#34; ) ax.legend() plt.show()   Quantitative comparisons: histograms A histogram would show the full distribution of values within each variable. We call the Axes hist method with the column of the DataFrame.\nAs before, we can label a variable by calling the hist method with the label key-word argument and then calling the legend method before we call plt.show.\n1 2 3 4 5 6 7 8 9 10  fig, ax = plt.subplots() ax.hist(mens_rowing[\u0026#34;Weight\u0026#34;], label=\u0026#34;Rowing\u0026#34;) ax.hist(mens_gymnastics[\u0026#34;Weight\u0026#34;], label=\u0026#34;Gymnastics\u0026#34;) ax.set_xlabel(\u0026#34;Weight (kg)\u0026#34;) ax.set_ylabel(\u0026#34;# of observations\u0026#34;) ax.legend() plt.show()   The number of default bars or bins in a histogram is 10, but we can customize that. If we provide an scalar to the bins key-word argument, the histogram will have that number of bins.\nIf we instead provide a list, these numbers will be set to be the boundaries between the bins.\nThe occlusion of two histogram plots can be eliminated by changing the type of histogram that is used. you can specify a histtype of \u0026ldquo;step\u0026rdquo;, which displays the histogram as thin lines, instead of solid bars.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  fig, ax = plt.subplots() ax.hist( mens_rowing[\u0026#34;Weight\u0026#34;], label=\u0026#34;Rowing\u0026#34;, bins=5, histtype=\u0026#34;step\u0026#34; ) ax.hist( mens_gymnastics[\u0026#34;Weight\u0026#34;], label=\u0026#34;Gymnastics\u0026#34;, bins=5, histtype=\u0026#34;step\u0026#34; ) ax.set_xlabel(\u0026#34;Weight (kg)\u0026#34;) ax.set_ylabel(\u0026#34;# of observations\u0026#34;) ax.legend() plt.show()   Statistical plotting The first is the use of error bars in plots. These are additional markers on a plot or bar chart that tell us something about the distribution of the data.\n Histograms show the entire distribution. Error bars instead summarize the distribution of the data in one number, such as the standard deviation of the values.\n There are at least two different ways to display error bars. Here, we add the error bar as an argument to a bar chart. Each call to the ax.bar method takes an x argument and a y argument. The yerr key-word argument takes an additional number.\n1 2 3 4 5 6 7  fig, ax = plt.subplots() ax.bar(\u0026#34;Rowing\u0026#34;, mens_rowing[\u0026#34;Height\u0026#34;].mean(), yerr=mens_rowing[\u0026#34;Height\u0026#34;].std()) ax.bar(\u0026#34;Gymnastics\u0026#34;, mens_gymnastics[\u0026#34;Height\u0026#34;].mean(), yerr=mens_gymnastics[\u0026#34;Height\u0026#34;].std()) ax.set_ylabel(\u0026#34;Height (cm)\u0026#34;) plt.show()   It summarizes the full distribution that you saw in the histograms in two numbers: the mean value, and the spread of values, quantified as the standard deviation.\nWe can also add error bars to a line plot. To plot this data with error bars, we will use the ax.errorbar method. This method takes a sequence of x values, y values and yerr values.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  fig, ax = plt.subplots() ax.errorbar( seattle_weather[\u0026#34;MONTH\u0026#34;], seattle_weather[\u0026#34;MLY-TAVG-NORMAL\u0026#34;], seattle_weather[\u0026#34;MLY-TAVG-STDDEV\u0026#34;] ) ax.errorbar( austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-TAVG-NORMAL\u0026#34;], austin_weather[\u0026#34;MLY-TAVG-STDDEV\u0026#34;] ) ax.set_ylabel(\u0026#34;Temperature (Fahrenheit)\u0026#34;) plt.show()   The second statistical visualization technique is the boxplot. It is implemented by ax.boxplot method. We can call it with a sequence of sequences. We add labels on each of the variables separately by calling ax.set_xticklabels method, labeling the y-axis as well.\n1 2 3 4 5 6 7 8 9 10 11 12 13  fig, ax = plt.subplots() ax.boxplot( [ mens_rowing[\u0026#34;Height\u0026#34;], mens_gymnastics[\u0026#34;Height\u0026#34;], ] ) ax.set_xticklabels([\u0026#34;Rowing\u0026#34;, \u0026#34;Gymnastics\u0026#34;]) ax.set_ylabel(\u0026#34;Height (cm)\u0026#34;) plt.show()   Quantitative comparisons: scatter plots A standard visualization for bi-variate comparisons is a scatter plot. To create this plot, we initialize a Figure and Axes objects and call the Axes scatter method.\nWe can customize scatter plots in a manner that is similar to the customization that we introduced in other plots. For example, we set the color argument to set color on each group of points.\n1 2 3 4 5 6 7 8 9 10 11 12 13  fig, ax = plt.subplots() eighty = climate_change[\u0026#34;1980-01-01\u0026#34;: \u0026#34;1989-12-31\u0026#34;] ninety = climate_change[\u0026#34;1990-01-01\u0026#34;: \u0026#34;1999-12-31\u0026#34;] ax.scatter(eighty[\u0026#34;co2\u0026#34;], eighty[\u0026#34;relative_temp\u0026#34;], color=\u0026#34;b\u0026#34;, label=\u0026#34;1980s\u0026#34;) ax.scatter(ninety[\u0026#34;co2\u0026#34;], ninety[\u0026#34;relative_temp\u0026#34;], color=\u0026#34;r\u0026#34;, label=\u0026#34;1990s\u0026#34;) ax.set_xlabel(\u0026#34;CO2 (ppm)\u0026#34;) ax.set_ylabel(\u0026#34;Relative temperature (C)\u0026#34;) ax.legend() plt.show()   But we can also enter a Serise as input to the c key-word argument, this variable will get encoded as color.\n Note that this is not the color key-word argument that we used before, but is instead just the letter c.\n Now, time of the measurements is encoded in the brightness of the color applied to the points, with dark blue points early on and later points in bright yellow.\n1 2 3 4 5 6 7 8 9 10 11 12  fig, ax = plt.subplots() ax.scatter( climate_change[\u0026#34;co2\u0026#34;], climate_change[\u0026#34;relative_temp\u0026#34;], c=climate_change.index ) ax.set_xlabel(\u0026#34;CO2 (ppm)\u0026#34;) ax.set_ylabel(\u0026#34;Relative temperature (C)\u0026#34;) plt.show()   Sharing visualizations with others Plot style we\u0026rsquo;ll change the overall style of the figure. we call plt.style.use() method before the plotting code, the figure style will look completely different.\nwe can choose \u0026ldquo;ggplot\u0026rdquo; style, or \u0026ldquo;seaborn-colorblind\u0026rdquo;, click here to find more style.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  plt.style.use(\u0026#34;seaborn\u0026#34;) fig, ax = plt.subplots() ax2 = ax.twinx() ax.plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-TAVG-NORMAL\u0026#34;], color=\u0026#34;b\u0026#34;) ax2.plot(austin_weather[\u0026#34;MONTH\u0026#34;], austin_weather[\u0026#34;MLY-TAVG-STDDEV\u0026#34;], color=\u0026#34;r\u0026#34;) ax.set_xlabel(\u0026#34;MONTH\u0026#34;) ax.set_ylabel(\u0026#34;MLY-TAVG-NORMAL\u0026#34;, color=\u0026#34;b\u0026#34;) ax.tick_params(\u0026#34;y\u0026#34;, colors=\u0026#34;b\u0026#34;) ax2.set_ylabel(\u0026#34;MLY-TAVG-NORMAL\u0026#34;, color=\u0026#34;r\u0026#34;) ax2.tick_params(\u0026#34;y\u0026#34;, colors=\u0026#34;r\u0026#34;) ax.set_title(\u0026#34;Title\u0026#34;) plt.show()   Saving visualizations Now, we replace the call to plt.show() with a call to the Figure object\u0026rsquo;s fig.savefig method. We provide a file-path as input to the function. If we do this, the figure will no longer appear on our screen, but instead appear as a file on our file-system.\nUsing savefig method, we can saved the figure as a png, jpg, svg \u0026hellip; file. You can control how small the resulting file will be, and the degree of loss of quality, by setting the quality key-word argument. This will be a number between 1 and 100. you can also control the quality through setting the dpi key-word argument.\n1  fig.savefig(\u0026#34;~/Documents/figure.png\u0026#34;, dpi=300)   Finally, you can call set_size_inches method to control is the size of the figure. This function takes a list. The first number sets the width of the figure and the second number sets the height of the figure.\n1 2  fig.set_size_inches([3,5]) fig.savefig(\u0026#34;~/Documents/figure_3_5.png\u0026#34;)   Automating figures from data you can write functions and programs that automatically adjust what they are doing based on the input data.\n1 2 3 4 5 6 7 8 9 10 11 12 13  sports_column = summer_2016_medals[\u0026#34;Sport\u0026#34;] sports = sports_column.unique() fig, ax = plt.subplots() for sport in sports: sport_df = summer_2016_medals[summer_2016_medals[\u0026#34;Sport\u0026#34;]==sport] ax.bar(sport, sport_df[\u0026#34;Weight\u0026#34;].mean(), yerr=sport_df[\u0026#34;Weight\u0026#34;].std()) ax.set_ylabel(\u0026#34;Weight\u0026#34;) ax.set_xticklabels(sports, rotation=90) plt.show()   You can also do this to achieve a similar effect:\n1  summer_2016_medals.groupby(\u0026#34;Sport\u0026#34;)[\u0026#34;Weight\u0026#34;].mean().plot(kind=\u0026#34;bar\u0026#34;)   ","date":"2020-04-16T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/data-visualization-i-matplotlib/","title":"Data Visualization I (Matplotlib)"},{"content":"","date":"2020-03-04T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/high-performance-python-v-big-data/","title":"High-Performance Python V (Big Data)"},{"content":"1 2 3 4  import numpy as np import pandas as pd import matplotlib.pyplot as plt %matplotlib inline   Linear separable Generate the data: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  randlist1 = np.array([np.random.uniform(-5,5) for i in range(500)]) randlist2 = np.array([np.random.uniform(0,3) for i in range(500)]) data_p1_0 = pd.DataFrame( { \u0026#34;x0\u0026#34;: 1, \u0026#34;x1\u0026#34;: randlist1, \u0026#34;x2\u0026#34;: randlist1 + randlist2, \u0026#34;y\u0026#34; : -1 } ) data_m1_0 = pd.DataFrame( { \u0026#34;x0\u0026#34;: 1, \u0026#34;x1\u0026#34;: randlist1, \u0026#34;x2\u0026#34;: randlist1 - randlist2, \u0026#34;y\u0026#34; : +1 } ) df = pd.concat([data_m1_0, data_p1_0], axis=0)   PLA model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  plt.figure(figsize=(8,6)) plt.scatter(data_m1_0[\u0026#34;x1\u0026#34;], data_m1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;r\u0026#34;, alpha=0.5, linewidths=0) plt.scatter(data_p1_0[\u0026#34;x1\u0026#34;], data_p1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;b\u0026#34;, alpha=0.5, linewidths=0) w = pd.Series([0, 0, 0], index=[\u0026#34;x0\u0026#34;, \u0026#34;x1\u0026#34;, \u0026#34;x2\u0026#34;]); times = 1; wl = []; x=np.linspace(-5,5,100) wl.append(w) mis_p = df[df[\u0026#34;y\u0026#34;]==+1][np.dot(df[df[\u0026#34;y\u0026#34;]==+1].iloc[:,0:df.shape[1]-1], w) \u0026lt;= 0] mis_n = df[df[\u0026#34;y\u0026#34;]==-1][np.dot(df[df[\u0026#34;y\u0026#34;]==-1].iloc[:,0:df.shape[1]-1], w) \u0026gt; 0] mis = pd.concat([mis_p, mis_n], axis=0) length = mis.shape[0] while length \u0026gt; 0: mis_point = mis.iloc[np.random.randint(length),:] w = w + mis_point[\u0026#34;y\u0026#34;] * mis_point.iloc[0: mis_point.shape[0]-1] mis_p = df[df[\u0026#34;y\u0026#34;]==+1][np.dot(df[df[\u0026#34;y\u0026#34;]==+1].iloc[:,0:df.shape[1]-1], w) \u0026lt;= 0] mis_n = df[df[\u0026#34;y\u0026#34;]==-1][np.dot(df[df[\u0026#34;y\u0026#34;]==-1].iloc[:,0:df.shape[1]-1], w) \u0026gt; 0] mis = pd.concat([mis_p, mis_n], axis=0) length = mis.shape[0] times += 1; wl.append(w) if times in [1, 2, 3, 4, 5, 10, 15, 50, 100]: plt.plot(x, -(w[1]/w[2])*x - (w[0]/w[2]), \u0026#34;--\u0026#34;, label=f\u0026#34;{times}hypothesis\u0026#34;) if times \u0026gt; 50000 : print(\u0026#34;over 50000 times loops\u0026#34;) break plt.plot(x, -(w[1]/w[2])*x - (w[0]/w[2]), \u0026#34;c\u0026#34;, label=f\u0026#34;end hypothesis (times={times})\u0026#34;) plt.legend() plt.savefig(\u0026#34;/Users/wanghaoming/Documents/LaTeX_doc/Machine_Learning/pla.png\u0026#34;, bbox_inches=\u0026#39;tight\u0026#39;, dpi=500)   Convergence process Convergence process of weight vector: $\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_t}{||\\mathbf{w}_f||\\cdot||\\mathbf{w}_t||}$\n1 2 3 4 5 6 7 8 9 10 11 12  wl1 = pd.DataFrame(wl) wl2 = wl1[[\u0026#34;x0\u0026#34;, \u0026#34;x1\u0026#34;, \u0026#34;x2\u0026#34;]].reset_index(drop=True) wf = np.array([0,1,-1]) wt = wl2.dot(wf) / (np.array([wl2.loc[v].dot(wl2.loc[v]) for v in wl2.index]) * wf.dot(wf)) ** 0.5 plt.figure(figsize=(8,6)) plt.plot( range(wt.shape[0]), wt, label= r\u0026#34;$\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_t}{||\\mathbf{w}_f||\\cdot||\\mathbf{w}_t||}$\u0026#34; ) plt.legend() plt.savefig(\u0026#34;/Users/wanghaoming/Documents/LaTeX_doc/Machine_Learning/converg.png\u0026#34;, bbox_inches=\u0026#39;tight\u0026#39;, dpi=500)   Calculate the maximum number of iterations: we have\n$$ \\mathbb{w}_{f}^{T} = \\mathbb{w}_{t} $$\nand\n$$ \\begin{aligned} ||\\mathbf{w}_{t+1}||^2 \u0026amp;= || \\mathbf{w}_{t}+y_{n(t)}\\mathbf{x}_{n(t)} ||^2\\\\ \u0026amp;= ||\\mathbf{w}_{t}||^2+2y_{n(t)}\\mathbf{w}_{t}^{T}\\mathbf{x}_{n(t)} + y_{n(t)}^{2}||\\mathbf{x}_{n}||^2\\\\ \u0026amp;\\leq ||\\mathbf{w}_{t}||^2+||\\mathbf{x}_{n}||^2\\\\ \u0026amp;\\leq ||\\mathbf{w}_{t}||^2 + \\max_{n}||\\mathbf{x}_{n}||^2. \\end{aligned} $$\ndefine $R^2 = \\max_{n}||\\mathbf{x}||^2$ and $\\rho = \\min_{n}\\frac{y_n\\mathbf{w}_{f}^{T}\\mathbf{x}_n}{||\\mathbf{w}_f||}$\nwe have\n$$ \\begin{aligned} ||\\mathbf{w}t||^2 \u0026amp;\\leq ||\\mathbf{w}{t-1}||^2 + R^2\\ \u0026amp;\\leq ||\\mathbf{w}{t-2}||^2 + 2R^2\\ \u0026amp;\\cdots\\ \u0026amp;\\leq ||\\mathbf{w}{0}||^2 + tR^2\\ \u0026amp;=tR^2. \\end{aligned} $$\ni.e. $||\\mathbf{w}_t||\\leq R\\sqrt{t}$\nsince\n1 2 3 4 5 6  $$\\begin{aligned} x +y \u0026amp;=z \\\\z +s \u0026amp;=t \\end{aligned} $$   $$ \\begin{aligned} x + y \u0026amp;= z \\\\ z + s \u0026amp;= t \\end{aligned} $$\n1 2 3 4 5 6 7 8 9 10 11 12  $$\\begin{aligned} \\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_t}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} \u0026amp; =\\frac{\\mathbf{w}_{f}^{T}(\\mathbf{w}_{t-1}+y_{n(t-1)}\\mathbf{x}_{n(t-1)})}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\\u0026amp;=\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_{t-1}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} +\\frac{y_{n(t-1)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-1)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\\u0026amp;=\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_{t-2}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} +\\frac{y_{n(t-2)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-2)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} +\\frac{y_{n(t-1)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-1)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\\u0026amp;\\cdots\\\\\u0026amp;=\\frac{1}{||\\mathbf{w}_t||}\\cdot\\sum^{t}_{i=1}\\frac{y_{n(i)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(i)}}{||\\mathbf{w}_{f}^{T}||} \\\\\u0026amp;\\geq\\frac{1}{||\\mathbf{w}_t||}\\cdott\\cdot\\rho\\geq\\frac{t\\rho}{R\\sqrt{t}}\\\\\u0026amp;=\\frac{\\rho}{R}\\sqrt{t}. \\end{aligned} $$   $$ \\begin{aligned} \\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_t}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} \u0026amp; = \\frac{\\mathbf{w}_{f}^{T}(\\mathbf{w}_{t-1}+y_{n(t-1)}\\mathbf{x}_{n(t-1)})}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\ \u0026amp;=\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_{t-1}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} + \\frac{y_{n(t-1)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-1)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\ \u0026amp;= \\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}_{t-2}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} + \\frac{y_{n(t-2)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-2)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||} + \\frac{y_{n(t-1)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(t-1)}}{||\\mathbf{w}_{f}^{T}||\\cdot||\\mathbf{w}_{t}||}\\\\ \u0026amp;\\cdots\\\\ \u0026amp;=\\frac{1}{||\\mathbf{w}_t||}\\cdot\\sum^{t}_{i=1}\\frac{y_{n(i)}\\mathbf{w}_{f}^{T}\\mathbf{x}_{n(i)}}{||\\mathbf{w}_{f}^{T}||} \\\\ \u0026amp;\\geq \\frac{1}{||\\mathbf{w}_t||}\\cdot t\\cdot \\rho\\geq \\frac{t\\rho}{R\\sqrt{t}}\\\\ \u0026amp;=\\frac{\\rho}{R}\\sqrt{t}. \\end{aligned} $$\nwe have that $\\frac{\\sqrt{t}\\rho}{R}\\leq 1$ and $t\\leq \\frac{R^2}{\\rho^2}$\n1 2 3 4 5 6  x_vec = df[[\u0026#34;x0\u0026#34;, \u0026#34;x1\u0026#34;, \u0026#34;x2\u0026#34;]].reset_index(drop=True) y = df[\u0026#34;y\u0026#34;] R = (np.array([x_vec.loc[r].dot(x_vec.loc[r]) for r in x_vec.index]).max()) ** 0.5 rhot = ((np.array([wf.dot(x_vec.loc[v]) for v in x_vec.index]) * y) / (wf.dot(wf))**0.5) rho = rhot.min() print(R, rho)   9.391078270239522 0.0014954984184524147  therefore the maximum iterations of this model is\n1 2  maxt = (R/rho)**2 maxt   39432926.04282378  Non-Linear separable Generate the data: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  randlist1 = np.array([np.random.uniform(-5,5) for i in range(500)]) randlist2 = np.array([np.random.uniform(-0.1,3) for i in range(500)]) data_p1_0 = pd.DataFrame( { \u0026#34;x0\u0026#34;: 1, \u0026#34;x1\u0026#34;: randlist1, \u0026#34;x2\u0026#34;: randlist1 + randlist2, \u0026#34;y\u0026#34; : -1 } ) data_m1_0 = pd.DataFrame( { \u0026#34;x0\u0026#34;: 1, \u0026#34;x1\u0026#34;: randlist1, \u0026#34;x2\u0026#34;: randlist1 - randlist2, \u0026#34;y\u0026#34; : +1 } ) df = pd.concat([data_m1_0, data_p1_0], axis=0) plt.figure(figsize=(8,6)) plt.scatter(data_m1_0[\u0026#34;x1\u0026#34;], data_m1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;r\u0026#34;, alpha=0.5, linewidths=0) plt.scatter(data_p1_0[\u0026#34;x1\u0026#34;], data_p1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;b\u0026#34;, alpha=0.5, linewidths=0) plt.savefig(\u0026#34;/Users/wanghaoming/Documents/LaTeX_doc/Machine_Learning/non_sep.png\u0026#34;, bbox_inches=\u0026#39;tight\u0026#39;, dpi=500)   Building Pocket Model: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  plt.figure(figsize=(8,6)) plt.scatter(data_m1_0[\u0026#34;x1\u0026#34;], data_m1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;r\u0026#34;, alpha=0.5, linewidths=0) plt.scatter(data_p1_0[\u0026#34;x1\u0026#34;], data_p1_0[\u0026#34;x2\u0026#34;], c=\u0026#34;b\u0026#34;, alpha=0.5, linewidths=0) w = pd.Series([0, 0, 0], index=[\u0026#34;x0\u0026#34;, \u0026#34;x1\u0026#34;, \u0026#34;x2\u0026#34;]); times = 1; x=np.linspace(-5,5,100) mis_p = df[df[\u0026#34;y\u0026#34;]==+1][np.dot(df[df[\u0026#34;y\u0026#34;]==+1].iloc[:,0:df.shape[1]-1], w) \u0026lt;= 0] mis_n = df[df[\u0026#34;y\u0026#34;]==-1][np.dot(df[df[\u0026#34;y\u0026#34;]==-1].iloc[:,0:df.shape[1]-1], w) \u0026gt; 0] mis = pd.concat([mis_p, mis_n], axis=0) length = mis.shape[0] lengthl = [] T = 50000 for i in range(T): lengthl.append(length) mis_point = mis.iloc[np.random.randint(mis.shape[0]),:] w1 = w + mis_point[\u0026#34;y\u0026#34;] * mis_point.iloc[0: mis_point.shape[0]-1] mis_p = df[df[\u0026#34;y\u0026#34;]==+1][np.dot(df[df[\u0026#34;y\u0026#34;]==+1].iloc[:,0:df.shape[1]-1], w1) \u0026lt;= 0] mis_n = df[df[\u0026#34;y\u0026#34;]==-1][np.dot(df[df[\u0026#34;y\u0026#34;]==-1].iloc[:,0:df.shape[1]-1], w1) \u0026gt; 0] mis1 = pd.concat([mis_p, mis_n], axis=0) length1 = mis1.shape[0] if length1 \u0026lt; length: w = w1 mis = mis1 length=length1 lengthl.append(length) plt.plot(x, -(w[1]/w[2])*x - (w[0]/w[2]), \u0026#34;c\u0026#34;, label=f\u0026#34;end hypothesis (times={T})\u0026#34;) plt.legend() plt.savefig(\u0026#34;/Users/wanghaoming/Documents/LaTeX_doc/Machine_Learning/pocket.png\u0026#34;, bbox_inches=\u0026#39;tight\u0026#39;, dpi=500)   Error prediction number 1 2 3 4 5 6 7 8  ll = pd.Series(lengthl) plt.figure(figsize=(8,6)) ll.plot() plt.xscale(\u0026#34;log\u0026#34;) for i in range(1, len(ll)): if ll[i] \u0026lt; ll[i-1]: plt.text(i ,ll[i], ll[i]) plt.savefig(\u0026#34;/Users/wanghaoming/Documents/LaTeX_doc/Machine_Learning/minlen.png\u0026#34;, bbox_inches=\u0026#39;tight\u0026#39;, dpi=500)   $\\mathbb{R}\\times\\mathbb{R}$ $$ \\mathbf{R}\\mathbf{R} $$\n\\href{https://katex.org/}{\\frac{\\mathbf{w}_{f}^{T}\\mathbf{w}t}{||\\mathbf{w}{f}^{T}||\\cdot}}\n$$ \\mathbf{w}_{t}^T\\mathbf{w}_{t} $$\n$$ \\mathbf{R}^T\\mathbf{R} $$\n","date":"2020-03-04T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/perceptron-learning-algorithm/","title":"Perceptron Learning Algorithm"},{"content":"","date":"2020-02-16T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/high-performance-python-iv-distribute-computing-pyspark/","title":"High-Performance Python IV (Distribute Computing \u0026 PySpark)"},{"content":"","date":"2020-02-01T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/high-performance-python-iii-multi-process/","title":"High-Performance Python III (Multi Process)"},{"content":"","date":"2020-01-13T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/high-performance-python-ii-multi-threading/","title":"High-Performance Python II (Multi Threading)"},{"content":"","date":"2020-01-01T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/high-performance-python-i-asyncio-coroutine/","title":"High-Performance Python I (Asyncio \u0026 Coroutine)"},{"content":"OOP Fundamental The fundamental concepts of OOP are objects and classes. An object is a data structure incorporating information about state and behavior. For example, an object representing a customer can have a certain phone number and email associated with them, and behaviors like placeOrder or cancelOrder. The distinctive feature of OOP is that state and behavior are bundled together: instead of thinking of customer data separately from customer actions, we think of them as one unit representing a customer. This is called encapsulation, and it\u0026rsquo;s one of the core tenets of object-oriented programming.\nClasses are like blueprints for objects. They describe the possible states and behaviors that every object of a certain type could have. For example, if you say \u0026ldquo;every customer will have a phone number and an email, and will be able to place and cancel orders\u0026rdquo;, you just defined a class. This way, you can talk about customers in a unified way. In Python, everything is an object. In particular, everything you deal with in Python has a class, a blueprint associated with it under the hood. The existence of these unified interfaces, is why you can use one kind of object in the same way.\nClasses incorporate information about state and behavior. State information in Python is contained in attributes, and behavior information \u0026ndash; in methods. For example, every numpy array has an attribute \u0026ldquo;shape\u0026rdquo; and a method \u0026ldquo;reshape()\u0026rdquo;. Attributes (or states) in Python objects are represented by variables \u0026ndash; like numbers, or strings, or tuples. Methods, or behaviors, are represented by functions. Both are accessible from an object using the dot . syntax.\nYou can call type() on any Python object to find out its class. And You can list all the attributes and methods that an object has by calling dir() on it.\nAttributes and Method To start a new class definition, all you need is a class statement, followed by the name of the class, followed by a colon. Everything in the indented block after will be considered a part of the class. You can create an \u0026ldquo;empty\u0026rdquo; class by including the pass statement after the class declaration.\nWe can create objects of the class by specifying the name of the class, followed by parentheses. Here, c1 and c2 are two different objects of the empty class Customer.\n1 2 3 4 5 6 7 8  class Customer: pass c1 = Customer() c2 = Customer() print(c1) print(c2)   \u0026lt;__main__.Customer object at 0x7fbc4944ad00\u0026gt; \u0026lt;__main__.Customer object at 0x7fbc4944adc0\u0026gt; Defining a method is simple. Methods are functions, so the definition of a method looks just like a regular Python function, with one exception: the self argument that every method will have as the first argument, possibly followed by other arguments.\nClasses are templates. Objects of a class don\u0026rsquo;t yet exist when a class is being defined, but we often need a way to refer to the data of a particular object within class definition. That is the purpose of self - it\u0026rsquo;s a stand-in for the future object. That\u0026rsquo;s why every method should have the self argument \u0026ndash; so we could use it to access attributes and call other methods from within the class definition even when no objects were created yet. Python will handle self when the method is called from an object using the object.method() syntax. In fact, using object.method() is equivalent to passing that object as an argument. That\u0026rsquo;s why we don\u0026rsquo;t specify it explicitly when calling the method from an existing object.\n1 2 3 4 5 6  class Customer: def identify(self, name): print(\u0026#34;This is \u0026#34;+name) c1 = Customer() c1.identify(\u0026#34;haoming\u0026#34;)   This is haoming By the principles of OOP, the data describing the state of the object should be bundled into the object. For example, customer name should be an attribute of a customer object, instead of a parameter passed to a method. In Python attributes \u0026ndash; like variables \u0026ndash; are created by assignment, meaning an attribute manifests into existence only when a value is assigned to it. (thus you can modify attr by assignment either inside the class, i.e. method; or outside the class, assignment.)\nHere is a method set_name with arguments self and new_name. To create an attribute of the Customer class called \u0026ldquo;name\u0026rdquo;, all we need to do is to assign something to self.name. Here, we set the name attribute to the new_name parameter of the function. When we create a customer, it does not yet have a name attribute. But after the set_name method was called, the name attribute is created, and we can access it through .name.\n Remember, self is a stand-in for object, so self.attribute should remind you of the object.attribute syntax.\n 1 2 3 4 5 6 7 8  class Customer: def set_name(self, name): self.name = name def identify(self): print(\u0026#34;This is \u0026#34;+self.name) c1 = Customer() print(c1.name)   --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_74663/4057745890.py in \u0026lt;module\u0026gt; 6 7 c1 = Customer() ----\u0026gt; 8 print(c1.name) AttributeError: 'Customer' object has no attribute 'name' 1 2  c1.set_name(\u0026#34;haoming\u0026#34;) c1.identify()   This is haoming 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # -------- Example -------- # class Employee: def set_name(self, new_name): self.name = new_name def set_salary(self, new_salary): self.salary = new_salary def give_raise(self, amount): self.salary = self.salary + amount def monthly_salary(self): return self.salary/12 emp = Employee() emp.set_name(\u0026#39;Korel Rossi\u0026#39;) emp.set_salary(50000) emp.give_raise(15000) mon_sal = emp.monthly_salary() print(\u0026#34;annual package: \u0026#34;, emp.salary) print(\u0026#34;month salary: \u0026#34;, mon_sal)   annual package: 65000 month salary: 5416.666666666667 __init__ constructor We have discussed that methods are functions within class with a special first argument self, and attributes are created by assignment and referred to using the self variable within methods.\nA better strategy would be to add data to the object when creating it, like you do when creating a numpy array or a DataFrame. Python allows you to add a special method __init__ called the constructor that is automatically called every time an object is created.\nSo now, we can pass the parameter in the parentheses when creating the customer object, and the __init__ method will be automatically called, and the attribute created. The init constructor is also a good place to set the default values for attributes.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # -------- Example -------- # 1. from datetime import datetime class Employee: def __init__(self, name, salary=0): self.name = name if salary \u0026gt; 0: self.salary = salary else: self.salary = 0 print(\u0026#34;Invalid salary!\u0026#34;) self.hire_date = datetime.today() self.hire_date = datetime.today() def give_raise(self, amount): self.salary += amount def monthly_salary(self): return self.salary/12 emp = Employee(\u0026#34;Korel Rossi\u0026#34;, -1000)   Invalid salary! 1 2 3 4 5 6  print(emp.name) print(emp.salary) emp.give_raise(12324) print(emp.monthly_salary) print(emp.monthly_salary()) print(emp.hire_date)   Korel Rossi 0 \u0026lt;bound method Employee.monthly_salary of \u0026lt;__main__.Employee object at 0x7fbc68aa6b80\u0026gt;\u0026gt; 1027.0 2019-08-21 11:56:58.019767 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # -------- Example -------- # 2. class Point: def __init__(self,x=0,y=0): \u0026#34;\u0026#34;\u0026#34;Accepts two arguments that initialize the corresponding attributes. Args: x(float,optional) y(float,optional) \u0026#34;\u0026#34;\u0026#34; self.x = x self.y = y def distance_to_origin(self): \u0026#34;\u0026#34;\u0026#34;Returns the distance from the point to the origin.\u0026#34;\u0026#34;\u0026#34; dis = (self.x ** 2 + self.y ** 2) ** .5 return dis def reflect(self, axis): \u0026#34;\u0026#34;\u0026#34;Reflects the point with respect to the x- or y-axis\u0026#34;\u0026#34;\u0026#34; if axis == \u0026#34;x\u0026#34;: self.y = -self.y elif axis == \u0026#34;y\u0026#34;: self.x = -self.x else: print(\u0026#34;error message\u0026#34;) pt = Point(x=3.0) pt.reflect(\u0026#34;y\u0026#34;) print((pt.x, pt.y)) pt.y = 4.0 print(pt.distance_to_origin())   (-3.0, 0) 5.0 There are some conventions that will make your code more reader-friendly.\n  There are two ways to define attributes: we can define an attribute in any method in a class; and then calling the method will add the attribute to the object. Alternatively, we can define them all together in the constructor. If possible, use latter, which makes your code more organized, readable, and maintainable code.\n  For classes, words should be camel case, which means that if your class name contains several words, they should be written without delimiters, and each word should start with a capital letter. For methods and attributes, words should be separated by underscores and start with lowercase letters.\n  the name \u0026ldquo;self\u0026rdquo; is a convention. You could actually use any name for the first variable of a method, it will always be treated as the object reference regardless.\n  classes, like functions, allow for docstrings which are displayed when help() is called on the object.\n  Inheritance and Polymorphism Instance and class data Class-level attribute Remember the class we defined above. It had attributes like name and salary, and we were able to assign specific values to them for each new instance of the class. These were Instance-level attributes. We used self to bind them to a particular instance.\nBut if you needed to store some data that is shared among all the instances of a class, you can define an attribute directly in the class body. This will create a Class-level attribute, that will serve as a \u0026ldquo;global variable\u0026rdquo; within a class.\nWe can define Class-level attribute MIN_SALARY, and set it to 30000. We refer to the attribute this attribute inside the class like we would use any global variable, only follow by the class name, instead of self. This MIN_SALARY variable will be shared among all the instances of the employee class. We can access it like any other attribute from an object instance, and the value will be the same across instances. Here we print the MIN_SALARY class attribute from two employee objects.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Employee: MIN_SALARY = 30000 # \u0026lt;-- assign Class-level attr, directly without `self` def __init__(self, name, salary=0): self.name = name # \u0026lt;-- assign Instance-level attr, bounded with instance by `self` if salary \u0026gt; Employee.MIN_SALARY: # \u0026lt;-- refer Class-level attr inside the class self.salary = salary else: self.salary = Employee.MIN_SALARY emp1 = Employee(\u0026#34;Haoming\u0026#34;, 37000) emp2 = Employee(\u0026#34;Yachong\u0026#34;, 36999) print(emp1.name) print(emp1.salary) print(emp1.MIN_SALARY) # \u0026lt;-- refer Class-level attr outside the class print(emp2.MIN_SALARY) print(Employee.MIN_SALARY)   Haoming 37000 30000 30000 30000 Notice that you can modify Class-level attr by assigning value to obj.ATTR directly. But if you do that, the only thing you changed is the specific instance\u0026rsquo;s attr, rather than the all instance.\n1 2 3 4 5  emp1.MIN_SALARY = 34000 print(emp1.MIN_SALARY) print(emp2.MIN_SALARY) print(Employee.MIN_SALARY)   34000 30000 30000 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # -------- Example -------- # 1 class Player: MAX_POSITION = 10 def __init__(self): self.position = 0 def move(self, steps): if self.position + steps \u0026lt; Player.MAX_POSITION: self.position += steps else: self.position = Player.MAX_POSITION def draw(self): drawing = \u0026#34;-\u0026#34; * self.position + \u0026#34;|\u0026#34; +\u0026#34;-\u0026#34;*(Player.MAX_POSITION - self.position) print(drawing) p = Player(); p.draw() p.move(4); p.draw() p.move(5); p.draw() p.move(3); p.draw()   |---------- ----|------ ---------|- ----------| Class-level method Instance-level methods are already shared between instances: the same code gets executed for every instance. The only difference is the data (different instance\u0026rsquo;s attr) that is fed into it.\nIt is possible to define methods bound to class rather than an instance, but they have a narrow application scope, because these methods will not be able to use any instance-level data. To define a class method, you start with a classmethod decorator, followed by a method definition. The only difference is that now the first argument is not self, but cls, referring to the class, just like the self argument was a reference to a particular instance. To call a class method, we use class.method syntax, rather than object.method syntax.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class Employee: MIN_SALARY = 30000 def __init__(self, name, salary=0): self.name = name if salary \u0026gt; Employee.MIN_SALARY: self.salary = salary else: self.salary = Employee.MIN_SALARY @classmethod def minsalary(cls, min_salary): Employee.MIN_SALARY = min_salary @classmethod def delta_minsalary(cls, delta): Employee.MIN_SALARY += delta emp1 = Employee(\u0026#34;Haoming\u0026#34;, 37000) emp2 = Employee(\u0026#34;Yachong\u0026#34;, 36999) emp1.MIN_SALARY = 27000 print(\u0026#34;1: \u0026#34;, emp1.MIN_SALARY) print(\u0026#34;2: \u0026#34;, emp2.MIN_SALARY) Employee.minsalary(25000) print(\u0026#34;3: \u0026#34;, emp1.MIN_SALARY) print(\u0026#34;4: \u0026#34;, emp2.MIN_SALARY) Employee.delta_minsalary(500) print(\u0026#34;5: \u0026#34;, emp1.MIN_SALARY) print(\u0026#34;6: \u0026#34;, emp2.MIN_SALARY)   1: 27000 2: 30000 3: 27000 4: 25000 5: 27000 6: 25500 The main use of class methods is alternative constructors. A class can only have one __init__ method, but there might be multiple ways to initialize an object. For example, we might want to create an Employee object from data stored in a file. We can\u0026rsquo;t use a instance method, because it would require an instance, and there isn\u0026rsquo;t one yet.\nHere we introduce a class method from_file that accepts a file name, reads the first line from the file that presumably contains the name of the employee, and returns an object instance. In the return statement, we use the cls variable, which refers to the class that class method follows, so this will call (notice the parentheses) the class and activities the __init__ constructor, just like using Employee with parentheses, and finally return object instance.\nThen we can call the method from_file by using class.method syntax, which will create an employee object without explicitly calling the constructor.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  !echo haoming \u0026gt; ~/Documents/names.txt !echo yachong \u0026gt;\u0026gt; ~/Documents/names.txt !echo shaonan \u0026gt;\u0026gt; ~/Documents/names.txt class Employee: MIN_SALARY = 30000 def __init__(self, name, salary=0): self.name = name if salary \u0026gt; Employee.MIN_SALARY: self.salary = salary else: self.salary = Employee.MIN_SALARY @classmethod def from_file(cls, filename, index): with open(filename, \u0026#34;r\u0026#34;) as f: names = f.readlines() name = names[index] return cls(name) filename = \u0026#34;/Users/wanghaoming/Documents/names.txt\u0026#34; objs = [ Employee.from_file(filename, i) for i in range(3) ] info = [(obj.name, obj.salary) for obj in objs] print(info)   [('haoming\\n', 30000), ('yachong\\n', 30000), ('shaonan\\n', 30000)]  Notice that class is also an object, just like function.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # -------- Example -------- # from datetime import datetime class BetterDate: def __init__(self, year, month, day): self.year, self.month, self.day = year, month, day @classmethod def from_str(cls, datestr): year, month, day = map(int, datestr.split(\u0026#34;-\u0026#34;)) return cls(year, month, day) @classmethod def from_datetime(cls, datetime): year, month, day = datetime.year, datetime.month, datetime.day return cls(year, month, day) today = datetime.today() bd = BetterDate.from_datetime(today) print(bd.year) print(bd.month) print(bd.day)   2019 9 4 Class inheritance Object-oriented programming is fundamentally about code reuse. There are millions of people out there writing code, so there\u0026rsquo;s a good chance that someone has already written code that solves a part of your problem! But what if that code doesn\u0026rsquo;t match your needs exactly? For example, you might want to modify the to_csv method of a pandas DataFrame to adjust the output format. You could do that by importing pandas and writing a new function, but it will not be integrated into the DataFrame interface. OOP will allow you to keep interface consistent while customizing functionality.\nWe can accomplish this with inheritance. Class inheritance is mechanism by which we can define a new class that gets all the the functionality of another class plus maybe something extra without re-implementing the code.\nDeclaring a class that inherits from another class is very straightforward: you simply add parentheses after the class name, and then specify the class to inherit from. Here, we define a rudimentary BankAccount class and a seemingly empty SavingsAccount class inherited from it.\u0026ldquo;Seemingly\u0026rdquo; because SavingsAccount actually has exactly as much in it as the BankAccount class.\n1 2 3 4 5 6 7 8 9 10 11 12 13  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingsAccount(BankAccount): pass sa1 = SavingsAccount(10000) sa1.withdraw(1024) print(sa1.balance)   8976 Inheritance represents \u0026ldquo;is-a\u0026rdquo; relationship: a savings account is a bank account (The opposite is not true), just with some extra features. Calling isinstance function on a SavingsAccount object shows that Python treats it like an instance of both SavingsAccount and BankAccount classes, which is not the case for a generic BankAccount object.\n1 2 3 4 5 6  print(isinstance(sa1, BankAccount)) print(isinstance(sa1, SavingsAccount)) ba1 = BankAccount(1000) print(isinstance(ba1, BankAccount)) print(isinstance(ba1, SavingsAccount))   True True True False Class-level attributes CAN be inherited, and the value of class attributes CAN be overwritten in the child class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class Player: MAX_POSITION = 10 MAX_SPEED = 3 def __init__(self): self.position = 0 def move(self, steps): if self.position + steps \u0026lt; Player.MAX_POSITION: self.position += steps else: self.position = Player.MAX_POSITION class Racer(Player): MAX_SPEED = 5 p = Player() r = Racer() print(\u0026#34;p.MAX_SPEED = \u0026#34;, p.MAX_SPEED) print(\u0026#34;r.MAX_SPEED = \u0026#34;, r.MAX_SPEED) print(\u0026#34;p.MAX_POSITION = \u0026#34;, p.MAX_POSITION) print(\u0026#34;r.MAX_POSITION = \u0026#34;, r.MAX_POSITION)   p.MAX_SPEED = 3 r.MAX_SPEED = 5 p.MAX_POSITION = 10 r.MAX_POSITION = 10 Customizing functionality via inheritance Let\u0026rsquo;s customize SavingsAccount class by adding a constructor specifically for SavingsAccount. It will take a balance parameter, just like BankAccount, and an additional interest_rate parameter. In that constructor, we first run the code for creating a generic BankAccount by explicitly calling the __init__ method follows the bankAccount class name.\nNotice that we use BankAccount.__init__() to tell Python to call (note the parentheses) the constructor from the parent class, and we also pass self to that constructor. self in this case refers a SavingsAccount object, but also a BankAccount object. so we can pass it to the __init__ method of BankAccount. Then we can add more functionality, in this case just initializing an attribute.\nNow when we create an instance of the SavingsAccount class, the new constructor will be called, and the interest_rate attribute will be initialized.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingsAccount(BankAccount): def __init__(self, balance, interest_rate): BankAccount.__init__(self, balance) self.interest_rate = interest_rate sa = SavingsAccount(1000, 0.05) print(sa.balance, sa.interest_rate)   1000 0.05  Remember that in Python, instances of a subclass are also instances of the parent class.\n SavingsAccount inherits the withdraw method from the parent BankAccount class. Calling withdraw on a savings account instance will execute exactly the same code as calling it on a generic bank account instance.\nYou can add new methods to a subclass. In these methods you can use data from both the child and the parent class. For example here, we add a compute_interest method by an expression involving the balance attribute that inherits from the parent clsss ,and interest_rate attribute that exists only in the child SavingsAccount class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingsAccount(BankAccount): def __init__(self, balance, interest_rate): BankAccount.__init__(self, balance) self.interest_rate = interest_rate def compute_interest(self, n_periods=1): return self.balance * ((1 + self.interest_rate) ** n_periods - 1) sa = SavingsAccount(10000, .05) print(sa.compute_interest(5)) sa.withdraw(2048) print(sa.compute_interest(5))   2762.8156250000034 2196.9909850000026 You can also modify the method of parent class in the subclass. We now define another subclass of BankAccount. Start by inheriting from the parent class, add a customized constructor that also executes the parent code, a new deposit method, and a withdraw method with a new argument to withdraw fee.\n Notice that we can change the signature of the method in the subclass by adding a parameter, and we again, just like in the constructor, call the parent version of the method directly by using parentclassname.method(self) syntax and passing self. Notice the parentheses, that means we call this function.\n( you can view function signature as number of arguments + type of argument + return value )\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class CheckingAccount(BankAccount): def __init__(self, balance, limit): BankAccount.__init__(self, balance) self.limit = limit def deposit(self, amount): self.balance += amount def withdraw(self, amount, fee=0): if fee \u0026lt;= self.limit: BankAccount.withdraw(self, amount+fee) else: BankAccount.withdraw(self, amount+self.limit) ca = CheckingAccount(10000, 50) ba = BankAccount(10000) print(ca.balance) ca.withdraw(6000, 34) ba.withdraw(6000) print(ca.balance) print(ba.balance)   10000 3966 4000 Now when you call withdraw from an object that is a CheckingAccount instance, the new customized version will be used, but when you call it from regular BankAccount, the basic version will be used. For a CheckingAccount instance, we could call the method with 2 parameters. But trying this call for a generic BankAccount instance would cause an error, because the method defined in the BankAccount class was not affected by the changes in the subclass.\nThe interface of the call is the same, and the actual method that is called is determined by the instance class. This is an application of polymorphism.\n1  ba.withdraw(300, 30)   --------------------------------------------------------------------------- TypeError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_74663/1465132301.py in \u0026lt;module\u0026gt; ----\u0026gt; 1 ba.withdraw(300, 30) TypeError: withdraw() takes 2 positional arguments but 3 were given  withdraw() takes self and amount 2 positional arguments.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # -------- Example -------- # class Employee: def __init__(self, name, salary=30000): self.name = name self.salary = salary def give_raise(self, amount): self.salary += amount class Manager(Employee): def display(self): print(\u0026#34;Manager \u0026#34;, self.name) def __init__(self, name, salary=50000, project=None): Employee.__init__(self, name, salary) self.project = project def give_raise(self, amount, bonus=1.05): Employee.give_raise(self, amount*bonus) mngr = Manager(\u0026#34;Ashta Dunbar\u0026#34;, 78500) mngr.give_raise(1000) print(mngr.salary) mngr.give_raise(2000, bonus=1.03) print(mngr.salary)   79550.0 81610.0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # -------- Example -------- # import pandas as pd class LoggedDF(pd.DataFrame): def __init__(self, *args, **kwargs): pd.DataFrame.__init__(self, *args, **kwargs) self.created_at = datetime.today() def to_csv(self, *args, **kwargs): temp = self.copy() # \u0026lt;-- `self` refers the object that method follows.  temp[\u0026#34;created_at\u0026#34;] = self.created_at pd.DataFrame.to_csv(temp, *args, **kwargs) LDF = LoggedDF( { \u0026#34;a\u0026#34;: [1,2,3,4,5], \u0026#34;b\u0026#34;: [2,3,4,5,6], \u0026#34;c\u0026#34;: [3,4,5,6,7] } ) LDF.to_csv(\u0026#34;~/Documents/LDF.csv\u0026#34;) !cat ~/Documents/LDF.csv   ,a,b,c,created_at 0,1,2,3,2019-09-04 20:05:50.471649 1,2,3,4,2019-09-04 20:05:50.471649 2,3,4,5,2019-09-09 20:05:50.471649 3,4,5,6,2019-09-09 20:05:50.471649 4,5,6,7,2019-09-09 20:05:50.471649 Integrating with Standard Python Comparison Here are two objects of the Customer class that have the same data. If we ask Python if these objects are equal, the answer is \u0026ldquo;False\u0026rdquo;. When an object is created, Python allocates a chunk of memory to that object, and the variable that the object is assigned to actually contains just the reference to the memory chunk.\n1 2 3 4 5 6 7 8 9  class Customer: def __init__(self, name, balance): self.name = name self.balance = balance customer1 = Customer(\u0026#34;haoming\u0026#34;, 20000) customer2 = Customer(\u0026#34;haoming\u0026#34;, 20000) customer1 == customer2   False When we call == to compare variables, Python acquiescently compares references of the memory chunk, not the data. Because customer1 and customer2 point to different chunks in memory, they are not considered equal.\n1 2  print(customer1) print(customer2)   \u0026lt;__main__.Customer object at 0x7fe21895adf0\u0026gt; \u0026lt;__main__.Customer object at 0x7fe21894f430\u0026gt; But we can define a special method for customizing comparison. The __eq__ method is implicitly called whenever two objects are compared to each other. We can re-define this method to execute custom comparison code. The method should accept two arguments, referring to the objects to be compared. They are usually called self and other by convention.\nNow, if we create two objects containing the same data and try to compare them using double equality sign, we see from the diagnostic printout that the __eq__ method is called, and the comparison returns \u0026ldquo;True\u0026rdquo;.\n1 2 3 4 5 6 7 8 9 10 11 12 13  class Customer: def __init__(self, name, balance): self.name = name self.balance = balance def __eq__(self, other): print(\u0026#34;__eq__() is called\u0026#34;) return (self.name == other.name) and (self.balance == other.balance) customer1 = Customer(\u0026#34;haoming\u0026#34;, 20000) customer2 = Customer(\u0026#34;haoming\u0026#34;, 20000) customer1 == customer2   __eq__() is called True Notice that the redefined __eq__ method compares instances by only attributes, which means though we\u0026rsquo;re comparing a Phone class instance with a BankAccount class instance, Python still returns True.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Phone: def __init__(self, number): self.number = number def __eq__(self, other): return self.number == other.number class BankAccount: def __init__(self, number, balance=0): self.number, self.balance = number, balance def withdraw(self, amount): self.balance -= amount def __eq__(self, other): return (self.number == other.number) acct = BankAccount(873555333) pn = Phone(873555333) print(acct == pn)   True But we can modify it by type function:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  class Phone: def __init__(self, number): self.number = number def __eq__(self, other): print(\u0026#34;Phone class\u0026#39;s __eq__\u0026#34;) return self.number == other.number class BankAccount: def __init__(self, number, balance=0): self.number, self.balance = number, balance def withdraw(self, amount): self.balance -= amount def __eq__(self, other): print(\u0026#34;BankAccount class\u0026#39;s __eq__\u0026#34;) return (self.number == other.number) and (type(self) == type(other)) acct = BankAccount(873555333) pn = Phone(873555333) print(acct == pn) print(pn == acct)   BankAccount class's __eq__ False Phone class's __eq__ True Notice that when comparing two object without inheriting relationship, the __eq__ of former object\u0026rsquo;s class will be called. self refers to this object, and other refers the later one, thus acct==pn is not equivalent with pn==acct.\nBut When we comparing two object with inheriting relationship, the subclass\u0026rsquo;s __eq__ will always be called.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Parent: def __eq__(self, other): print(\u0026#34;Parent\u0026#39;s __eq__() called\u0026#34;) return True class Child(Parent): def __eq__(self, other): print(\u0026#34;Child\u0026#39;s __eq__() called\u0026#34;) return True p = Parent() c = Child() print(p == c) print(c == p) print(c == c) print(p == p)   Child's __eq__() called True Child's __eq__() called True Child's __eq__() called True Parent's __eq__() called True  Recall, __init__ implicitly called as creating an instance; __eq__ implicitly called as calling ==.\n Python allows you to implement all the comparison operators in your custom class using special methods:\n   Operator Method     == __eq__()   != __ne__()   \u0026gt;= __ge__()   \u0026lt;= __le__()   \u0026gt; __gt__()   \u0026lt; __lt__()    String representation When calling print on an object of a custom class returns the object\u0026rsquo;s address in memory by default. But there are plenty of classes for which the printout is much more informative. For example, if we print a numpy array or a DataFrame, we\u0026rsquo;ll see the actual data contained in the object.\nThere are two special methods that we can define in a class that will return a printable representation of an object.\n__str__ method is executed when we call print or str on an object. __str__ is supposed to give an informal representation, suitable for an end user;\n1 2 3 4 5  import numpy as np npls = np.array([1,2,3]) print(npls) str(npls)   [1 2 3] '[1 2 3]' __repr__ method is executed when we call repr on the object, or when we print it in the console without calling print explicitly. __repr__ is mainly used by developers.\n1  repr(npls)   'array([1, 2, 3])' 1  npls   array([1, 2, 3]) __str__ and __repr__ accept only self argument and return a string. The best practice is to use __repr__ to print a string that can be used to reproduce the object. (reproduce means the return of __repr__ could create the same object directly.)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  class Customer: def __init__(self, name, balance): self.name = name self.balance = balance def __eq__(self, other): print(\u0026#34;__eq__() is called\u0026#34;) return (self.name == other.name) and (self.balance == other.balance) def __repr__(self): return \u0026#34;Customer(\u0026#39;{name}\u0026#39;, {balance})\u0026#34;.format(name=self.name, balance=self.balance) c1 = Customer(\u0026#34;haoming\u0026#34;, 142857) cc1 = eval(repr(c1)) print(type(cc1)) print(cc1 == c1)   \u0026lt;class '__main__.Customer'\u0026gt; __eq__() is called True  eval function accepts the string of an expression and return the value of the expression.\n If you only choose to implement one of them, chose __repr__, because it is also used as a fallback for print when __str__ is not defined.\n1 2 3 4 5 6 7 8 9  class Customer: def __init__(self, name, balance): self.name = name self.balance = balance def __repr__(self): return \u0026#34;Customer(\u0026#39;{name}\u0026#39;, {balance})\u0026#34;.format(name=self.name, balance=self.balance) c1 = Customer(\u0026#34;haoming\u0026#34;, 142857)   1  repr(c1)   Customer('haoming', 142857) 1  print(c1)   Customer('haoming', 142857) In this class we didn\u0026rsquo;t define the __str__ method, so __repr__ will be used as a fallback for the actual print method as well. Notice the single quotes around the name in the return statement, the point of __repr__ is to give the exact call needed to reproduce the the object, where the name should be in quotes.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # -------- Example -------- # class Employee: def __init__(self, name, salary=30000): self.name, self.salary = name, salary def __str__(self): s = \u0026#34;Employee name: {name}\\nEmployee salary: {salary}\u0026#34;.format(name=self.name, salary=self.salary) return s def __repr__(self): return \u0026#34;Employee(\u0026#39;{}\u0026#39;, {})\u0026#34;.format(self.name, self.salary) emp1 = Employee(\u0026#34;Amar Howard\u0026#34;, 30000) emp2 = Employee(\u0026#34;Carolyn Ramirez\u0026#34;, 35000) print(emp1) print(emp2) print(\u0026#34;\\n\u0026#34;) print(repr(emp1)) print(repr(emp2))   Employee name: Amar Howard Employee salary: 30000 Employee name: Carolyn Ramirez Employee salary: 35000 Employee('Amar Howard', 30000) Employee('Carolyn Ramirez', 35000)  Recall, the triple quotes are used in Python to define multi-line strings, and the format method is used on strings to substitute values inside curly brackets with variables.\n Exceptions Some statements in Python will cause an error when you try to execute them. These errors are called exceptions. Many exceptions have special names, like ZeroDivisionError or TypeError. If exceptions not handled correctly, they will stop the execution of your program entirely.\nInstead, you might want to execute special code to handle this case. To catch an exception and handle it, use the try-except-finally code: wrap the code that you\u0026rsquo;re worried about in a try block, then add an except block, followed by the name of the particular exception you want to handle (exceptions names are optional) , and the code that should be executed when the exception is raised. Then if this particular exception does happen, the program will not terminate, but execute the code in the except block instead. You can also have multiple exception blocks. And finally, you can use the optional \u0026ldquo;finally\u0026rdquo; block that will contain the code that runs no matter what. This block is best used for cleaning up like, for example, closing opened files.\n1 2 3 4 5 6 7 8  try: # Try running some code except ZeroDivisionError: # Run this code if ZeroDivisionError happens except TypeError: # Run this code if TypeError happens finally: # \u0026lt;-- optional # Run this code no matter what   Sometimes, you want to raise exceptions yourself, for example when some conditions aren\u0026rsquo;t satisfied. You can use the raise keyword, optionally followed by a specific error message in parentheses. The user of the code can then decide to handle the error using try/except.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  def make_list_of_ones(length): if length \u0026lt;=0 : raise ValueError(\u0026#34;Invalid length!\u0026#34;) return [1]*length def tef(func, arg): try: func(arg) except ValueError: print(\u0026#34;length should be positive!\u0026#34;) finally: print(\u0026#34;program is over.\u0026#34;) tef(make_list_of_ones, -1)   length should be positive! program is over. You can define your own exceptions in Python by inheriting from built-in classes BaseException or Exception. To define a custom exception, just define a class that inherits from the built-in Exception class or one of its subclasses. The class itself can be empty - inheritance alone is enough to ensure that Python will treat this class as an exception class.\nFor example, let\u0026rsquo;s define a BalanceError class that inherits from Exception. Then, in Customer class we raise an exception if a negative balance value is passed to the constructor.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class BalanceError(Exception): pass class Customer: def __init__(self, name, balance): if balance \u0026lt; 0: raise BalanceError(\u0026#34;balance must be positive\u0026#34;) else: self.name = name self.balance = balance try: c1 = Customer(\u0026#34;haoming\u0026#34;, -1000) except BalanceError: c1 = Customer(\u0026#34;haoming\u0026#34;, 0) print(\u0026#34;balance must be positive, the account with 0 balance value has been created.\u0026#34;)   except block for a parent exception will catch child exceptions, but the opposite is not true:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class SalaryError(ValueError): pass class BonusError(SalaryError): pass class Employee: MIN_SALARY = 30000 MAX_BONUS = 5000 def __init__(self, name, salary = 30000): self.name = name if salary \u0026lt; Employee.MIN_SALARY: raise SalaryError(\u0026#34;Salary is too low!\u0026#34;) self.salary = salary def give_bonus(self, amount): if amount \u0026gt; Employee.MAX_BONUS: raise BonusError(\u0026#34;The bonus amount is too high!\u0026#34;) elif self.salary + amount \u0026lt; Employee.MIN_SALARY: raise SalaryError(\u0026#34;The salary after bonus is too low!\u0026#34;) else: self.salary += amount emp = Employee(\u0026#34;Katze Rik\u0026#34;, salary=50000)   1 2 3 4  try: emp.give_bonus(7000) # bonus \u0026gt; MAX_BONUS --\u0026gt; BonusError Caught except SalaryError: print(\u0026#34;SalaryError caught!\u0026#34;)   SalaryError caught! 1 2 3 4  try: emp.give_bonus(7000) # bonus \u0026gt; MAX_BONUS --\u0026gt; BonusError Caught except BonusError: print(\u0026#34;BonusError caught!\u0026#34;)   BonusError caught! 1 2 3 4  try: emp.give_bonus(-100000) # salary + amount \u0026lt; MIN_SALARY --\u0026gt; SalaryError Caught except SalaryError: print(\u0026#34;SalaryError caught again!\u0026#34;)   SalaryError caught again! 1 2 3 4  try: emp.give_bonus(-100000) # salary + amount \u0026lt; MIN_SALARY --\u0026gt; SalaryError Caught except BonusError: print(\u0026#34;BonusError caught again!\u0026#34;)   --------------------------------------------------------------------------- SalaryError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_57175/1321339394.py in \u0026lt;module\u0026gt; 1 try: ----\u0026gt; 2 emp.give_bonus(-100000) # salary + amount \u0026lt; MIN_SALARY --\u0026gt; SalaryError Caught 3 except BonusError: 4 print(\u0026quot;BonusError caught again!\u0026quot;) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_57175/1909163033.py in give_bonus(self, amount) 17 18 elif self.salary + amount \u0026lt; Employee.MIN_SALARY: ---\u0026gt; 19 raise SalaryError(\u0026quot;The salary after bonus is too low!\u0026quot;) 20 21 else: SalaryError: The salary after bonus is too low! If you don\u0026rsquo;t specify the exception name behind the except, then Python views it as Exception, thus every exceptions will be caught.\n1 2 3 4  try: emp.give_bonus(-100000) except Exception: # or just `except:`  print(\u0026#34;BonusError caught again!\u0026#34;)   BonusError caught again! It\u0026rsquo;s better to include an except block for a child exception before the block for a parent exception, otherwise the child exceptions will be always be caught in the parent block, and the except block for the child will never be executed.\n1 2 3 4 5 6 7 8  emp = Employee(\u0026#34;Katze Rik\u0026#34;,\\ 50000) try: emp.give_bonus(7000) # sub error except BonusError: print(\u0026#34;BonusError caught\u0026#34;) except SalaryError: print(\u0026#34;SalaryError caught\u0026#34;)   BonusError caught 1 2 3 4 5 6 7 8  emp = Employee(\u0026#34;Katze Rik\u0026#34;,\\ 50000) try: emp.give_bonus(7000) # sub error except SalaryError: print(\u0026#34;SalaryError caught\u0026#34;) except BonusError: print(\u0026#34;BonusError caught\u0026#34;)   SalaryError caught Class Design Liskov substitution principle Polymorphism means using a unified interface to operate on objects of different classes just as We\u0026rsquo;ve already dealt with pd.DataFrame.\nRecall that we defined a BankAccount class, and two classes inherited from it: a CheckingAccount class and a SavingsAccount class. All of them had a withdraw method, but the CheckingAccount\u0026rsquo;s method was executing different code.\nLet\u0026rsquo;s say we defined a function to withdraw the same amount of money from a whole list of accounts at once. This function doesn\u0026rsquo;t know whether the objects passed to it are CheckingAccount, SavingsAccount or just BankAccount. All that matters is that they have a withdraw method that accepts one argument. That is enough to make the function work. It does not check which withdraw it should call \u0026ndash; the original or the modified. When the withdraw method is actually called, Python will dynamically pull the correct method: modified withdraw for whenever a CheckingAccount is being processed,and base withdraw for whenever a SavingAccount or generic BankAccount is processed. So you, as a person writing this batch processing function, don\u0026rsquo;t need to worry about what exactly is being passed to it, only what kind of interface it has. To really make use of this idea, you have to design your classes with inheritance and polymorphism - the uniformity of interface - in mind.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingsAccount(BankAccount): pass class CheckingAccount(BankAccount): def __init__(self, balance, limit): BankAccount.__init__(self, balance) self.limit = limit def deposit(self, amount): self.balance += amount def withdraw(self, amount, fee=20): if fee \u0026lt;= self.limit: BankAccount.withdraw(self, amount+fee) else: BankAccount.withdraw(self, amount+self.limit) def batch_withdraw(list_of_accounts, amount): for acct in list_of_accounts: acct.withdraw(amount) a1 = BankAccount(1000) a2 = SavingsAccount(2000) a3 = CheckingAccount(3000, 50) accounts = [a1, a2, a3] batch_withdraw(accounts, 500) repr([ac.balance for ac in accounts])   '[500, 1500, 2480]' There is a fundamental object-oriented design principle of when and how to use inheritance properly, called \u0026ldquo;Liskov substitution principle (LSP)\u0026quot;: A base class should be interchangeable with any of its subclasses without altering any properties of the surrounding program.\nOn the one hand, the method in a subclass should have a signature with parameters and returned values compatible with the method in the parent class. On the other hand, the state of objects also must stay consistent; the subclass method shouldn\u0026rsquo;t rely on stronger input conditions, should not provide weaker output conditions, it should not throw additional exceptions and so on.\n The state of an object is it\u0026rsquo;s attributes with it\u0026rsquo;s values. To modify an object\u0026rsquo;s state, a method need to have access to this object. For ordinary methods, this is provided by the self parameter. Python\u0026rsquo;s classes are objects, so Python has \u0026ldquo;classmethods\u0026rdquo; which can be invoked on either an instance or the class itself, but get the class object itself instead of an instance. Those classmethods can then modify the class\u0026rsquo;s state (class attributes, which are shared by all instances of the class).\n The ultimate rule is that if your class hierarchy violates the Liskov substitution principle, then you should not be using inheritance, because it is likely to cause the code to behave in unpredictable ways somewhere down the road.\nUsing the example of our Account hierarchy, that means that wherever in your application you use a BankAccount object instance, substituting a CheckingAaccount instead should not affect anything in the surrounding program. For example, the batch withdraw functions worked regardless of what kind of account was used.\nLet\u0026rsquo;s illustrate some possible violations of LSP on our account classes: for example,\n the parent\u0026rsquo;s \u0026ndash; or base\u0026rsquo;s \u0026ndash; withdraw method could require 1 parameter, but the subclass method could require 2. Then we couldn\u0026rsquo;t use the subclass\u0026rsquo;s withdraw in place of the parent\u0026rsquo;s. But if the subclass method has a default value for the second parameter, then there is no problem. If the subclass method only accepts certain amounts, unlike the base one, then sometimes the subclass could not be used in place of the base class, if those unsuitable amounts are used. If the base withdraw had a check for whether the resulting balance is positive, and only performed the withdraw in that case, but the subclass did not do that, we wouldn\u0026rsquo;t be able to use subclass in place of the base class, because it\u0026rsquo;s possible that ambient program depends on the fact that the balance is always positive after withdraw.  The classic example of a problem that violates the Liskov Substitution Principle is the Circle-Ellipse problem, sometimes called the Square-Rectangle problem. By all means, it seems like you should be able to define a class Rectangle, with attributes h and w (for height and width), and then define a class Square that inherits from the Rectangle. After all, a square \u0026ldquo;is-a\u0026rdquo; rectangle! Unfortunately, this intuition doesn\u0026rsquo;t apply to object-oriented design.\n1 2 3 4 5 6 7 8 9 10 11 12 13  class Rectangle: def __init__(self, h, w): self.h = h self.w = w class Square(Rectangle): def __init__(self, w): self.h = w self.w = w s1 = Square(4) s1.h = 7 print(s1.w, s1.h)   4 7 For example, we create a Square object with side length 4. Then the 4x4 Square object would no longer be a square if we assign 7 to h. A Square inherited from a Rectangle will always have both the h and w attributes, but we can\u0026rsquo;t allow them to change independently of each other. We can make such modifies:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Rectangle: def __init__(self, w,h): self.w, self.h = w,h def set_h(self, h): self.h = h def set_w(self, w): self.w = w class Square(Rectangle): def __init__(self, w): self.w, self.h = w, w def set_h(self, h): self.h = h self.w = h def set_w(self, w): self.h = w self.w = w   But these setter methods violate Liskov Substitution principle. Each of the setter methods of Square change both h and w attributes, while setter methods of Rectangle change only one attribute at a time, so the Square objects cannot be substituted for Rectangle into programs that rely on one attribute staying constant.\nPrivate attributes Any attribute or method of any class in Python can be accessed by anyone. There are a few ways to manage access to data. We can use some universal naming conventions to signal that the data is not for external consumption.\n_xxx When involving the attribute and method, the leading underscore has an conventional meaning. It is a tips to developer that Python community reach a consensus where this attribute or method are for internal use only. This convention is defined in PEP 8.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class MyClass: def my_func(self): print(\u0026#34;I Love Python.\u0026#34;) self.at1 = 1 self._at2 = 2 def _my_func(self): print(\u0026#34;I Love Python too.\u0026#34;) self.at3 = 3 self._at4 = 4 mc = MyClass() mc.my_func() mc._my_func() print(mc.at1, mc._at2, mc.at3, mc._at4)   I Love Python. I Love Python too. 1 2 3 4 You can see that _my_func() or _at2 does not prevent us from entering the class. This because it is not mandatory, just conventional. However, the leading underscore does generate affection when importing from modules.\nNow, if you use wildcards * to import all names from a module, Python does not import names with leading underscores (but the methods and attributes warped by unprefixed object can be imported).\nFor example, we write such a module, and name it as my_module.py.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class MyClass: def my_func(self): self.at1 = 1 self._at2 = 2 def _my_func(self): self.at3 = 3 self._at4 = 4 def my_func3(): def _my_func4(): print(\u0026#34;test\u0026#34;) return _my_func4 def _my_func2(): print(\u0026#34;test\u0026#34;)   import the module with wildcard:\n1 2 3 4 5 6 7  from my_module import * mc = MyClass() mc.my_func() mc._my_func() print(mc.at1, mc._at2, mc.at3, mc._at4) my_func3()()   1 2 3 4 test 1  _my_func2()   --------------------------------------------------------------------------- NameError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_25437/3445096031.py in \u0026lt;module\u0026gt; ----\u0026gt; 1 _my_func2() NameError: name '_my_func2' is not defined Unlike wildcard imports, regular imports are not affected by the leading single underscore naming convention:\n1 2  import my_module as mm mm._my_func2()   test In general, you should avoid wildcard imports and calling the leading underlined methods and attributes in public space.\n__xxx The double leading underscore prefix causes the Python interpreter to override attribute/method names to avoid naming conflicts in subclasses. This is also called name mangling - the interpreter changes the name of a variable so that it is less likely to collide when the class is extended.\n1 2 3 4 5 6 7 8 9 10  class Test: def __init__(self): self.foo = 11 self._bar = 23 self.__baz = 23 def __func(self): print(\u0026#34;test\u0026#34;) t = Test() dir(t)   ['_Test__baz', # \u0026lt;--- '_Test__func', # \u0026lt;--- ... '_bar', 'foo'] You will see that there is a attribute on this object named _Test__baz and a method named _Test_func. This is the name modification that the Python interpreter does. It does this to avoid subclasses overwriting base class attributes and methods.\nLet\u0026rsquo;s create a subclass that extends the Test class and try to override the existing attributes/method added in the constructor:\n1 2 3 4 5 6 7 8 9 10 11 12 13  class ExtendedTest(Test): def __init__(self): super().__init__() self.foo = \u0026#39;overridden\u0026#39; self.__baz = \u0026#39;overridden\u0026#39; def __func(self): print(\u0026#34;test1\u0026#34;) t2 = ExtendedTest() print(t2.foo) print(t2._bar) print(t2.__baz)   overridden 23 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_29055/1866563237.py in \u0026lt;module\u0026gt; 11 print(t2.foo) 12 print(t2._bar) ---\u0026gt; 13 print(t2.__baz) AttributeError: 'ExtendedTest' object has no attribute '__baz' 1  dir(t2)   ['_ExtendedTest__baz', # \u0026lt;-- '_ExtendedTest__func', # \u0026lt;-- '_Test__baz', # \u0026lt;-- '_Test__func', # \u0026lt;-- ... '_bar', 'foo'] You will find the __baz attribute and __func method of subclass has been renemed by Python interpreter as _ExtendedTest__baz and _ExtendedTest__func. Thus __baz/__func of base class has not been overrided by subclass.\n1 2 3 4  print(t2._Test__baz) t2._Test__func() print(t2._ExtendedTest__baz) t2._ExtendedTest__func()   23 test overridden test1  Click here or here for more information.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # -------- Example -------- # class BetterDate: _MAX_DAYS = 30 _MAX_MONTHS = 12 def __init__(self, year, month, day): self.year, self.month, self.day = year, month, day @classmethod def from_str(cls, datestr): year, month, day = map(int, datestr.split(\u0026#34;-\u0026#34;)) return cls(year, month, day) def _is_valid(self): return (self.day \u0026lt;= BetterDate._MAX_DAYS) and (self.month \u0026lt;= BetterDate._MAX_MONTHS) bd1 = BetterDate(2020, 4, 30) print(bd1._is_valid()) bd2 = BetterDate(2020, 6, 45) print(bd2._is_valid())   True False Properties We have worked with an Employee class where we defined methods like set_salary that were used to set the values for attributes. Later, we use the constructor to initialize the attributes . We can access and change the attributes directly by assignment. But this means that with a simple equality we can assign anything to salary: a million, a negative number, or even the word \u0026ldquo;Hello\u0026rdquo;. But salary should only be positive number.\nSo how do we control attribute access, validate it or even make the attribute read-only? We could modify the set_salary method, but that wouldn\u0026rsquo;t help, because we could still use the dot syntax and assignment via equality.\nWe can reach there using the property decorator.\n Start by defining an \u0026ldquo;internal\u0026rdquo; attribute that will store the data, it is recommended to start the name with one leading underscore. Here, we defined a _salary attribute. Next, we define a method whose name is the exact name we\u0026rsquo;d like the restricted attribute to have, and put a decorator \u0026ldquo;property\u0026rdquo; on it. In our case that method is called salary, without underscore, because that\u0026rsquo;s how we\u0026rsquo;d like to refer to it. If we were writing a DataFrame class, this could be \u0026ldquo;columns\u0026rdquo;, or \u0026ldquo;shape\u0026rdquo;. The method just returns the actual internal attribute that is storing the data. To customize how the attribute is set, we implement a method with a decorator \u0026lt;attribute-name\u0026gt;.setter: salary.setter in our case. The method itself is again named exactly the same as the property \u0026ndash; salary - and it will be called when a value is assigned to the property attribute. It has a self argument, and an argument that represents the value to be assigned. Here we raise an exception if the value is negative, otherwise change the internal attribute.  1 2 3 4 5 6 7 8 9 10 11 12 13  class Employer: def __init__(self, name, new_salary): self._salary = new_salary @property def salary(self): return self._salary @salary.setter def salary(self, new_salary): if new_salary \u0026lt; 0: raise ValueError(\u0026#34;Invalid salary\u0026#34;) self._salary = new_salary   So there are two methods called salary \u0026ndash; the name of the property \u0026ndash; that have different decorators. The method with property decorator returns the data, and the method with salary.setter decorator implements validation and sets the attribute.\nWe can use this property just as if it was a regular attribute (remember the only real attribute we have is the internal underscore-salary). Use the dot syntax and equality sign to assign a value to the salary property. Then, the setter method will be called. If we try to assign a negative value to salary, an exception will be raised.\n1 2 3 4 5  emp = Employer(\u0026#34;haoming\u0026#34;, 35000) print(emp.salary) # \u0026lt;-- accessing the property emp.salary = 60000 # \u0026lt;-- @salary.setter print(emp.salary) # \u0026lt;-- accessing the property again emp.salary = -1   35000 60000 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_29055/2378834019.py in \u0026lt;module\u0026gt; ----\u0026gt; 1 emp.salary = -1 /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_29055/3054542886.py in salary(self, new_salary) 10 def salary(self, new_salary): 11 if new_salary \u0026lt; 0: ---\u0026gt; 12 raise ValueError(\u0026quot;Invalid salary\u0026quot;) 13 self._salary = new_salary 14 ValueError: Invalid salary 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # -------- Example -------- # class Customer: def __init__(self, name, new_bal): self.name = name if new_bal \u0026lt; 0: raise ValueError(\u0026#34;Invalid balance!\u0026#34;) self._balance = new_bal @property def balance(self): print(\u0026#34;property called\u0026#34;) return self._balance @balance.setter def balance(self, new_bal): if new_bal \u0026lt; 0: raise ValueError(\u0026#34;Invalid balance!\u0026#34;) self._balance = new_bal print(\u0026#34;Setter method called\u0026#34;) cust = Customer(\u0026#34;Belinda Lutz\u0026#34;, 2000) print(cust.balance) cust.balance = 3000 print(cust.balance)   property called 2000 Setter method called property called 3000 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # -------- Example -------- # import pandas as pd from datetime import datetime class LoggedDF(pd.DataFrame): def __init__(self, *args, **kwargs): pd.DataFrame.__init__(self, *args, **kwargs) self._created_at = datetime.today() def to_csv(self, *args, **kwargs): temp = self.copy() temp[\u0026#34;created_at\u0026#34;] = self._created_at pd.DataFrame.to_csv(temp, *args, **kwargs) # Add a read-only property: _created_at @property def created_at(self): return self._created_at # Instantiate a LoggedDF called ldf ldf = LoggedDF({\u0026#34;col1\u0026#34;: [1,2], \u0026#34;col2\u0026#34;:[3,4]}) print(ldf.created_at)   2019-09-10 14:56:45.115035 There are a few other things you can do with properties: if you do not define a setter method, the property will be read-only, like Dataframe shape. A method with an \u0026lt;attribute-name\u0026gt;.getter decorator will be called when the property\u0026rsquo;s value is just retrieved, and the method with the \u0026lt;attribute-name\u0026gt;.deleter \u0026ndash; when an attribute is deleted.\n","date":"2019-09-10T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-iv-class/","title":"Object Oriented Programming IV (Class)"},{"content":"","date":"2019-09-10T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-v-special-attributes-magic-methods/","title":"Object Oriented Programming V (Special Attributes \u0026 Magic Methods)"},{"content":"1. OOP Fundamental 1.1 Attributes and Method 1 2 3 4 5 6 7 8 9 10 11 12  class Employee: def set_name(self, new_name): self.name = new_name def set_salary(self, new_salary): self.salary = new_salary def give_raise(self, amount): self.salary = self.salary + amount def monthly_salary(self): return self.salary / 12   method = function; attribute = variable\n1 2 3 4  # self 就是对象 object 的替身 emp = Employee() emp.set_salary(1000) # 理解为 set_salary(emp, 10000)  self.salary # 理解为 emp.salary   variable 可以打印, 也可以赋值\n1 2  emp.salary = emp.salary + 5000 # e.t. emp.give_raise(5000)   注意method可以不指定参数\n1  emp.monthly_salary() # e.t. emp.salary / 12   class 是模板, object 是具有不同状态值的类的实例. method 是calss 中的函数, 具有特殊的第一个参数self, self 是未来 object 的替身. attribute 通过赋值创建, 并在 method 中使用 self 变量调用.\n the name \u0026ldquo;self\u0026rdquo; is a convention. You could actually use any name for the first variable of a method, it will always be treated as the object reference regardless. But don\u0026rsquo;t do it, and always use \u0026ldquo;self\u0026rdquo;.\n classes, like functions, allow for docstrings which are displayed when help()is called on the object. Remember the first lesson of the course, and use the docstrings to make the life of the person using your class easier.\n1.2 constructor __init__() We learned that methods are functions within class with a special first argument self, and that attributes are created by assignment and referred to using the self variable within methods.\nIn the exercises, you created an Employee class, and for each attribute you wanted to create, you defined a new method, and then called those methods one after another. This could quickly get unsustainable if your classes contain a lot of data.\nA better strategy would be to add data to the object when creating it. Python allows you to add a special method called the constructor __init__() that is automatically called every time an object is created.\n Exercise 1 Instead of using the methods like set_salary() that you wrote in the previous lesson, you will introduce a constructor that assigns name and salary to the employee at the moment when the object is created.\n1 2 3 4 5 6 7 8 9 10 11 12 13  class Employee: # Create __init__() method def __init__(self, name, salary=0): # Create the name and salary attributes self.name = name self.salary = salary # From the previous lesson def give_raise(self, amount): self.salary += amount def monthly_salary(self): return self.salary/12   The __init__() method is a great place to do preprocessing. Modify __init__() to check whether the salary parameter is positive:\n if yes, assign it to the salary attribute, if not, assign 0 to the attribute and print \u0026ldquo;Invalid salary!\u0026rdquo;  1 2 3 4 5 6 7 8 9 10  class Employee: def __init__(self, name, salary=0): self.name = name # Modify code below to check if salary is positive if salary \u0026gt; 0: self.salary = salary else: self.salary = 0 print(\u0026#34;Invalid salary!\u0026#34;)   Import datetime from the datetime module. This contains the function that returns current date. Add an attribute hire_date and set it to datetime.today().\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # Import datetime from datetime from datetime import datetime class Employee: def __init__(self, name, salary=0): self.name = name if salary \u0026gt; 0: self.salary = salary else: self.salary = 0 print(\u0026#34;Invalid salary!\u0026#34;) # Add the hire_date attribute and set it to today\u0026#39;s date self.hire_date = datetime.today() # ...Other methods omitted for brevity ...    Exercise 2\nDefine the class Point that has:\n Two attributes, x and y - the coordinates of the point on the plane; A constructor that accepts two arguments, x and y, that initialize the corresponding attributes. These arguments should have default value of 0.0; A method distance_to_origin() that returns the distance from the point to the origin. A method reflect(), that reflects the point with respect to the x- or y-axis, accepts one argument axis,   if axis=\u0026quot;x\u0026quot; , it sets the y attribute to the negative value of the y attribute,     if axis=\u0026quot;y\u0026quot;, it sets the x attribute to the negative value of the x attribute,     for any other value of axis, prints an error message.    1 2 3 4 5 6 7 8 9 10 11 12 13 14  # Write the class Point as outlined in the instructions class Point: def __init__(self, x=0.0, y=0.0): self.x = x self.y = y def distance_to_origin(self): return (self.x**2 + self.y**2)**0.5 def reflect(self, axis): if axis == \u0026#34;x\u0026#34;: self.y = -self.y elif axis == \u0026#34;y\u0026#34;: self.x = -self.x else: print(\u0026#34;error\u0026#34;)    there are two ways to define attributes:\n we can define an attribute in any method in a class; and then calling the method will add the attribute to the object. we can define them all together in the constructor.  If possible, try to avoid defining attributes outside the constructor.\n easier to read all attributes defining all attributes in the constructor ensures that all of them are created when the object is created, so you don\u0026rsquo;t have to worry about trying to access an attribute that doesn\u0026rsquo;t yet exist All this results in more organized, readable, and maintainable code.  To name your classes, use camel case, which means that if your class name contains several words, they should be written without delimiters, and each word should start with a capital letter.\nFor methods and attributes, it\u0026rsquo;s the opposite \u0026ndash; words should be separated by underscores and start with lowercase letters.\n2. Inheritance and Polymorphism Inheritance and Polymorphism, together with encapsulation, form the core principles of OOP.\n2.1 Instance \u0026amp; Class * Attribute \u0026amp; Method Instance-level data you need to learn how to distinguish between instance-level data and class level data. Remember the Employee class you defined in the previous chapter. It had attributes like name and salary, and we were able to assign specific values to them for each new instance of the class. These were instance attributes. We used self to bind them to a particular instance.\nClass-level data But maybe you needed to store some data that is shared among all the instances of a class. For example, if you wanted to introduce a minimal salary across the entire organization. That data should not differ among object instances. Then, you can define an attribute directly in the class body. This will create a class attribute, that will serve as a \u0026ldquo;global variable\u0026rdquo; within a class. For example, we can define MIN_SALARY, and set it to 30000.\n1 2 3 4 5 6 7 8  class Employee: MIN_SALARY = 30000 # \u0026lt;-- Note1: no self def __init__(self, name, salary): self.name = name if salary \u0026gt; Employee.MIN_SALARY: # \u0026lt;-- Note2: Class_Name.Class_attribute self.salary = salary else: self.salary = Employee.MIN_SALARY   Note that we do not use self to define the attribute, and we use the class name instead of self when referring to the attribute.\nThis MIN_SALARY variable will be shared among all the instances of the employee class. We can access it like any other attribute from an object instance, and the value will be the same across instances.\n1 2  emp = Employee(\u0026#34;Tom\u0026#34;, 40000) print(emp.MIN_SALARY) # \u0026lt;-- Note3: object_name.Class_attribute   So, the main use case for class attributes is global constants that are related to class, for example min/max values for attributes \u0026ndash; like the min_salary example \u0026ndash; or commonly used values: for example,if you were defining a Circle class, you could store pi as a class attribute.\nClass methods What about methods? Regular methods are already shared between instances: the same code gets executed for every instance. The only difference is the data that is fed into it.\nIt is possible to define methods bound to class rather than an instance, but they have a narrow application scope, because these methods will not be able to use any instance-level data.\nTo define a class method, you start with a classmethod decorator @classmethod, followed by a method definition. The only difference is that now the first argument is not self, but cls, referring to the class, just like the self argument was a reference to a particular instance.\n1 2 3  class MyClass: @classmethod # \u0026lt;-- Note1: ues decorator to declare a class method def my_method(cls, args...): # \u0026lt;-- Note2: cls argument   Then you write it as any other function, keeping in mind that you can\u0026rsquo;t refer to any instance attributes in that method. To call a class method, we use class-dot-method syntax, rather than object-dot-method syntax.\n1  MyClass.my_method(args...) # Note3: Class_name.Class_method   Alternative constructors Python allows you to define class methods , using the @classmethod decorator and a special first argument cls. The main use of class methods is defining methods that return an instance of the class, but aren\u0026rsquo;t using the same code as __init__().\n A class can only have one __init__ method, but there might be multiple ways to initialize an object.\n For example, we might want to create an Employee object from data stored in a file. We can\u0026rsquo;t use a method, because it would require an instance, and there isn\u0026rsquo;t one yet! Here we introduce a class method from_file that accepts a file name, reads the first line from the file that presumably contains the name of the employee, and returns an object instance.\n1 2 3 4 5 6  class Employee: @classmethod def from_file(cls, filename): with open(filename, \u0026#34;r\u0026#34;) as f: name = f.readline() return cls(name)   In the return statement, we use the cls variable \u0026ndash; remember that now cls refers to the class, so this will call the __init__ constructor, just like using Employee with parentheses would when used outside the class definition.\nThen we can call the method from_file by using class-dot-method syntax, which will create an employee object without explicitly calling the constructor.\n1 2  emp = Employee.from_file(\u0026#34;employee_data.txt\u0026#34;) type(emp)       class attribute class method     define MIN_SALARY = 30000 @classmethod  def from_file(cls, filename):   call in class Employee.MIN_SALARY -   call out class emp.MIN_SALARY Employee.MIN_SALARY Employee.from_file     Exercise 1 Define a class Player that has:\n A class attribute MAX_POSITION with value 10. The __init__() method that sets the position instance attribute to 0. Print Player.MAX_POSITION. Create a Player object p and print its MAX_POSITION. Add a move() method with a steps parameter such that:   if position plus steps is less than MAX_POSITION, then add steps to position and assign the result back to position;     otherwise, set position to MAX_POSITION.    1 2 3 4 5 6 7 8 9 10 11 12  class Player: MAX_POSITION = 10 def __init__(self): self.position = 0 # Add a move() method with steps parameter def move(self, steps): if steps + self.position \u0026lt; Player.MAX_POSITION: self.position = self.position + steps else: self.position = Player.MAX_POSITION    Exercise 2 The Player class from the previous exercise is pre-defined. Recall that it has a position instance attribute, and MAX_SPEED and MAX_POSITION class attributes. The initial value of MAX_SPEED is 3.\n Create two Player objects p1 and p2. Print p1.MAX_SPEED and p2.MAX_SPEED. Assign 7 to p1.MAX_SPEED. Print p1.MAX_SPEED and p2.MAX_SPEED again. Print Player.MAX_SPEED.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # Create Players p1 and p2 p1 = Player() p2 = Player() print(\u0026#34;MAX_SPEED of p1 and p2 before assignment:\u0026#34;) # Print p1.MAX_SPEED and p2.MAX_SPEED print(p1.MAX_SPEED) print(p2.MAX_SPEED) # Assign 7 to p1.MAX_SPEED p1.MAX_SPEED = 7 print(\u0026#34;MAX_SPEED of p1 and p2 after assignment:\u0026#34;) # Print p1.MAX_SPEED and p2.MAX_SPEED print(p1.MAX_SPEED) print(p2.MAX_SPEED) print(\u0026#34;MAX_SPEED of Player:\u0026#34;) # Print Player.MAX_SPEED print(Player.MAX_SPEED)   1 2 3 4 5 6 7 8  MAX_SPEED of p1 and p2 before assignment: 3 3 MAX_SPEED of p1 and p2 after assignment: 7 3 MAX_SPEED of Player: 3   Even though MAX_SPEED is shared across instances, assigning 7 to p1.MAX_SPEED didn\u0026rsquo;t change the value of MAX_SPEED in p2, or in the Player class.\nSo what happened? In fact, Python created a new instance attribute in p1, also called it MAX_SPEED, and assigned 7 to it, without touching the class attribute.\nNow let\u0026rsquo;s change the class attribute value for real.\n Modify the assignment to assign 7 to Player.MAX_SPEED instead.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  print(\u0026#34;MAX_SPEED of p1 and p2 before assignment:\u0026#34;) # Print p1.MAX_SPEED and p2.MAX_SPEED print(p1.MAX_SPEED) print(p2.MAX_SPEED) # ---MODIFY THIS LINE---  Player.MAX_SPEED = 7 print(\u0026#34;MAX_SPEED of p1 and p2 after assignment:\u0026#34;) # Print p1.MAX_SPEED and p2.MAX_SPEED print(p1.MAX_SPEED) print(p2.MAX_SPEED) print(\u0026#34;MAX_SPEED of Player:\u0026#34;) # Print Player.MAX_SPEED print(Player.MAX_SPEED)    Exercise 3 you are developing a time series package and want to define your own class for working with dates, BetterDate. The attributes of the class will be year, month, and day. You want to have a constructor that creates BetterDate objects given the values for year, month, and day, but you also want to be able to create BetterDate objects from strings like 2020-04-30.\n  Add a class method from_str() that:\n  accepts a string datestr of the format'YYYY-MM-DD',\n  splits datestr and converts each part into an integer,\n  returns an instance of the class with the attributes set to the values extracted from datestr.\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class BetterDate: # Constructor def __init__(self, year, month, day): # Recall that Python allows multiple variable assignments in one line self.year, self.month, self.day = year, month, day # Define a class method from_str @classmethod def from_str(cls, datestr): # Split the string at \u0026#34;-\u0026#34; and convert each part to integer parts = datestr.split(\u0026#34;-\u0026#34;) year, month, day = int(parts[0]), int(parts[1]), int(parts[2]) # Return the class instance return cls(year, month, day) bd = BetterDate.from_str(\u0026#39;2020-04-30\u0026#39;) print(bd.year) print(bd.month) print(bd.day)   1 2 3  2020 4 30   For compatibility, you also want to be able to convert a datetime object into a BetterDate object.\n Add a class method from_datetime() that accepts a datetime object as the argument, and uses its attributes .year, .month and .day to create a BetterDate object with the same attribute values.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # import datetime from datetime from datetime import datetime class BetterDate: def __init__(self, year, month, day): self.year, self.month, self.day = year, month, day @classmethod def from_str(cls, datestr): year, month, day = map(int, datestr.split(\u0026#34;-\u0026#34;)) return cls(year, month, day) # Define a class method from_datetime accepting a datetime object @classmethod def from_datetime(cls, datetime): year, month, day = datetime.year, datetime.month, datetime.day return cls(year, month, day) # You should be able to run the code below with no errors:  today = datetime.today() bd = BetterDate.from_datetime(today) print(bd.year) print(bd.month) print(bd.day)   1 2 3  2022 3 16   2.2 Class inheritance Code reuse Object-oriented programming is fundamentally about code reuse. But what if that code doesn\u0026rsquo;t match your needs exactly? For example, you might want to modify the to_csv method of a pandas DataFrame to adjust the output format. You could do that by importing pandas and writing a new function, but it will not be integrated into the DataFrame interface. OOP will allow you to keep interface consistent while customizing functionality.\nInheritance We can accomplish this with inheritance. Class inheritance is mechanism by which we can define a new class that gets all the the functionality of another class plus maybe something extra without re-implementing the code.\nDeclaring a class that inherits from another class is very straightforward: you simply add parentheses after the class name, and then specify the class to inherit from. Here, we define a rudimentary BankAccount class and a seemingly empty SavingsAccount class inherited from it.\n1 2 3 4 5 6 7 8  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingsAccount(BankAccount): pass   \u0026ldquo;Seemingly\u0026rdquo; because SavingsAccount actually has exactly as much in it as the BankAccount class. For example, we can create an object \u0026ndash; even though we did not define a constructor \u0026ndash; and we can access the balance attribute and the withdraw method from the instance of SavingsAccount, even though these features weren\u0026rsquo;t defined in the new class.\n1  savings_acct = SavingsAccount(1000)   That\u0026rsquo;s because inheritance represents \u0026ldquo;is-a\u0026rdquo; relationship: a savings account is a bank account, just with some extra features. Calling isinstance function on a savingsaccount object shows that Python treats it like an instance of both savingsaccount and BankAccount classes,\n1 2 3 4 5 6 7  isinstance(saving_acct, SavingsAccount) True isinstance(saving_acct, BankAccount) True   which is not the case for a generic BankAccount object. i.e. every Child class is a Parent class, but the reverse is not necessarily true.\n1 2 3 4 5 6 7 8  acct = SavingsAccount(1000) isinstance(acct, SavingsAccount) False isinstance(acct, BankAccount) True    Exercise 1 Recall the Employee class from earlier in the course. In most organizations, managers enjoy more privileges and more responsibilities than a regular employee. So it would make sense to introduce a Manager class that has more functionality than Employee.\nBut a Manager is still an employee, so the Manager class should be inherited from the Employee class.\n Add an empty Manager class that is inherited from Employee. add a display() method to the Manager class that just prints the string \u0026ldquo;Manager\u0026rdquo; followed by the full name, e.g. \u0026ldquo;Manager Katie Flatcher\u0026rdquo; Create an object mng of the Manager class with the name Debbie Lashko and salary 86500. Print the name of mng.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Employee: MIN_SALARY = 30000 def __init__(self, name, salary=MIN_SALARY): self.name = name if salary \u0026gt;= Employee.MIN_SALARY: self.salary = salary else: self.salary = Employee.MIN_SALARY def give_raise(self, amount): self.salary += amount # Add a display method class Manager(Employee): def display(self): print(f\u0026#34;Manager {self.name}\u0026#34;) mng = Manager(\u0026#34;Debbie Lashko\u0026#34;, 86500) print(mng.name) # Call mng.display() mng.display()   2.3 Customizing functionality via inheritance Customizing constructors We could already create SavingsAccount objects, but they did not have any functionality that BankAccount did not have. Let\u0026rsquo;s start customization by adding a constructor specifically for SavingsAccount.\nIt will take a balance parameter, just like BankAccount, and an additional interest_rate parameter. In that constructor, we first run the code for creating a generic BankAccount by explicitly calling the init method of the bankAccount class.\n1 2 3  class SavingAccount(BankAccount): def __init__(self, balance, interest_rate): BankAccount.__init__(self, balance)   Notice that we use BankAccount-dot-init to tell Python to call the constructor from the parent class, and we also pass self to that constructor. Self in this case is a SavingsAccount \u0026ndash; that\u0026rsquo;s the class we\u0026rsquo;re in \u0026ndash; but remember that in Python, instances of a subclass are also instances of the parent class. so it is a BankAccount as well, and we can pass it to the init method of BankAccount. when we create an instance of the SavingsAccount class, the new constructor will be called, and in particular, the interest_rate attribute will be initialized.\n Then we can add more functionality, in this case just initializing an attribute. You actually aren\u0026rsquo;t required to call the parent constructor in the subclass, or to call it first \u0026ndash; you can use new code entirely \u0026ndash; but you\u0026rsquo;ll likely to almost always use the parent constructor.\n Customizing functionality In the exercises, you saw you can add methods to a subclass just like to any other class. In those methods you can use data from both the child and the parent class. For example here, we add a compute_interest method that returns the amount of interest in the account. Notice that we multiply the balance attribute - which was inherited from the BankAccount parent - by an expression involving the interest_rate attribute that exists only in the child SavingsAccount class.\n1 2 3 4 5 6 7 8 9 10 11 12  class BankAccount: def __init__(self, balance): self.balance = balance def withdraw(self, amount): self.balance -= amount class SavingAccount(BankAccount): def __init__(self, balance, interest_rate): BankAccount.__init__(self, balance) self.interest_rate = interest_rate def compute_interest(self, n_period = 1): return self.balance * ((1 + self.interest_rate) ** n_period -1)   Now let\u0026rsquo;s talk about customizing functionality. SavingsAccount inherits the withdraw method from the parent BankAccount class. Calling withdraw on a SavingsAccount instance will execute exactly the same code as calling it on a generic BankAccount instance. We want to create a CheckingAccount class, which should have a slightly modified version of the withdraw method: it will have a parameter and adjust the withdrawal amount.\nHere\u0026rsquo;s an outline of what that could look like. - Start by inheriting from the parent class,\n  add a customized constructor that also executes the parent code,\n  a new deposit method, and a withdraw method, but we add a new argument to withdraw - fee, that specifies the additional withdrawal fee.\n  We compare the fee to some fee limit, and then call the parent withdraw method, passing a new amount to it \u0026ndash; with fees subtracted.\n  1 2 3 4 5 6 7 8 9 10 11  class CheckingAccount(BankAccount): def __init__(self, balance, limit): BankAccount.__init__(self, content) self. limit = limit def deposit(self, amount): self.balance += amount def withdraw(self, amount, fee=0): if fee \u0026lt;= self.limit: BankAccount.withdraw(self, amount - fee) else: BankAccount.withdraw(self, amount - self.limit)   So this method runs almost the same code as the BankAccount\u0026rsquo;s withdraw method without re-implementing it - just augmenting.\nNotice that we can change the signature of the method in the subclass by adding a parameter, and we again, just like in the constructor, call the parent version of the method directly by using parent-class-dot syntax and passing self.\n  在类中使用方法时, 第一个参数永远是 self (class method 第一个参数是 cls) 在子类中采用 parent.method调用父类的方法.    Exercise 1 In this exercise, you\u0026rsquo;ll continue working with the Manager class that is inherited from the Employee class. You\u0026rsquo;ll add new data to the class, and customize the give_raise() method to increase the manager\u0026rsquo;s raise amount by a bonus percentage whenever they are given a raise.\nAdd a constructor to Manager that:\n accepts name, salary (default 50000), and project (default None) calls the constructor of the Employee class with the name and salary parameters, creates a project attribute and sets it to the project parameter.  Add a give_raise() method to Manager that:\n accepts the same parameters as Employee.give_raise(), plus a bonus parameter with the default value of 1.05 (bonus of 5%), multiplies amount by bonus, uses the Employee\u0026rsquo;s method to raise salary by that product.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  class Employee: def __init__(self, name, salary=30000): self.name = name self.salary = salary def give_raise(self, amount): self.salary += amount class Manager(Employee): def display(self): print(\u0026#34;Manager \u0026#34;, self.name) def __init__(self, name, salary=50000, project=None): Employee.__init__(self, name, salary) self.project = project # Add a give_raise method def give_raise(self, amount, bonus=1.05): return Employee.give_raise(self, amount * bonus) mngr = Manager(\u0026#34;Ashta Dunbar\u0026#34;, 78500) mngr.give_raise(1000) print(mngr.salary) mngr.give_raise(2000, bonus=1.03) print(mngr.salary)    Exercise 2 In this exercise, you\u0026rsquo;ll create subclasses of the Player class from the first lesson of the chapter, and explore the inheritance of class attributes and methods.\n Create a class Racer inherited from Player, Assign 5 to MAX_SPEED in the body of the class. Create a Player object p and a Racer object r (no arguments needed for the constructor).  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class Player: MAX_POSITION = 10 MAX_SPEED = 3 def __init__(self): self.position = 0 # Add a move() method with steps parameter def move(self, steps): if steps + self.position \u0026lt; Player.MAX_POSITION: self.position = self.position + steps else: self.position = Player.MAX_POSITION # Create a Racer class and set MAX_SPEED to 5 class Racer(Player): MAX_SPEED = 5 # Create a Player and a Racer objects p = Player() r = Racer()   Notice: Class attributes CAN be inherited, and the value of class attributes CAN be overwritten in the child class\n Exercise 3 In this exercise, you will implement a small LoggedDF class that inherits from a regular pandas DataFrame but has a created_at attribute storing the timestamp. You will then augment the standard to_csv() method to always include a column storing the creation date.\n Tip: all DataFrame methods have many parameters, and it is not sustainable to copy all of them for each method you\u0026rsquo;re customizing. The trick is to use variable-length arguments *args and **kwargs to catch all of them.\n   Import pandas as pd.\n  Define LoggedDF class inherited from pd.DataFrame.\n  Define a constructor with arguments *args and **kwargs that:\n   calls the pd.DataFrame constructor with the same arguments,     assigns datetime.today() to self.created_at.    Add a to_csv() method to LoggedDF that:\n   copies self to a temporary DataFrame using .copy(),     creates a new column created_at in the temporary DataFrame and fills it with self.created_at     calls pd.DataFrame.to_csv() on the temporary variable.    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # Import pandas as pd import pandas as pd # Define LoggedDF inherited from pd.DataFrame and add the constructor class LoggedDF(pd.DataFrame): def __init__(self, *args, **kwargs): pd.DataFrame.__init__(self, *args, **kwargs) self.created_at = datetime.today() def to_csv(self, *args, **kwargs): # Copy self to a temporary DataFrame temp = self.copy() # Create a new column filled with self.created_at temp[\u0026#34;created_at\u0026#34;] = self.created_at # Call pd.DataFrame.to_csv on temp, passing in *args and **kwargs pd.DataFrame.to_csv(temp, *args, **kwargs)   Note that: df.to_csv(\u0026quot;/path\u0026quot;) \u0026ndash;\u0026gt; to_csv(df, \u0026quot;/path\u0026quot;) \u0026ndash;\u0026gt; df=self \u0026ndash;\u0026gt; temp = self.copy() e.t. temp=df.copy(). 记住self是 object 的替身.\n","date":"2019-09-01T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-iv-class/","title":"Object Oriented Programming IV (Class)"},{"content":"Intro Docstrings Docstrings, which describes what the arguments are supposed to be, and what it returns, makes code much easier to use, read, and maintain. A docstring is a string enclosed in triple quotes and written as the first line of a function.\n1 2 3 4 5  def func() \u0026#34;\u0026#34;\u0026#34; docstring \u0026#34;\u0026#34;\u0026#34; pass   Every docstring has some (although usually not all) of these five key pieces of information:\n what the function does what the arguments are what the return value or values should be info about any errors raised, anything else you\u0026rsquo;d like to say about the function.  Python community has evolved several standards for how to format your docstrings. Google-style and Numpydoc are the most popular formats, so we\u0026rsquo;ll focus on those.\nIn Google style, the docstring starts with a concise description of what the function does. This should be in imperative language.\n1 2 3 4 5 6 7  def count_letter(content, letter): \u0026#34;\u0026#34;\u0026#34; Count the number of times `letter` appears in `content` \u0026#34;\u0026#34;\u0026#34; if (not isinstance(letter, str)) or len(letter) != 1: raise ValueError(\u0026#39;`letter` must be a single character string.\u0026#39;) return len([char for char in content if char == letter])   Next comes the \u0026ldquo;Args\u0026rdquo; section where you list each argument name, followed by its expected type in parentheses, and then what its role is in the function. If you need extra space, you can break to the next line and indent. If an argument has a default value, mark it as \u0026ldquo;optional\u0026rdquo; when describing the type. If the function does not take any parameters, feel free to leave this section out.\n1 2 3 4 5 6 7 8 9 10  def count_letter(content, letter): \u0026#34;\u0026#34;\u0026#34;Count the number of times `letter` appears in `content`. Args: content (str): The string to search. letter (str): The letter to search for. \u0026#34;\u0026#34;\u0026#34; if (not isinstance(letter, str)) or len(letter) != 1: raise ValueError(\u0026#39;`letter` must be a single character string.\u0026#39;) return len([char for char in content if char == letter])   The next section is the \u0026ldquo;Returns\u0026rdquo; section, where you list the expected type or types of what gets returned. You can also provide some comment about what gets returned, but often the name of the function and the description will make this clear. Finally, if your function intentionally raises any errors, you should add a \u0026ldquo;Raises\u0026rdquo; section. You can also include any additional notes or examples of usage in free form text at the end.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def count_letter(content, letter): \u0026#34;\u0026#34;\u0026#34;Count the number of times `letter` appears in `content`. Args: content (str): The string to search. letter (str): The letter to search for. Returns: int Raises: ValueError: If `letter` is not a one-character string. \u0026#34;\u0026#34;\u0026#34; if (not isinstance(letter, str)) or len(letter) != 1: raise ValueError(\u0026#39;`letter` must be a single character string.\u0026#39;) return len([char for char in content if char == letter])    Personally, I think the Numpydoc format looks better than the Google style.\n you can access the contents of your function\u0026rsquo;s docstring using __doc__ attribute. Notice that the __doc__ attribute contains the raw docstring, including any tabs or spaces.\nTo remove those leading spaces, you can use the getdoc() function from the inspect module. The inspect module contains a lot of useful methods for gathering information about functions.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import inspect def build_tooltip(function): \u0026#34;\u0026#34;\u0026#34;Create a tooltip for any function that shows the function\u0026#39;s docstring. Args: function (callable): The function we want a tooltip for. Returns: str \u0026#34;\u0026#34;\u0026#34; docstring = inspect.getdoc(function) border = \u0026#39;#\u0026#39; * 28 return \u0026#39;{}\\n{}\\n{}\u0026#39;.format(border, docstring, border) print(build_tooltip(count_letter)) print(build_tooltip(range)) print(build_tooltip(print))   ############################ Count the number of times `letter` appears in `content`. Args: content (str): The string to search. letter (str): The letter to search for. Returns: int Raises: ValueError: If `letter` is not a one-character string. ############################ ############################ range(stop) -\u0026gt; range object range(start, stop[, step]) -\u0026gt; range object Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1. start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3. These are exactly the valid indices for a list of 4 elements. When step is given, it specifies the increment (or decrement). ############################ ############################ print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. ############################ DRY \u0026amp; Do one thing DRY (also known as \u0026ldquo;don\u0026rsquo;t repeat yourself\u0026rdquo;) and the \u0026ldquo;Do One Thing\u0026rdquo; principle are good ways to ensure that functions are well designed and easy to test.\nWhen you are writing code to look for answers to a research question, it is totally normal to copy and paste a bit of code, tweak it slightly, and return it. But it can lead to real problems. For instance, it is easy to accidentally introduce errors that are hard to spot. Another problem is that if you want to change something, you often have to do it in multiple places.\nWrapping the repeated logic in a function and then calling that function several times makes it much easier to avoid the kind of errors introduced by copying and pasting. And if you ever need to change something, you only have to do it in one or two places.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def standardize(column): \u0026#34;\u0026#34;\u0026#34;Standardize the values in a column. Args: column (pandas Series): The data to standardize. Returns: pandas Series: the values as z-scores \u0026#34;\u0026#34;\u0026#34; z_score = (column - column.mean()) / column.std() return z_score df[\u0026#39;y1_z\u0026#39;] = standardize(df.y1_gpa) df[\u0026#39;y2_z\u0026#39;] = standardize(df.y2_gpa) df[\u0026#39;y3_z\u0026#39;] = standardize(df.y3_gpa) df[\u0026#39;y4_z\u0026#39;] = standardize(df.y4_gpa)   Another software engineering principle: Do One Thing. Every function should have a single responsibility. Instead of one big function, we could have a more nimble function. We get several advantages from splitting the big function into smaller functions. First of all, our code has become more flexible. The code will also be easier for other developers to understand, and it will be more pleasant to test and debug. Finally, if you ever need to update your code, functions that each have a single responsibility make it easier to predict how changes in one place will affect the rest of the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # split it into two simpler functions: mean() and median() def mean_and_median(values): \u0026#34;\u0026#34;\u0026#34;Get the mean and median of a sorted list of `values` Args: values (iterable of float): A list of numbers Returns: tuple (float, float): The mean and median \u0026#34;\u0026#34;\u0026#34; mean = sum(values) / len(values) midpoint = int(len(values) / 2) if len(values) % 2 == 0: median = (values[midpoint - 1] + values[midpoint]) / 2 else: median = values[midpoint] return mean, median   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # function mean() def mean(values): \u0026#34;\u0026#34;\u0026#34;Get the mean of a sorted list of values Args: values (iterable of float): A list of numbers Returns: float \u0026#34;\u0026#34;\u0026#34; mean = sum(values)/len(values) return mean # function median() def median(values): \u0026#34;\u0026#34;\u0026#34;Get the median of a sorted list of values Args: values (iterable of float): A list of numbers Returns: float \u0026#34;\u0026#34;\u0026#34; midpoint = int(len(values) / 2) if len(values) % 2 == 0: median = (values[midpoint - 1] + values[midpoint]) / 2 else: median = values[midpoint] return median   Pass by assignment The way that Python passes information to functions is called \u0026ldquo;pass by assignment\u0026rdquo;.\nConsider function foo() that takes a list and sets the first value of the list to 99. Then we set \u0026ldquo;my_list\u0026rdquo; to the value [1, 2, 3] and pass it to foo(). The value of \u0026ldquo;my_list\u0026rdquo; would be [99, 2, 3] after calling foo(). Lists in Python are mutable objects, meaning that they can be changed.\n1 2 3 4 5  def foo(x): x[0] = 99 my_list = [1, 2, 3] foo(my_list) print(my_list)   [99, 2, 3] Consider function bar() that takes an argument and adds 90 to it. Then we assign the value 3 to the variable \u0026ldquo;my_var\u0026rdquo; and call bar() with \u0026ldquo;my_var\u0026rdquo; as the argument. The value of \u0026ldquo;my_var\u0026rdquo; would be 3 after we\u0026rsquo;ve called bar(). In Python, integers are immutable objects, meaning they can\u0026rsquo;t be changed.\n1 2 3 4 5  def bar(x): x = x + 90 my_var = 3 bar(my_var) print(my_var)   3 Imagine that this gray bar is the computer\u0026rsquo;s memory. When we set the variable \u0026ldquo;a\u0026rdquo; equal to the list [1, 2, 3], the Python interpreter makes \u0026lsquo;a\u0026rsquo; points to this location in memory. Then if we type \u0026ldquo;b = a\u0026rdquo;, the interpreter makes \u0026lsquo;b\u0026rsquo; points to whatever \u0026lsquo;a\u0026rsquo; is pointing to. (certainly, \u0026lsquo;a\u0026rsquo; points to whatever \u0026lsquo;b\u0026rsquo; is pointing to correspondingly.)\nIf we append 4 to the end of \u0026ldquo;a\u0026rdquo;, both variables get it because there is only one list. Likewise, if we append 5 to \u0026ldquo;b\u0026rdquo;, both variables get it.\nHowever, if we assign \u0026ldquo;a\u0026rdquo; to a different object (like int) in memory, that does not change where \u0026ldquo;b\u0026rdquo; is pointing. Now, things that happen to \u0026ldquo;a\u0026rdquo; are no longer happening to \u0026ldquo;b\u0026rdquo;, and vice versa.\nWhen we assign a list to the variable \u0026ldquo;my_list\u0026rdquo;, it sets up a location in memory for it. Then, when we pass \u0026ldquo;my_list\u0026rdquo; to the function foo(), the parameter \u0026ldquo;x\u0026rdquo; gets assigned to that same location. So when the function modifies the thing that \u0026ldquo;x\u0026rdquo; points to, it is also modifying the thing that \u0026ldquo;my_list\u0026rdquo; points to.\nIn the other example, we created a variable \u0026ldquo;my_var\u0026rdquo; and assigned it the value 3. Then we passed it to the function bar(), which caused the argument \u0026ldquo;x\u0026rdquo; to point to the same place \u0026ldquo;my_var\u0026rdquo; is pointing. But the bar() function assigns \u0026ldquo;x\u0026rdquo; to a new value , so the \u0026ldquo;my_var\u0026rdquo; variable isn\u0026rsquo;t touched. In fact, there is no way in Python to have changed \u0026ldquo;x\u0026rdquo; or \u0026ldquo;my_var\u0026rdquo; directly, because integers are immutable variables.\n You can comprehend it as: Python interpreter kills the old x, and release the relationship between x and my_var, and then create a new object x which has nothing to do with my_var.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def store_lower(_dict, _string): # \u0026lt;-- d \u0026amp; (associates with) _dict; s \u0026amp; _string \u0026#34;\u0026#34;\u0026#34;Add a mapping between `_string` and a lowercased version of `_string` to `_dict` Args: _dict (dict): The dictionary to update. _string (str): The string to add. \u0026#34;\u0026#34;\u0026#34; orig_string = _string # \u0026lt;-- orig_string \u0026amp; _string \u0026amp; s  _string = _string.lower() # \u0026lt;-- _string # (breaks up with) orig_string \u0026amp; s _dict[orig_string] = _string d = {} s = \u0026#39;Hello\u0026#39; store_lower(d, s) print(d,s)   {'Hello': 'hello'} Hello # {'orig_string': '_string'} s There are only a few immutable data types in Python because almost everything is represented as an object. The only way to tell if something is mutable is to see if there is a function or method that will change the object without assigning it to a new variable.\nNotice, Consider foo() is a function that appends the value 1 to the end of a list with an empty list as a default value.\n1 2 3  def foo(var=[]): var.append(1) return var   When we call foo() the first time, we will get a list with one entry as expected. But, when we call foo() again, the default value has already been modified.\n1 2  foo() foo()   [1] [1, 1] If you want a mutable variable as a default value, consider defaulting to None and setting the argument in the function.\n1 2 3 4 5 6 7  def foo(var=None): if var is None: var = [] var.append(1) return var foo() foo()   [1] [1] I wan to explain exactly what\u0026rsquo;s happening when we call a function with mutable object default value. Consider following example,\n1 2 3 4 5 6 7 8 9  def addend(lt=[]): # 0. lt.append(\u0026#39;end\u0026#39;) return lt lst = [1, 2, 3, 4] # 1. print(addend(lst)) # 2. print(lst) print(addend()) # 3. print(addend()) # 4.   [1, 2, 3, 4, 'end'] [1, 2, 3, 4, 'end'] ['end'] ['end', 'end']  step 0: def addend(lt=[]): As we define the function append(), Python interpreter assigns a memory space block, which stored an empty list, to argument lt. Notice, lt points to this block. step 1: lst = [1,2,3,4] We we define a global list object lst, Python interpreter assigns another memory, which stored a corresponding list, to variable lst. lst points to this block. step 2: print(addend(lst)) When we call function addend with parameter lst, Python interpreter reads this global object in the local scope, and then makes pointer lt point to the block pointed by lst. Thus lt, lst point to the same memory block, which loaded list object ([1,2,3,4]). And then interpreter appends a new element \u0026ldquo;end\u0026rdquo; to this block, which means it changes the value of lt and lst simultaneously. This is the reason why the outcome of print(lst) is [1, 2, 3, 4, 'end'].   Notice that if lt, lst is an immutable object, the python interpreter will kill the older lt pointer, and assigns a new memory block to lt, instead of appending the element to the memory block. Thus it will not modify the value of lst. Collectively,\n immutable object: change the space pointed by variable. mutable object: change the value of space pointed by variable.    step 3/4: print(addend()) When we call addend() without parameter, the Python interpreter will add an element \u0026ldquo;end\u0026rdquo; to the space pointed by lt; when we call addend() again, the space pointed by lt has already been changed.  Above example is adapted from link.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # Modify this func using an immutable variable for the default argument. def add_column(values, df=pandas.DataFrame()): \u0026#34;\u0026#34;\u0026#34;Add a column of `values` to a DataFrame `df`. The column will be named \u0026#34;col_\u0026lt;n\u0026gt;\u0026#34; where \u0026#34;n\u0026#34; is the numerical index of the column. Args: values (iterable): The values of the new column df (DataFrame, optional): The DataFrame to update. If no DataFrame is passed, one is created by default. Returns: DataFrame \u0026#34;\u0026#34;\u0026#34; df[\u0026#39;col_{}\u0026#39;.format(len(df.columns))] = values return df   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  def better_add_column(values, df=None): \u0026#34;\u0026#34;\u0026#34;Add a column of `values` to a DataFrame `df`. The column will be named \u0026#34;col_\u0026lt;n\u0026gt;\u0026#34; where \u0026#34;n\u0026#34; is the numerical index of the column. Args: values (iterable): The values of the new column df (DataFrame, optional): The DataFrame to update. If no DataFrame is passed, one is created by default. Returns: DataFrame \u0026#34;\u0026#34;\u0026#34; if df is None: df = pandas.DataFrame() df[\u0026#39;col_{}\u0026#39;.format(len(df.columns))] = values return df   Context Managers Using context managers A context manager is a type of function that\n sets up a context for code to run in, runs your code, and then removes the context.  The \u0026ldquo;open()\u0026rdquo; function is a context manager. When you write \u0026ldquo;with open()\u0026rdquo;, it opens a file that you can read from or write to. Then, it gives control back to your code so that you can perform operations on the file object. When the code inside the indented block is done, the \u0026ldquo;open()\u0026rdquo; function makes sure that the file is closed before continuing on in the script.\nAny time you use a context manager, it will look like this:\n The keyword \u0026ldquo;with\u0026rdquo; lets Python know that you are trying to enter a context. Then you call a function. You can call any function that is built to work as a context manager. A context manager can take arguments like any normal function. You end the \u0026ldquo;with\u0026rdquo; statement with a colon \u0026lsquo;:\u0026rsquo;, as if you were writing a for loop or an if statement. Any code that you want to run inside the context that the context manager created needs to be indented. When the indented block is done, the context manager gets a chance to clean up anything that it needs to, like when the \u0026ldquo;open()\u0026rdquo; context manager closed the file.  Collectively:\n1 2  with \u0026lt;context-manager\u0026gt;(\u0026lt;args\u0026gt;): # code ...    Statements in Python that have an indented block after them, like for loops, if/else statements, function/class definitions def/Class, etc. are called \u0026ldquo;compound statements\u0026rdquo;. The \u0026ldquo;with\u0026rdquo; statement is another type of compound statement.\n Some context managers want to return a value that you can use inside the context. By adding \u0026ldquo;as\u0026rdquo; and a variable name at the end of the \u0026ldquo;with\u0026rdquo; statement, you can assign the returned value to the variable name.\n1 2 3 4 5 6 7 8 9  with open(\u0026#39;alice.txt\u0026#39;) as file: text = file.read() n = 0 for word in text.split(): if word.lower() in [\u0026#39;cat\u0026#39;, \u0026#39;cats\u0026#39;]: n += 1 print(\u0026#39;Lewis Carroll uses the word \u0026#34;cat\u0026#34; {}times\u0026#39;.format(n))   Lewis Carroll uses the word \u0026quot;cat\u0026quot; 24 times Writing context managers There are two ways to define a context manager in Python:\n by using a class that has special __enter__() and __exit__() methods by decorating a certain kind of function.  We will focus on the function-based method here. There are five parts to creating a context manager.\n define a function. (optional) add any setup code your context needs. use the \u0026ldquo;yield\u0026rdquo; keyword to signal to Python that this is a special kind of function. (optional) add any teardown code that your context needs. decorate the function on the line above your context manager function with @contextlib.contextmanager.  1 2 3 4 5 6  import contextlib @contextlib.contextmanager def context_`func()`: # setup code yield # teardown code   When you write yield keyword, it means that you are going to return a value, but you expect to finish the rest of the function at some point in the future. As we say last blog, the \u0026ldquo;yield\u0026rdquo; keyword as a thing that gets used when creating generators. In fact, a context manager function is technically a generator that yields a single value. The value that your context manager yields can be assigned to a variable in the \u0026ldquo;with\u0026rdquo; statement by adding \u0026ldquo;as \u0026lt;variable name\u0026gt;\u0026rdquo;.\nHere, we\u0026rsquo;ve assigned the value 42 that my_context() yields to the variable \u0026ldquo;foo\u0026rdquo;. By running this code, you can see that after the context block is done executing, the rest of the my_context() function gets run, printing \u0026ldquo;goodbye\u0026rdquo;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import contextlib @contextlib.contextmanager def my_context(): \u0026#34;\u0026#34;\u0026#34;Show the order of the execution of CM code. Yield: a certain value. \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;1\u0026#34;) yield 34 print(\u0026#34;2\u0026#34;) with my_context() as foo: print(foo)   1 34 2 This context manager is an example of code that accesses a database. Like most context managers, it has some setup code that runs before the function yields. This context manager uses that setup code to connect to the database. Most context managers also have some teardown or cleanup code when they get control back after yielding.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @contextlib.contextmanager def database(url): \u0026#34;\u0026#34;\u0026#34;Connect to a database and close the connection after query. Yield: connection object \u0026#34;\u0026#34;\u0026#34; db = postgres.connect(url) yield db db.disconnect() url = \u0026#34;https://xxxx\u0026#34; with database(url) as d: outcome = d.execute(\u0026#34;select * from table\u0026#34;)   This setup/teardown behavior allows a context manager to hide things like connecting and disconnecting from a database so that a programmer using the context manager can just perform operations on the database without worrying about the underlying details.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @contextlib.contextmanager def open_read_only(filename): \u0026#34;\u0026#34;\u0026#34;Open a file in read-only mode. Args: filename (str): The location of the file to read. Yields: str: the content of the opened file object. \u0026#34;\u0026#34;\u0026#34; f = open(filename, mode=\u0026#39;r\u0026#39;) content = f.read() yield content f.close() with open_read_only(\u0026#39;my_file.txt\u0026#39;) as content: print(content)   Congratulations! You wrote a context manager that acts like `open()` but responses the content of the file directly without `read()` method. The database() context manager that we\u0026rsquo;ve been looking at yields a specific value - the database connection - that can be used in the context block. Some context managers don\u0026rsquo;t yield an explicit value. in_dir() is a context manager that changes the current working directory to a specific path and then changes it back after the context block is done. It does not need to return anything with its \u0026ldquo;yield\u0026rdquo; statement.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import os @contextlib.contextmanager def in_dir(path=\u0026#34;../\u0026#34;): \u0026#34;\u0026#34;\u0026#34;changes the current working directory to a specific path and then changes it back after the context block is done. Yield: None \u0026#34;\u0026#34;\u0026#34; old_dir = os.getcwd() print(os.getcwd()) os.chdir(path) yield os.chdir(old_dir) print(os.getcwd()) with in_dir(): print(os.getcwd()) print(os.listdir())   /Users/wanghaoming/PycharmProjects/daliy_test/save /Users/wanghaoming/PycharmProjects/daliy_test ['testpdf1.pdf', 'skl.ipynb', 'testpdf.pdf', 'pdf.ipynb', 'save', '.idea'] /Users/wanghaoming/PycharmProjects/daliy_test/save 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @contextlib.contextmanager def timer(): \u0026#34;\u0026#34;\u0026#34;Time the execution of a context block. Yields: None \u0026#34;\u0026#34;\u0026#34; start = time.time() yield end = time.time() print(\u0026#39;Elapsed: {:.2f}s\u0026#39;.format(end - start)) with timer(): print(\u0026#39;This should take approximately 0.25 seconds\u0026#39;) time.sleep(0.25)   This should take approximately 0.25 seconds Elapsed: 0.25s Advanced topics Nested contexts Imagine you are implementing this copy() function that copies the contents of one file to another file. One way you could write this function would be to open the source file, store the contents of the file in the \u0026ldquo;contents\u0026rdquo; variable, then open the destination file and write the contents to it. This approach works fine until you try to copy a file that is too large to fit in memory.\n1 2 3 4 5 6 7 8 9 10 11  def copy(src, dst): \u0026#34;\u0026#34;\u0026#34;Copy the contents of one file to another. Args: src (str): File name of the file to be copied. dst (str): Where to write the new file. \u0026#34;\u0026#34;\u0026#34; with open(src,\u0026#34;r\u0026#34;) as f_src: contents = f_src.read() with open(dst,\u0026#34;w\u0026#34;) as f_dst: f_dst.write(contents)   A good ideal is that we could open both files at once and copy over one line at a time. The file object that the \u0026ldquo;open()\u0026rdquo; context manager returns can be iterated over in a for loop. In Python, nested \u0026ldquo;with\u0026quot; statements are perfectly legal.\n1 2 3 4 5 6 7 8 9 10 11  def copy(src, dst): \u0026#34;\u0026#34;\u0026#34;Copy the contents of one file to another. Args: src (str): File name of the file to be copied. dst (str): Where to write the new file. \u0026#34;\u0026#34;\u0026#34; with open(src,\u0026#34;r\u0026#34;) as f_src: with open(dst,\u0026#34;w\u0026#34;) as f_dst: for line in f_src: f_dst.write(line)   The context manager stock('NVDA') will connect to the NASDAQ and return an object that you can use to get the latest price by calling its .price() method. We now connect to stock('NVDA') and record 10 timesteps of price data by writing it to the file NVDA.txt. Notice that the object returned by stock() would be very large, thus we use nested context manager:\n1 2 3 4 5 6  with stock(\u0026#34;NVDA\u0026#34;) as nvda: with open(\u0026#39;NVDA.txt\u0026#39;, \u0026#39;w\u0026#39;) as f_out: for _ in range(10): value = nvda.price() print(\u0026#39;Logging ${:.2f}for NVDA\u0026#39;.format(value)) f_out.write(\u0026#39;{:.2f}\\n\u0026#39;.format(value))   Opening stock ticker for NVDA Logging $139.50 for NVDA Logging $139.54 for NVDA Logging $139.61 for NVDA Logging $139.65 for NVDA Logging $139.72 for NVDA Logging $139.73 for NVDA Logging $139.80 for NVDA Logging $139.78 for NVDA Logging $139.73 for NVDA Logging $139.64 for NVDA Closing stock ticker Handling errors If the programmer who uses your context manager writes code that causes an error after setup code but before teardown code, then the file or connection would not be close.\nTo cope with an error, you may be familiar with the \u0026ldquo;try\u0026rdquo; statement. It allows you to write code that might raise an error inside the \u0026ldquo;try\u0026rdquo; block and catch that error inside the \u0026ldquo;except\u0026rdquo; block. You can choose to ignore the error or re-raise it. The \u0026ldquo;try\u0026rdquo; statement also allows you to add a \u0026ldquo;finally\u0026rdquo; block. This is code that runs no matter what an exception occurred or not.\nThe solution is to put a \u0026ldquo;try\u0026rdquo; statement before the \u0026ldquo;yield\u0026rdquo; statement in our context manager function and a \u0026ldquo;finally\u0026rdquo; statement before teardown code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  def in_dir(directory): \u0026#34;\u0026#34;\u0026#34;Change current working directory to `directory`, allow the user to run some code, and change back. Args: directory (str): The path to a directory to work in. \u0026#34;\u0026#34;\u0026#34; current_dir = os.getcwd() os.chdir(directory) try: yield finally: os.chdir(current_dir)   If you notice that your code is following any of these patterns, you might consider using a context manager.\n   setup teardown     open close   lock release   change reset   enter exit   start stop   setup teardown   connect disconnect   Adapted from Dave Brondsema\u0026rsquo;s talk at PyCon 2012.     Decorators Functions are objects Functions are just like any other object in Python. They are not fundamentally different from lists, dictionaries, DataFrames, strings, integers, floats, modules, or anything else in Python. And because functions are just another type of object, you can do anything to or with them that you would do with any other kind of object.\nYou can take a function and assign it to a variable, like assign the print() function to p, and use it as your print() function.\n1 2  p = print p(\u0026#34;test\u0026#34;)   test You can also add functions to a list or dictionary. Here, we\u0026rsquo;ve added the functions my_function(), open(), and print() to the list \u0026ldquo;list_of_functions\u0026rdquo;. Below that, we\u0026rsquo;ve added the same three functions to a dictionary dict_of_functions, under the keys \u0026ldquo;func1\u0026rdquo;, \u0026ldquo;func2\u0026rdquo;, and \u0026ldquo;func3\u0026rdquo;. We can call the element of the list or reference values of the dictionary and use them as if we were calling the functions directly.\n1 2 3 4 5 6 7 8 9 10  def my_function(): return 42 list_of_functions = [my_function, open, print] dict_of_functions = { \u0026#34;func1\u0026#34;: my_function, \u0026#34;func2\u0026#34;: open, \u0026#34;func3\u0026#34;: print } dict_of_functions[\u0026#34;func3\u0026#34;](list_of_functions[0]())   42 Notice that when you assign a function to a variable, you do not include the parentheses after the function name. This is a subtle but very important distinction. When you type my_function() with the parentheses, you are calling that function. It evaluates to the value that the function returns. However, when you type \u0026ldquo;my_function\u0026rdquo; without the parentheses, you are referencing the function itself. It evaluates to a function object.\n1 2  print(my_function()) print(my_function)   42 \u0026lt;function my_function at 0x7fe6c1691b80\u0026gt; Since a function is just an object like anything else in Python, you can pass one as an argument to another function. The has_docstring() function checks to see whether the function that is passed to it has a docstring or not. We could define these two functions, no() and yes(), and pass them as arguments to the has_docstring() function. Since the no() function doesn\u0026rsquo;t have a docstring, the has_docstring() function returns False. Likewise, has_docstring() returns True for the yes() function.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  def has_docstring(func): \u0026#34;\u0026#34;\u0026#34;Check to see if the function `func` has a docstring. Args: func (callable): A function. Returns: bool \u0026#34;\u0026#34;\u0026#34; return func.__doc__ is not None def yes(): \u0026#34;\u0026#34;\u0026#34;Return the value 42 \u0026#34;\u0026#34;\u0026#34; return 42 def no(): return 42 print(has_docstring(yes)) print(has_docstring(no)) print(has_docstring(has_docstring))   True False True Functions can also be defined inside other functions. These kinds of functions are called nested functions. A nested function can make your code easier to read. In this example, if x and y are within some bounds, foo() prints x times y. We can make that if statement easier to read by defining an in_range() function.\n1 2 3 4 5 6 7 8 9 10 11 12  def foo1(x,y): if (x\u0026gt;4 and x\u0026lt;10) and (y\u0026gt;4 and y \u0026lt;10): print(x*y) def foo2(x,y): def in_range(v): return v\u0026gt;4 and v\u0026lt;10 if in_range(x) and in_range(y): print(x*y) foo1(5,6) foo2(7,8)   30 56 Function also could return a function. For instance, the function get_function() creates a new function, print_me(), and then returns it. If we assign the result of calling get_function() to the variable \u0026ldquo;new_func\u0026rdquo;, we are assigning the return value, \u0026ldquo;print_me()\u0026rdquo; to \u0026ldquo;new_func\u0026rdquo;. We can then call new_func()`` as if it were the print_me() function.\n1 2 3 4 5 6 7  def get_function(): def print_me(s): print(s) return print_me new_func = get_function() new_func(\u0026#34;test\u0026#34;)   test 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  def create_math_function(func_name): if func_name == \u0026#39;add\u0026#39;: def add(a, b): return a + b return add elif func_name == \u0026#39;subtract\u0026#39;: def subtract(a,b): return a-b return subtract else: print(\u0026#34;I don\u0026#39;t know that one\u0026#34;) add = create_math_function(\u0026#39;add\u0026#39;) print(\u0026#39;5 + 2 = {}\u0026#39;.format(add(5, 2))) subtract = create_math_function(\u0026#39;subtract\u0026#39;) print(\u0026#39;5 - 2 = {}\u0026#39;.format(subtract(5, 2)))   5 + 2 = 7 5 - 2 = 3 Scope We have discussed scope in python before, now we gonna briefly recall it. Python has to have strict rules about which variable you are referring to when using a particular variable name.\n First, the interpreter looks in the Local Scope. When you are inside a function, the local scope is made up of the arguments and any variables defined inside the function. In the case of nested functions, where one function is defined inside another function, Python will check the scope of the parent function after checking the local scope. This is called the Nonlocal Scope to show that it is not the local scope of the child function and not the global scope. If the interpreter can\u0026rsquo;t find the variable in the (non)local scope, it expands its search to the Global Scope. These are the things defined outside the function. Finally, if it can\u0026rsquo;t find the thing it is looking for in the global scope, the interpreter checks the Builtin Scope. These are things that are always available in Python. For instance, the print() function is in the builtin scope, which is why we are able to use it in any scope.  Note that Python only gives you read access, instead of write, to variables defined outside of your current scope. But you can write it indirectly using global or nonlocal keywords.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  x = 50 def one(): x = 10 def two(): global x x = 30 def three(): x = 100 print(x) for func in [one, two, three]: `func()` print(x)   50 30 100 30 Closure A closure in Python is a tuple of variables that are no longer in scope, but that a function needs in order to run.\nConsider an example. The function foo() defines a nested function bar() that prints the value of \u0026ldquo;a\u0026rdquo;. foo() returns this new function, so when we say \u0026ldquo;func = foo()\u0026rdquo; we are assigning the bar() function to the variable \u0026ldquo;func\u0026rdquo;. When we call func(), it prints the value of variable \u0026ldquo;a\u0026rdquo;, which is 5.\n1 2 3 4 5 6 7 8  def foo(): a = 5 def bar(): # Notice, if you set `def bar(a):`, then you must assign it a value when you call bar(). print(a) return bar func = foo() func()   a How does function \u0026ldquo;func()\u0026rdquo; know anything about variable \u0026ldquo;a\u0026rdquo;? \u0026ldquo;a\u0026rdquo; is defined in foo()\u0026rsquo;s scope, not bar()\u0026rsquo;s. You would think that \u0026ldquo;a\u0026rdquo; would not be observable outside of the scope of foo(). That\u0026rsquo;s where closures come in. When foo() returned the new bar() function, Python helpfully attached any nonlocal variable that bar() was going to need to the function object.\nThose variables get stored in a tuple in the \u0026ldquo;__closure__\u0026rdquo; attribute, which could be iterated, of the function. The closure for \u0026ldquo;func\u0026rdquo; has one variable, and you can view the value of that variable by accessing the \u0026ldquo;cell_contents\u0026rdquo; of the item.\n1 2 3 4  print(func.__closure__) print(type(func.__closure__)) print(len(func.__closure__)) print(func.__closure__[0].cell_contents)   (\u0026lt;cell at 0x7fe6b033aa30: int object at 0x7fe70002e9b0\u0026gt;,) \u0026lt;class 'tuple'\u0026gt; 1 5 1 2 3 4 5 6 7 8 9 10 11 12 13  def parent(arg_1, arg_2): value = 22 my_dict = {\u0026#39;chocolate\u0026#39;: \u0026#39;yummy\u0026#39;} def child(): print(2 * value) print(my_dict[\u0026#39;chocolate\u0026#39;]) print(arg_1 + arg_2) return child new_function = parent(3, 4) print([cell.cell_contents for cell in new_function.__closure__])   [3, 4, {'chocolate': 'yummy'}, 22] Let\u0026rsquo;s examine this bit of code. Here, x is defined in the global scope. foo() creates a function bar() that prints whatever argument was passed to foo(). When we call foo() and assign the result to \u0026ldquo;my_func\u0026rdquo;, we pass in \u0026ldquo;x\u0026rdquo;. So, as expected, calling my_func() prints the value of x. Now let\u0026rsquo;s delete x and call my_func() again, we would still print 25. That\u0026rsquo;s because foo()\u0026rsquo;s \u0026ldquo;value\u0026rdquo; argument gets added to the closure attached to the new \u0026ldquo;my_func\u0026rdquo; function. So even though x doesn\u0026rsquo;t exist anymore, the value persists in its closure.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  x = 25 def foo(value=1): def bar(): print(value) return bar my_func = foo(x) # \u0026lt;-- Create closure here my_func() del(x) my_func() print(my_func.__closure__[0].cell_contents) x = 52 my_func() print(my_func.__closure__[0].cell_contents)   25 25 25 25 25 Notice that nothing changes if we overwrite \u0026ldquo;x\u0026rdquo; instead of deleting it. Here we\u0026rsquo;ve passed x into foo() and then assigned the new function to the variable x. The old value of \u0026ldquo;x\u0026rdquo;, 25, is still stored in the new function\u0026rsquo;s closure, even though the new function is now stored in the \u0026ldquo;x\u0026rdquo; variable.\nDecorators Let\u0026rsquo;s say you have a function that takes some inputs and returns some outputs. Decorators are just functions that take a function as an argument and return a modified version of that function that changes that function\u0026rsquo;s behavior. You can modify the inputs, modify the outputs, or even change the behavior of the function itself.\nTo start off, let\u0026rsquo;s define a function double_args does not modify anything of the input function.\n1 2  def double_args(func): return func   It just takes a function and immediately returns it. If we call this version of double_args() that does nothing and pass it the multiply() function and then assign the result to the variable \u0026ldquo;new_multiply\u0026rdquo;, then we can call new_multiply(1, 5) and get the same value we would have gotten from multiply(1, 5).\n1 2 3 4 5 6 7 8  def multiply(a,b): return a * b def double_args(func): return func new_multiply = double_args(multiply) print(new_multiply(1,5) == multiply(1,5))   True In order for your decorator to return a modified function, it is usually helpful for it to define a nested function to return. We\u0026rsquo;ll call that nested function \u0026ldquo;wrapper()\u0026rdquo;. All wrapper() does is take two arguments and passes them on to whatever function was passed to double_args() in the first place, assuming that the function passed to double_args() also takes exactly two arguments.\nSo, double_args() is still not doing anything to actually modify the function it is decorating. Once again, we\u0026rsquo;ll pass multiply() to double_args() and assign the result to new_multiply(). If we then call new_multiply(), which is now equal to the wrapper() function, wrapper() calls multiply() because it is the function that was passed to double_args(). So wrapper() calls multiply() with the arguments 1 and 5, which returns 5.\n1 2 3 4 5 6 7  def double_args(func): def wrapper(a,b): return(func(a,b)) return wrapper new_multiply = double_args(multiply) # ==\u0026gt; **refer** `wrapper` with 2 arguments `a`,`b` and a closure `multiply`. new_multiply(1,5) # ==\u0026gt; **call** wrapper(1,5) return multiply(1,5)   5 Now let\u0026rsquo;s actually modify the function our decorator is decorating. This time, wrapper() will still call whatever function is passed to double_args(), but it will double every argument when it calls the original function. As usual, we will call double_args() on the multiply() function and assign the result to new_multiply. Now, when we call new_multiply() with 1 and 5 as arguments, new_multiply() is equal to wrapper(), which calls multiply() after doubling each argument. So 1 becomes 2 and 5 becomes 10, giving us 2 times 10, which equals 20.\n1 2 3 4 5 6 7  def double_args(func): def wrapper(a,b): return(func(2*a,2*b)) return wrapper new_multiply = double_args(multiply) # ==\u0026gt; e.t. wrapper with closure `multiply` new_multiply(1,5) # ==\u0026gt; e.t. `wrapper(1,5)` returns `multiply(2,10)`   20 This time, instead of assigning the new function to \u0026ldquo;new_multiply\u0026rdquo;, we\u0026rsquo;re going to overwrite the \u0026ldquo;multiply\u0026rdquo; variable. And then calling multiply() with arguments 1 and 5 gives us 20 instead of 5. Remember that we can do this because Python stores the original multiply function in the new function\u0026rsquo;s closure.\n1 2 3  multiply = double_args(multiply) print(multiply(1,5)) print(multiply.__closure__[0].cell_contents)   20 \u0026lt;function multiply at 0x7f0060c9e620\u0026gt; Now we can implement above code in a concise way, using @ symbol followed by the decorator\u0026rsquo;s name on the line directly above the function you are decorating.\n1 2 3 4 5 6 7 8 9 10  def double_args(func): def wrapper(a,b): return func(a*2, b*2) return wrapper @double_args def multiply(a,b): return a * b multiply(1,5)   20 This is just a Python convenience for saying \u0026ldquo;multiply\u0026rdquo; equals the value returned by calling double_args() with \u0026ldquo;multiply\u0026rdquo; as the only argument, i.e. multiply = double_args(multiply). The above code is exactly equivalent to the following code,\n1 2 3 4 5 6 7 8 9 10  def double_args(func): def wrapper(a,b): return func(a*2, b*2) return wrapper def multiply(a,b): return a * b multiply = double_args(multiply) multiply(1,5)   20 More on Decorators Real-world examples count time cost We will walk through some real-world decorators so that we can start to recognize common decorator patterns. The timer() decorator runs the decorated function and then prints how long it took for the function to run.\n you wind up adding some version of this to all of projects because it is a pretty easy way to figure out where your computational bottlenecks are.\n All decorators have fairly similar-looking docstrings because they all take and return a single function. Like most decorators, we\u0026rsquo;ll start off by defining a wrapper() function. This is the function that the decorator will return. wrapper() takes any number of positional and keyword arguments so that it can be used to decorate any function. The first thing the new function will do is record the time that it was called with the time() function. Then wrapper() gets the result of calling the decorated function. We don\u0026rsquo;t return that value yet though. After calling the decorated function, wrapper() checks the time again, and prints a message about how long it took to run the decorated function. Once we\u0026rsquo;ve done that, we need to return the value that the decorated function calculated.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import time def timer(func): \u0026#34;\u0026#34;\u0026#34;A decorator that prints how long a function took to run. Args: func (callable): The function being decorated. Returns: callable: The decorated function. \u0026#34;\u0026#34;\u0026#34; def wrapper(*args, **kargs): start_time = time.time() result = func(*args, **kargs) print(f\u0026#34;time cost: {time.time()-start_time}s\u0026#34;) return result return wrapper @timer def sleep_second(n): time.sleep(n) print(\u0026#34;get up ~ \u0026#34;) sleep_second(3)   get up ~ time cost: 3.0057671070098877s Alternatively, you can also modify it as\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  import time import numpy as np def timer(func): \u0026#34;\u0026#34;\u0026#34;A decorator that prints how long a function took to run. Args: func (callable): The function being decorated. Returns: callable: The decorated function. \u0026#34;\u0026#34;\u0026#34; def wrapper(*args, **kargs): start_time = time.time() result = func(*args, **kargs) cost = time.time()-start_time timecost[func.__name__]=cost return result return wrapper @timer def sleep_second1(n): time.sleep(n) print(\u0026#34;get up ~ \u0026#34;) @timer def sleep_second2(n): time.sleep(n) print(\u0026#34;get up ~ \u0026#34;) @timer def sleep_second3(n): time.sleep(n) print(\u0026#34;get up ~ \u0026#34;) timecost = {} funcls = [sleep_second1,sleep_second2,sleep_second3] [f(np.random.uniform(.5,2.5)) for f in funcls] print(timecost) # \u0026lt;-- Notice, we can accept the desired dict because dict is mutable object.    get up ~ get up ~ get up ~ {'sleep_second1': 0.689359188079834, 'sleep_second2': 1.0407230854034424, 'sleep_second3': 1.763228178024292} store the result Memoizing is the process of storing the results of a function so that the next time the function is called with the same arguments; you can just look up the answer.\nWe start by setting up a dictionary that will map arguments to results. Then, as usual, we create wrapper() to be the new decorated function that this decorator returns. When the new function gets called, we check to see whether we\u0026rsquo;ve ever seen these arguments before. If we haven\u0026rsquo;t, we send them to the decorated function and store the arguments and result in the dictionary. The next time we call this function with those same arguments, the return value will already be in the dictionary, and we can return the value very quickly.\nThere are something deserve attentions:\n Fitstly, when we use @ symbol, Python actions as multiply = memoize(multiply), which means Python packages all objects required by wrapper function, include (original)multiply and result_dict , in to the closure. Secondly, when we call multiply(1,2,3,4,5), the result_dict will be written the arguments and result by Python. But notice that dict is mutable object, which means the closure\u0026rsquo;s second element, result_dict, will be changed simultaneously.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import time def memoize(func): \u0026#34;\u0026#34;\u0026#34;A decorator that stores the result of decorated function with specific arguments. Args: func (callable): The function being decorated. Returns: callable: The decorated function. \u0026#34;\u0026#34;\u0026#34; result_dict = {} def wrapper(*args): if args not in result_dict: result_dict[args] = func(*args) return result_dict[args] return wrapper @memoize # \u0026lt;--- e.t. multiply = memoize(multiply) def multiply(*args): j = 1 for i in args: j *= i time.sleep(3) print(\u0026#34;time cost: 3s\u0026#34;) return j print([cell.cell_contents for cell in multiply.__closure__]) print(multiply(1,2,3,4,5)) print([cell.cell_contents for cell in multiply.__closure__]) print(multiply(1,2,3,4,5)) print([cell.cell_contents for cell in multiply.__closure__]) print(multiply(1,2,3,4,5,6)) print([cell.cell_contents for cell in multiply.__closure__])   [\u0026lt;function multiply at 0x7fe6d00fe3a0\u0026gt;, {}] time cost: 3s 120 [\u0026lt;function multiply at 0x7fe6d00fe3a0\u0026gt;, {(1, 2, 3, 4, 5): 120}] 120 [\u0026lt;function multiply at 0x7fe6d00fe3a0\u0026gt;, {(1, 2, 3, 4, 5): 120}] time cost: 3s 720 [\u0026lt;function multiply at 0x7fe6d00fe3a0\u0026gt;, {(1, 2, 3, 4, 5): 120, (1, 2, 3, 4, 5, 6): 720}]  You should consider using a decorator when you want to add some common bit of code to multiple functions.\n multi decorators You can use @ symbol folded to make multi decorators, like:\n1 2 3 4  @decorator2 @decorator1 def func(): pass   Recall that when we use @decorator, what Python exactly does is overwrite the decorated function func, like func = decorator(func), which assigns the child function of decorator with the closure containing origin func to new func. Homogeneously, multi decorators just do nestedly overwrite the decorated function with inner-to-outer order. For instance, if we use above codes, then decorator1 overwrites func firstly, assigns child function with closure to func; And then decorator2 overwrites func again, assigns child function with closure to func. There is an example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  def decorator1(func): a1 = 1 print(\u0026#34;Get in decorator1\u0026#34;) def wrapper1(*args): print(\u0026#34;Get in wrapper1\u0026#34; ,a1) return func(*args) return wrapper1 def decorator2(func): a2 = 2 print(\u0026#34;Get in decorator2\u0026#34;) def wrapper2(*args): print(\u0026#34;Get in wrapper2\u0026#34; ,a2) return func(*args) return wrapper2 @decorator1 def f(): print(\u0026#34;Ger in f\u0026#34;)   Get in decorator1 Python implements f = decorator1(f), thus print the \u0026ldquo;Get in decorator1\u0026rdquo;.\n1 2  print(f.__closure__) print([cell.cell_contents for cell in f.__closure__])   (\u0026lt;cell at 0x7fe6c168c7f0: int object at 0x7fe70002e930\u0026gt;, \u0026lt;cell at 0x7fe6c168c2b0: function object at 0x7fe6d00fdee0\u0026gt;) [1, \u0026lt;function f at 0x7fe6d00fdee0\u0026gt;] We can see the global object f and nonlocal object a1 has been in closure of decorated f. Now call the multi decorators:\n1 2 3 4 5 6 7  @decorator2 @decorator1 def f(): print(\u0026#34;Ger in f\u0026#34;) print(f.__closure__) print([cell.cell_contents for cell in f.__closure__])   Get in decorator1 Get in decorator2 (\u0026lt;cell at 0x7fe6e0242df0: int object at 0x7fe70002e950\u0026gt;, \u0026lt;cell at 0x7fe6e0242280: function object at 0x7fe7014f6160\u0026gt;) [2, \u0026lt;function decorator1.\u0026lt;locals\u0026gt;.wrapper1 at 0x7fe7014f6160\u0026gt;] we can see Python implements f = decorator1(f) and f = decorator2(f) successively, and print the statement in corresponding order. Notice that the nonlocal object a2 and decorated f (wrapper1) were written into the closure of final f. So where is the closure of wrapper1 that we discussed? We can find them disassembling \u0026lt;function decorator1.\u0026lt;locals\u0026gt;.wrapper1 at 0x7fe7014f6160\u0026gt;\n1 2  print(f.__closure__[1].cell_contents.__closure__) print([cell1.cell_contents for cell1 in f.__closure__[1].cell_contents.__closure__])   (\u0026lt;cell at 0x7fe7014f8af0: int object at 0x7fe70002e930\u0026gt;, \u0026lt;cell at 0x7fe7014f87c0: function object at 0x7fe7014f61f0\u0026gt;) [1, \u0026lt;function f at 0x7fe7014f61f0\u0026gt;]  f.__closure__[1] is a cell object, you should call cell_contents attribute to attain the content of it.\n Everything we discussed above happened before calling the double-decorated function f. Since f is a nested function, like f=decorator2(decorator1(f)), when we call f(), the inner function wrapper2 will conduct firstly, and then wrapper1 and finally original f.\n1  f()   Get in wrapper2 2 Get in wrapper1 1 Ger in f other examples print_return_type() will print out the type of the variable that gets returned from every call of any function it is decorating\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def print_return_type(func): def wrapper(v): result = func(v) print(\u0026#39;{}() returned type {}\u0026#39;.format( func.__name__, type(result) )) return result return wrapper @print_return_type def foo(value): return value print(foo(42)) print(foo([1, 2, 3])) print(foo({\u0026#39;a\u0026#39;: 42}))   foo() returned type \u0026lt;class 'int'\u0026gt; 42 foo() returned type \u0026lt;class 'list'\u0026gt; [1, 2, 3] foo() returned type \u0026lt;class 'dict'\u0026gt; {'a': 42} Counting how many times some functions is called:\n1 2 3 4 5 6 7 8 9 10 11 12 13  def counter(func): # \u0026lt;-- called when use `@` def wrapper(*args, **kwargs): # \u0026lt;-- called everytime calling `foo()` wrapper.count += 1 return func() # \u0026lt;-- Notice the parentheses, we need to implement the passed-in function and attain the outcome, instead of assigning it to something. wrapper.count = 0 return wrapper @counter def foo(): print(\u0026#39;calling foo()\u0026#39;) [foo() for _ in range(5)] print(\u0026#39;foo() was called {}times.\u0026#39;.format(foo.count))   calling foo() calling foo() calling foo() calling foo() calling foo() foo() was called 5 times.  You can define the attribute for function object by func.attr or setattr()/getattr(). (more)\n Metadata One of the problems with decorators is that they obscure the decorated function\u0026rsquo;s metadata. Here we have a function, sleep_n_seconds(), with a docstring that explains exactly what it does. We can access the metadata for the function, like its docstring, name and default arguments.\n1 2 3 4 5 6 7 8 9 10 11  def sleep_n_seconds(n=10): \u0026#34;\u0026#34;\u0026#34;Pause processing for n seconds. Args: n (int): The number of seconds to pause for. \u0026#34;\u0026#34;\u0026#34; time.sleep(n) print(sleep_n_seconds.__doc__) print(sleep_n_seconds.__name__) print(sleep_n_seconds.__defaults__)   Pause processing for n seconds. Args: n (int): The number of seconds to pause for. sleep_n_seconds (10,) But if we decorate sleep_n_seconds() with the timer() decorator, when we try to print the docstring or default, we get nothing back. Furthermore, when we try to look up the function\u0026rsquo;s name, Python tells us that sleep_n_seconds()\u0026rsquo;s name is \u0026ldquo;wrapper\u0026rdquo;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import time def timer(func): def wrapper(*args, **kargs): start_time = time.time() result = func(*args, **kargs) print(time.time()-start_time) return result return wrapper @timer def sleep_n_seconds(n=10): \u0026#34;\u0026#34;\u0026#34;Pause processing for n seconds. Args: n (int): The number of seconds to pause for. \u0026#34;\u0026#34;\u0026#34; time.sleep(n) print(sleep_n_seconds.__doc__) print(sleep_n_seconds.__name__) print(sleep_n_seconds.__defaults__)   None wrapper None Remember that when we write decorators, we almost always define a nested function to return. Because the decorator overwrites the sleep_n_seconds() function, when you ask for sleep_n_seconds()\u0026rsquo;s docstring or name, you are actually referencing the nested function that was returned by the decorator. In this case, the nested function was called wrapper() and it didn\u0026rsquo;t have a docstring. You can access to this function via the closure, like\n1 2 3  print(sleep_n_seconds.__closure__[0].cell_contents.__doc__) print(sleep_n_seconds.__closure__[0].cell_contents.__name__) print(sleep_n_seconds.__closure__[0].cell_contents.__defaults__)   Pause processing for n seconds. Args: n (int): The number of seconds to pause for. sleep_n_seconds (10,) But there is an easy way to get to it if you need it. The wraps() function from the functools module is a decorator that you use when defining a decorator. If you use it to decorate the wrapper function that your decorator returns, it will modify wrapper()\u0026rsquo;s metadata to look like the function you are decorating. Notice that the wraps() decorator takes the function you are decorating as an argument, we will talked about decorators that take arguments in the next section.\nIf we use this updated version of the timer() decorator to decorate sleep_n_seconds() and then try to print sleep_n_seconds()\u0026rsquo;s metadata, Python gives you the metadata from the function being decorated rather than the metadata of the wrapper() function.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  import time from functools import wraps def timer(func): @wraps(func) def wrapper(*args, **kargs): start_time = time.time() result = func(*args, **kargs) print(time.time()-start_time) return result return wrapper @timer def sleep_n_seconds(n=10): \u0026#34;\u0026#34;\u0026#34;Pause processing for n seconds. Args: n (int): The number of seconds to pause for. \u0026#34;\u0026#34;\u0026#34; time.sleep(n) print(f\u0026#34;sleep {n}s\u0026#34;) print(sleep_n_seconds.__doc__) print(sleep_n_seconds.__name__) print(sleep_n_seconds.__defaults__) # \u0026lt;-- why???   Pause processing for n seconds. Args: n (int): The number of seconds to pause for. sleep_n_seconds None # \u0026lt;-- why??? As an added bonus, using wraps() when creating your decorator also gives you easy access to the original undecorated function via the __wrapped__ attribute, or .__closure__[0].cell_content__\n1 2 3 4 5 6 7  orgfuc = sleep_n_seconds.__wrapped__ print(orgfuc) print(sleep_n_seconds.__closure__[0].cell_contents) print(orgfuc.__doc__) print(orgfuc.__name__) print(orgfuc.__defaults__)   \u0026lt;function sleep_n_seconds at 0x7fdc88b33af0\u0026gt; \u0026lt;function sleep_n_seconds at 0x7fdc88b33af0\u0026gt; Pause processing for n seconds. Args: n (int): The number of seconds to pause for. sleep_n_seconds (10,) Notice that __wrapped__ attribute is a function object, thus you can call it directly.\n1  orgfuc(3)   sleep 3s Decorators that take arguments To add arguments to our decorator, we need another level of function nesting.\nLet\u0026rsquo;s consider this run_three_times() decorator. If you use it to decorate a function, it will run that function three times.\n1 2 3 4 5  def run_three_times(func): def wrapper(*args, **kargs): for _ in range(3): func(*args, **kargs) return wrapper   Let\u0026rsquo;s think about what we would need to change if we wanted to write a run_n_times() decorator. A decorator is only supposed to take one argument - the function it is decorating. Also, when you use decorator syntax, you\u0026rsquo;re not supposed to use the parentheses. To make run_n_times() work, we have to turn it into a function that returns a decorator, rather than a function that is a decorator.\nSo run_n_times() takes n as an argument, instead of func. Then, inside of run_n_times(), we\u0026rsquo;ll define a new decorator function. This function takes \u0026ldquo;func\u0026rdquo; as an argument because it is the function that will be acting as our decorator. We start our new decorator with a nested wrapper() function, as usual. Finally, run_n_times() returns the decorator() function we just defined, then we can use that return value as a decorator.\n1 2 3 4 5 6 7 8 9 10 11 12 13  def run_n_times(n): def decorator(func): def wrapper(*arg, **kargs): for _ in range(n): func(*arg, **kargs) return wrapper return decorator @run_n_times(4) def print_sum(a,b): print(a+b) print(1,3)   4 4 4 4 Notice how when we decorate print_sum() with run_n_times(), we use parentheses after @run_n_times. This indicates that we are actually calling run_n_times() and decorating print_sum() with the result of that function call. Since the return value from run_n_times() is a decorator function, we can use it to decorate print_sum().\nNow let\u0026rsquo;s explain exactly how this works without using decorator syntax. Like before, we have a function, run_n_times() that returns a decorator function when you call it. If we call run_n_times() with the argument 3, it will return a decorator. In fact, it returns the decorator just like run_three_times defined above. The argument 3 is in the closure of returned decorator:\n1 2  # run_n_times(3) almost e.t. run_three_times print([cell.cell_contents for cell in run_n_times(3).__closure__])   [3] We could decorate print_sum() with this returned new decorator using decorator syntax. Python makes it convenient to do both of those in a single step though. When we use decorator syntax, the thing that comes after the @ symbol must be a reference to a decorator function. We can use the name of a specific decorator, or we can call a function that returns a decorator.\nNotice that decorating a function almost is equivalent with overwriting it. Thus we can decorate an already has been defined function by overwriting like:\n1 2  print = run_n_times(5)(print) # run_n_times(5) returns a decorator, and then the decorator overwrites `print` and assigns the result to `print`. print(\u0026#34;hello\u0026#34;)   hello hello hello hello hello  Remember implement del print after test.\n There is another application:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  def html(open_tag, close_tag): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): msg = func(*args, **kwargs) return \u0026#39;{}{}{}\u0026#39;.format(open_tag, msg, close_tag) return wrapper return decorator @html(\u0026#34;\u0026lt;b\u0026gt;\u0026#34;, \u0026#34;\u0026lt;/b\u0026gt;\u0026#34;) def hello(name): return \u0026#39;Hello {}!\u0026#39;.format(name) @html(\u0026#34;\u0026lt;i\u0026gt;\u0026#34;, \u0026#34;\u0026lt;/i\u0026gt;\u0026#34;) def goodbye(name): return \u0026#39;Goodbye {}.\u0026#39;.format(name) @html(\u0026#34;\u0026lt;div\u0026gt;\u0026#34;, \u0026#34;\u0026lt;/div\u0026gt;\u0026#34;) def hello_goodbye(name): return \u0026#39;\\n{}\\n{}\\n\u0026#39;.format(hello(name), goodbye(name)) print(hello_goodbye(\u0026#39;Alice\u0026#39;))   \u0026lt;div\u0026gt; \u0026lt;b\u0026gt;Hello Alice!\u0026lt;/b\u0026gt; \u0026lt;i\u0026gt;Goodbye Alice.\u0026lt;/i\u0026gt; \u0026lt;/div\u0026gt; Other real world examples timeout Let\u0026rsquo;s imagine that we have some functions that occasionally either run for longer than we want them to or just hang and never return. It would be nice if we could add some kind of timeout() decorator to those functions that will raise an error if the function runs for longer than expected.\nTo create the timeout() decorator, we are going to use some functions from Python\u0026rsquo;s signal module.\n The signal.signal() function tells Python, \u0026ldquo;When you see the signal whose number is signalnum, call the handler function.\u0026rdquo;. In this case, we tell Python to call raise_timeout() whenever it sees the alarm signal. The raise_timeout() function raises a TimeoutError when it is called. The signal.alarm() function lets us set an alarm for some number of seconds in the future. Passing 0 to the alarm() function cancels the alarm. timeout() is a function that returns a decorator. It just like a decorator factory. When you call timeout(), it cranks out a brand new decorator that times out in 5 seconds, or 20 seconds, or whatever value we pass as n_seconds. wrapper() sets an alarm for 5 seconds in the future. Then it calls the function being decorated. It wraps that call in a try block so that in a finally block we can cancel the alarm. This ensures that the alarm either rings or gets canceled. Remember, when the alarm rings, Python calls the raise_timeout() function.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import time import signal import functools def raise_timeout(*args, **kwargs): # \u0026lt;-- Notice the arguments, why??? raise TimeoutError(\u0026#34;you timeout\u0026#34;) signal.signal( signalnum=signal.SIGALRM, handler=raise_timeout ) def timeout(n_seconds): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): signal.alarm(n_seconds) try: return func(*args, **kwargs) finally: signal.alarm(0) return wrapper return decorator @timeout(3) def foo(): time.sleep(5) print(\u0026#39;foo!\u0026#39;) @timeout(20) def bar(): time.sleep(5) print(\u0026#39;bar!\u0026#39;) foo()   --------------------------------------------------------------------------- TimeoutError Traceback (most recent call last) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_38592/2588934869.py in \u0026lt;module\u0026gt; 31 print('bar!') 32 ---\u0026gt; 33 foo() /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_38592/2588934869.py in wrapper(*args, **kwargs) 15 signal.alarm(n_seconds) 16 try: ---\u0026gt; 17 return func(*args, **kwargs) 18 finally: 19 signal.alarm(0) /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_38592/2588934869.py in foo() 23 @timeout(3) 24 def foo(): ---\u0026gt; 25 time.sleep(5) 26 print('foo!') 27 /var/folders/p6/qtqch15n41v436lkcl5zb7g80000gn/T/ipykernel_38592/2588934869.py in raise_timeout(*args, **kwargs) 2 3 def raise_timeout(*args, **kwargs): ----\u0026gt; 4 raise TimeoutError(\u0026quot;you timeout\u0026quot;) 5 6 signal.signal( TimeoutError: you timeout 1  bar()   bar! Notice that wrapper() returns the result of calling func(), decorator() returns wrapper, and timeout() returns decorator. So when we call foo(), which has a 5-second timeout, it will timeout like before. But bar(), which has a 20-second timeout, prints its message in 10 seconds, so the alarm gets canceled.\ntag your functions 1 2 3 4 5 6 7 8 9 10 11 12 13 14  def tag(*tags): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): return func(*args, **kwargs) wrapper.tags = tags return wrapper return decorator @tag(\u0026#39;test\u0026#39;, \u0026#39;this is a tag\u0026#39;) def foo(): pass print(foo.tags)   ('test', 'this is a tag') Check the return type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  def returns(return_type): def decorator(func): def wrapper(*args, **kargs): result = func(*args, **kargs) assert type(result) == return_type return result return wrapper return decorator @returns(dict) def foo(value): return value try: print(foo([1,2,3])) except AssertionError: print(\u0026#39;foo() did not return a dict!\u0026#39;)   foo() did not return a dict! assert \u0026lt;condition\u0026gt; return an AssertionError if \u0026lt;condition\u0026gt; is False.\n","date":"2019-08-19T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-iii-context-managers-decorators/","title":"Object Oriented Programming III (Context Managers \u0026 Decorators)"},{"content":" All figures in this blog are embedded by Github Image Hosting Service. These figures may not be displayed on mobile devices.\n Iterators in PythonLand Introduction to iterators When you use a for loop to print out each element of a list, you\u0026rsquo;re iterating over the list. You can also use a for loop to iterate over characters in a string. You can also use a for loop to iterate a over a sequence of numbers produced by a special range object. The reason that we can loop over such objects is that they are special objects called iterables: lists, strings and range objects are all iterables, as are many other Python objects, such as dictionaries and file connections.\nThe actual definition of an iterable is an object that has an associated iter() method. Once this iter() method is applied to an iterable, an iterator object is created. An iterator is defined as an object that has an associated next() method that produces the consecutive values. To create an iterator from an iterable, all we need to do is use the function iter() and pass it the iterable. Once we have the iterator defined, we pass it to the function next() and this returns the first value. Calling next() again on the iterator returns the next value until there are no values left to return and then it throws us a StopIteration error.\n iter(iterable) \u0026mdash;-\u0026gt; iterator next(iterator) \u0026mdash;-\u0026gt; iterate the elements in iterator   Under the hood, this is actually what a for loop is doing: it takes an iterable, creates the associated iterator object, and iterates over it.\n 1 2 3 4 5 6 7 8 9 10  flash = [\u0026#39;jay garrick\u0026#39;, \u0026#39;barry allen\u0026#39;, \u0026#39;wally west\u0026#39;, \u0026#39;bart allen\u0026#39;] for item in flash: print(item) # e.t. superhero = iter(flash) print(next(superhero)) print(next(superhero)) print(next(superhero)) print(next(superhero))   jay garrick barry allen wally west bart allen jay garrick barry allen wally west bart allen You can also print all values of an iterator in one fell swoop using the * operator. This * operator unpacks all elements of an iterator or an iterable. Be warned, however, once you do so, you cannot do it (the iterator instead of the iterable) again as there are no more values to iterate through. We would have to redefine our iterator to do so.\n1 2 3 4 5 6 7 8 9 10 11 12  def pr(ob): print(\u0026#34;ob: \u0026#34;, ob) print(\u0026#34;*ob: \u0026#34;, *ob) print(\u0026#34;type: \u0026#34;, type(ob), \u0026#34;\\n\u0026#34;) word = \u0026#34;dfghjhgfds\u0026#34; word1 = iter(word) pr(word) pr(word1) pr(word) pr(word1)   ob: dfghjhgfds *ob: d f g h j h g f d s type: \u0026lt;class 'str'\u0026gt; ob: \u0026lt;str_iterator object at 0x7fc5787b2ac0\u0026gt; *ob: d f g h j h g f d s type: \u0026lt;class 'str_iterator'\u0026gt; ob: dfghjhgfds *ob: d f g h j h g f d s type: \u0026lt;class 'str'\u0026gt; ob: \u0026lt;str_iterator object at 0x7fc5787b2ac0\u0026gt; *ob: type: \u0026lt;class 'str_iterator'\u0026gt; You can also assembles the elements, in the iterator, into a list with list() method\n1 2 3 4  word = \u0026#34;dfghjhgfds\u0026#34; word1 = iter(word) print(word1) print(list(word1))   \u0026lt;str_iterator object at 0x7fc5787b2df0\u0026gt; ['d', 'f', 'g', 'h', 'j', 'h', 'g', 'f', 'd', 's'] We mentioned before that dictionaries and file connections are iterables as well. To iterate over the key-value pairs of a Python dictionary, we need to unpack them by applying the items() method to the dictionary.\nw.r.t. file connections, here you can see how to use the iter() and next() methods to return the lines from a file.\n1 2 3 4 5 6 7 8  (base) wanghaoming@localhost oop_ii_slide % touch file.txt (base) wanghaoming@localhost oop_ii_slide % echo \u0026#34;the first line\u0026#34; \u0026gt; file.txt (base) wanghaoming@localhost oop_ii_slide % echo \u0026#34;the second line\u0026#34; \u0026gt;\u0026gt; file.txt (base) wanghaoming@localhost oop_ii_slide % echo \u0026#34;the third line\u0026#34; \u0026gt;\u0026gt; file.txt (base) wanghaoming@localhost oop_ii_slide % cat file.txt the first line the second line the third line   1 2 3 4 5 6 7 8 9 10  def pr(ob): print(\u0026#34;ob: \u0026#34;, ob) print(next(ob)) # Placing it below *ob will cause an error because there are no more elements in the iterator print(\u0026#34;*ob: \u0026#34;, *ob) print(\u0026#34;type: \u0026#34;, type(ob), \u0026#34;\\n\u0026#34;) file = open(\u0026#34;file.txt\u0026#34;) it = iter(file) pr(it)   ob: \u0026lt;_io.TextIOWrapper name='file.txt' mode='r' encoding='UTF-8'\u0026gt; the first line *ob: the second line # \u0026lt;-- Notice here the third line type: \u0026lt;class '_io.TextIOWrapper'\u0026gt; Operating iterator Now, we are going to introduce two useful functions. The first function, enumerate, will allow us to add a counter to any iterable while the second function, zip, will allow us to stitch together an arbitrary number of iterables.\nenumerate is a function that takes any iterable as argument, such as a list, and returns a special enumerate object, which consists of pairs containing the elements of the original iterable, along with their index within the iterable. The enumerate object itself is also an iterable and we can loop over it while unpacking its elements using the clause for index, value in enumerate(avengers). The default behavior of enumerate to begin indexing at 0. However, you can alter this with startargument, such as start=10\n1 2 3 4 5 6 7 8  tx = \u0026#34;asdfghjkll\u0026#34; etx = enumerate(tx) print(*tx) print(list(tx)) print(*etx) print(list(etx))   a s d f g h j k l l ['a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'l'] (0, 'a') (1, 's') (2, 'd') (3, 'f') (4, 'g') (5, 'h') (6, 'j') (7, 'k') (8, 'l') (9, 'l') [] # \u0026lt;-- lazy evaluation Notice that The enumerate object has the characteristics of lazy evaluation. The elements that have been visited in the enumerate object cannot be accessed again, and the use of square brackets to index the elements is not supported. (Objects like zip, filter, map, etc. have similar characteristics.)\n1 2 3 4 5 6 7 8  tx = \u0026#34;asdfghjkll\u0026#34; mtx = map( lambda x: x+\u0026#34;!\u0026#34;, tx ) print(mtx) print(*mtx) print(list(mtx))   \u0026lt;map object at 0x7fc5a95e7b20\u0026gt; a! s! d! f! g! h! j! k! l! l! [] Now let\u0026rsquo;s move on to zip, which accepts an arbitrary number of iterables and returns an iterator of tuples. We could use a for loop to iterate over the zip object and print the tuples. We could also have used the * operator or list method to print all the elements.\n1 2 3 4 5 6 7 8  s = \u0026#34;asdfghjkl\u0026#34; t = \u0026#34;qwertyuio\u0026#34; st = zip(s,t) print(st) print(next(st), \u0026#34;\\n\u0026#34;) for i in st: print(i)   \u0026lt;zip object at 0x7fc5787fce40\u0026gt; ('a', 'q') ('s', 'w') ('d', 'e') ('f', 'r') ('g', 't') ('h', 'y') ('j', 'u') ('k', 'i') ('l', 'o') Notice the difference between zip(), *zip(), and zip(*).\n zip(it1, it2) can assemble two iterable object it1, it2 to a zip object; zip(it1) assemble a iterable object it with an empty iterable object. *z can show a zip object; zip(*z) can disassemble a zip object z to the original iterable objects.  1 2 3 4 5 6 7 8 9  s = list(\u0026#34;asdfghjkl\u0026#34;) t = list(\u0026#34;qwertyuio\u0026#34;) print(\u0026#34;zip:\u0026#34;, zip(s,t)) print(\u0026#34;*zip:\u0026#34;, *zip(s,t)) print(\u0026#34;zip(*):\u0026#34;, *zip(*zip(s,t))) s1, t1 = zip(*zip(s,t)) print(list(s1) == s and list(t1) == t)   zip: \u0026lt;zip object at 0x7fc5a95b2ec0\u0026gt; *zip: ('a', 'q') ('s', 'w') ('d', 'e') ('f', 'r') ('g', 't') ('h', 'y') ('j', 'u') ('k', 'i') ('l', 'o') zip(*): ('a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l') ('q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o') True 1 2 3 4 5 6 7  z1 = zip(mutants, powers) print(*z1) z1 = zip(mutants, powers) result1, result2 = zip(*z1) print(result1 == mutants) print(result2 == powers)   ('charles xavier', 'telepathy') ('bobby drake', 'thermokinesis') ('kurt wagner', 'teleportation') ('max eisenhardt', 'magnetokinesis') ('kitty pryde', 'intangibility') True True Using iterators to load large files into memory If you are pulling data that you can\u0026rsquo;t hold it in memory. One solution is to load the data in chunks, perform the desired operation or operations on each chuck, store the result, discard the chunk and then load the next chunk. To surmount this challenge, we can use the pandas function pd.read_csv()and specify the argument chunksize.\nThe object created by the read_csv() call is an iterable so you can can iterate over it, using a for loop, in which each chunk will be a DataFrame.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def count_entries(csv_file, c_size, colname): \u0026#34;\u0026#34;\u0026#34;Return a dictionary with counts of occurrences as value for each key.\u0026#34;\u0026#34;\u0026#34; counts_dict = {} for chunk in pd.read_csv(csv_file, chunksize=c_size): for entry in chunk[colname]: if entry in counts_dict.keys(): counts_dict[entry] += 1 else: counts_dict[entry] = 1 return counts_dict result_counts = count_entries(\u0026#34;tweets.csv\u0026#34;, 10, \u0026#34;lang\u0026#34;) print(result_counts)   {'en': 97, 'et': 1, 'und': 2} List comprehensions and generators List comprehensions You can finish a for loop in one line of code by comprehensions. The syntax is as follows:\n1  [ \u0026lt;expression\u0026gt; for \u0026lt;variable\u0026gt; in \u0026lt;iterable\u0026gt; ]    You can write a list comprehension over any iterable.\n 1 2 3 4 5  matrix = [[i for i in range(6)] for j in range(5)] Print the matrix for row in matrix: print(row)   [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5] [0, 1, 2, 3, 4, 5] 1 2 3 4 5  tweet_time = df[\u0026#34;created_at\u0026#34;] print(tweet_time.head()) tweet_clock_time = [entry[12:20] for entry in tweet_time] print(tweet_clock_time)   0 Tue Mar 29 23:40:17 +0000 2016 1 Tue Mar 29 23:40:17 +0000 2016 2 Tue Mar 29 23:40:17 +0000 2016 3 Tue Mar 29 23:40:17 +0000 2016 4 Tue Mar 29 23:40:17 +0000 2016 Name: created_at, dtype: object ['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19'] We can also use list comprehensions to create nested loop. The syntax is as follows:\n1  [\u0026lt;exp.\u0026gt; \u0026lt;outer for loop\u0026gt; \u0026lt;inner for loop\u0026gt;]   1 2  ls = [(x,y) for x in range(0,3) for y in range(3,6)] print(ls)   [(0, 3), (0, 4), (0, 5), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5)] Advanced comprehensions We can filter the output of a list comprehension using a conditional on the iterable, the syntax is as follows:\n1  [\u0026lt;exp.\u0026gt; \u0026lt;for loop\u0026gt; if \u0026lt;con.\u0026gt;]   We can also condition the list comprehension on the output expression, like\n1  [\u0026lt;exp.\u0026gt; if \u0026lt;con.\u0026gt; else \u0026lt;exp.\u0026gt; \u0026lt;for loop\u0026gt;]   1 2 3 4 5 6 7 8 9 10 11 12 13 14  [ \u0026lt;exp.1\u0026gt; if \u0026lt;con.1\u0026gt; else \u0026lt;exp.2\u0026gt; if \u0026lt;con.2\u0026gt; else \u0026lt;exp3\u0026gt; \u0026lt;for loop\u0026gt; ] # e.t. if con.1: exp.1 elif con.2: exp.2 else: exp.3   some example:\n1 2 3 4 5  fellowship = [\u0026#39;frodo\u0026#39;, \u0026#39;samwise\u0026#39;, \u0026#39;merry\u0026#39;, \u0026#39;aragorn\u0026#39;, \u0026#39;legolas\u0026#39;, \u0026#39;boromir\u0026#39;, \u0026#39;gimli\u0026#39;] new_fellowship = [member for member in fellowship if len(member)\u0026gt;=7] print(new_fellowship)   ['samwise', 'aragorn', 'legolas', 'boromir'] 1 2 3 4 5  fellowship = [\u0026#39;frodo\u0026#39;, \u0026#39;samwise\u0026#39;, \u0026#39;merry\u0026#39;, \u0026#39;aragorn\u0026#39;, \u0026#39;legolas\u0026#39;, \u0026#39;boromir\u0026#39;, \u0026#39;gimli\u0026#39;] new_fellowship = [member if len(member)\u0026gt;=7 else \u0026#34;\u0026#34; for member in fellowship] print(new_fellowship)   ['', 'samwise', '', 'aragorn', 'legolas', 'boromir', ''] 1 2 3 4 5  tweet_time = df[\u0026#34;created_at\u0026#34;] tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == \u0026#34;19\u0026#34;] print(tweet_clock_time)   ['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19'] Dictionary comprehensions Now we can also write dictionary comprehensions to create new dictionaries from iterables. The syntax is almost the same as in list comprehensions and there are 2 differences.\n One, we use curly braces instead of square brackets. Two, the key and value are separated by a colon in the output expression.  We can generate a dictionary from two list:\n1 2 3 4 5 6  keys = list(\u0026#34;abcdefg\u0026#34;) vals = list(\u0026#34;1234567\u0026#34;) dic = { key: value for key, value in zip(keys, vals) } print(dic)   {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5', 'f': '6', 'g': '7'} 1 2 3 4 5 6  import numpy as np import pandas as pd ks = list(\u0026#34;abcde\u0026#34;) vs = [np.random.randn(10) for i in range(5)] df = pd.DataFrame({k:v for k,v in zip(ks,vs)}) print(df)    a b c d e 0 0.108696 0.405694 0.018458 0.529013 0.284126 1 0.645469 0.937125 -0.420953 0.210035 0.151663 2 1.414896 1.298583 1.485383 -0.096663 0.036326 3 0.883876 -3.009644 1.328881 -0.127821 -0.111707 4 1.888317 -2.507632 0.157957 2.036903 2.164004 5 0.144894 1.298034 0.160900 -0.022732 0.080893 6 -0.233574 0.076446 -0.146595 0.842054 1.818775 7 0.509977 -0.424521 0.657196 -0.913793 0.131405 8 -0.049865 -0.816738 -0.975876 0.170173 -0.569519 9 -0.269802 0.755459 0.021207 0.102335 0.119438 1 2 3 4 5 6 7 8 9 10 11  import numpy as np import pandas as pd ks = list(\u0026#34;abcde\u0026#34;) vs = [ np.random.rand(10) if i \u0026lt;2 else np.random.uniform(5,6,10) if i\u0026lt;4 else np.random.randint(0,9,10) for i in range(5) ] df = pd.DataFrame({k:v for k,v in zip(ks,vs)}) print(df)    a b c d e 0 0.797270 0.079468 5.167152 5.205353 7 1 0.036326 0.752136 5.421250 5.275327 4 2 0.698624 0.703501 5.322341 5.295758 8 3 0.306367 0.092034 5.659722 5.430591 8 4 0.217272 0.251593 5.353020 5.078669 2 5 0.404077 0.882906 5.145223 5.866817 3 6 0.677442 0.012514 5.186332 5.221120 8 7 0.080858 0.226505 5.724067 5.976189 7 8 0.366588 0.884782 5.561158 5.070010 6 9 0.694882 0.928411 5.180124 5.449207 2 1 2 3 4 5 6 7  fellowship = [\u0026#39;frodo\u0026#39;, \u0026#39;samwise\u0026#39;, \u0026#39;merry\u0026#39;, \u0026#39;aragorn\u0026#39;, \u0026#39;legolas\u0026#39;, \u0026#39;boromir\u0026#39;, \u0026#39;gimli\u0026#39;] new_fellowship = { member: len(member) for member in fellowship } print(new_fellowship)   {'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5} Generator expressions Recall that this list comprehension will create a list. Now lets replace the square brackets with round parentheses. Something called a generator object has been created.\nA generator is like a list comprehension except it does not store the list in memory: it does not construct the list, but is an object we can iterate over to produce elements of the list as required. Like any other iterator, we can pass a generator to the function next() in order to iterate through its elements.\n1 2 3 4 5 6 7 8 9 10 11  result = (num for num in range(0,10)) print(next(result)) print(next(result)) print(next(result)) print(next(result)) print(next(result), \u0026#34;\\n\u0026#34;) # Print the rest of the values for value in result: print(value)   0 1 2 3 4 5 6 7 8 9 Generator is an example of something called lazy evaluation, whereby the evaluation of the expression is delayed until its value is needed. (This means that you can\u0026rsquo;t index values by square brackets.) This can help a great deal when working with extremely large sequences as you don\u0026rsquo;t want to store the entire list in memory, which is what comprehensions would do; you can generate elements of the sequence on the fly. Let\u0026rsquo;s say that we wanted to iterate over a very large sequence of numbers, such as from 0 up to 10 to the power of a million.\n1  [i for i in range(10 ** 1000000)]    DO NOT try this on your personal computer.\n This can cause outages, since the list we are trying to create are so large that can\u0026rsquo;t even be stored in memory. however: We can easily create the analogous generator object because it does not yet create the entire list.\n1 2  g = (i for i in range(10 ** 1000000)) print(next(g))   0 The thing we can do in a list comprehension such as filtering and applying conditionals, can also be done in a generator expression.\nGenerator functions are functions that, when called, produce generator objects. Generator functions are written with the syntax of any other user-defined function, however instead of returning values using the keyword return, they yield sequences of values using the keyword yield.\n1 2 3 4 5 6 7 8 9 10 11  lannister = [\u0026#39;cersei\u0026#39;, \u0026#39;jaime\u0026#39;, \u0026#39;tywin\u0026#39;, \u0026#39;tyrion\u0026#39;, \u0026#39;joffrey\u0026#39;] def get_lengths(input_list): \u0026#34;\u0026#34;\u0026#34;Generator function that yields the length of the strings in input_list.\u0026#34;\u0026#34;\u0026#34; for person in input_list: yield len(person) for value in get_lengths(lannister): print(value)   6 5 5 6 7 World Bank Data Analysis Case Here, we will use the skills of writing user-defined functions, iterators, list comprehensions and generators to wrangle and extract meaningful information from a real-world dataset, the World Bank World Development Indicators dataset.\nThis dataset contains data on 217 world economies for over half a century, from 1960 up until 2015. The data contains hundreds of indicators from population, electricity consumption and CO2 emissions to literacy rates, unemployment and mortality rates.\n The first list feature_names contains header names of the dataset and the second list row_vals contains actual values of a row from the dataset, corresponding to each of the header names. Create a zip object by calling zip() and passing to it feature_names and row_vals. Assign the result to zipped_lists. Create a dictionary from the zipped_lists zip object by calling dict() with zipped_lists. Assign the resulting dictionary to rs_dict.\n1 2 3  zipped_lists = zip(feature_names, row_vals) rs_dict = dict(zipped_lists) # e.t. rs_dict = {k:v for k,v in zipped_lists} print(rs_dict)   {'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'} Define the function lists2dict() with two parameters: first is list1 and second is list2. Return the resulting dictionary rs_dict in lists2dict(). Call the lists2dict() function with the arguments feature_names and row_vals. Assign the result of the function call to rs_fxn.\n1 2 3 4 5 6 7 8 9  def lists2dict(list1, list2): \u0026#34;\u0026#34;\u0026#34;Return a dictionary where list1 provides the keys and list2 provides the values.\u0026#34;\u0026#34;\u0026#34; zipped_lists = zip(list1, list2) rs_dict = dict(zipped_lists) return rs_dict rs_fxn = lists2dict(feature_names, row_vals) print(rs_fxn)   {'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'} row_lists is a list of lists, where each sublist is a list of actual values of a row from the dataset. Inspect the contents of row_lists by printing the first two lists in row_lists. Create a list comprehension that generates a dictionary using lists2dict() for each sublist in row_lists. The keys are from the feature_names list and the values are the row entries in row_lists. Use sublist as your iterator variable and assign the resulting list of dictionaries to list_of_dicts. Look at the first two dictionaries in list_of_dicts by printing them out.\n1 2 3 4 5 6 7  print(row_lists[0]) print(row_lists[1]) list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists] print(list_of_dicts[0]) print(list_of_dicts[1])   ['Arab World', 'ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT', '1960', '133.56090740552298'] ['Arab World', 'ARB', 'Age dependency ratio (% of working-age population)', 'SP.POP.DPND', '1960', '87.7976011532547'] {'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'} {'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Age dependency ratio (% of working-age population)', 'IndicatorCode': 'SP.POP.DPND', 'Year': '1960', 'Value': '87.7976011532547'} To use the DataFrame() function, first import the pandas package with the alias pd. Create a DataFrame from the list of dictionaries in list_of_dicts by calling pd.DataFrame(). Assign the resulting DataFrame to df. Inspect the contents of df printing the head of the DataFrame. Head of the DataFrame df can be accessed by calling df.head().\n1 2 3 4 5  import pandas as pd list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists] df = pd.DataFrame(list_of_dicts) df.head()    CountryName CountryCode IndicatorName IndicatorCode Year Value 0 Arab World ARB Adolescent fertility rate (births per 1,000 wo... SP.ADO.TFRT 1960 133.56090740552298 1 Arab World ARB Age dependency ratio (% of working-age populat... SP.POP.DPND 1960 87.7976011532547 2 Arab World ARB Age dependency ratio, old (% of working-age po... SP.POP.DPND.OL 1960 6.634579191565161 3 Arab World ARB Age dependency ratio, young (% of working-age ... SP.POP.DPND.YG 1960 81.02332950839141 4 Arab World ARB Arms exports (SIPRI trend indicator values) MS.MIL.XPRT.KD 1960 3000000.0 In the function read_large_file(), read a line from file_object by using the method readline(). Assign the result to data. In the function read_large_file(), yield the line read from the file data. In the context manager, create a generator object gen_file by calling your generator function read_large_file() and passing file to it. Print the first three lines produced by the generator object gen_file using next().\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def read_large_file(file_object): \u0026#34;\u0026#34;\u0026#34;A generator function to read a large file lazily.\u0026#34;\u0026#34;\u0026#34; while True: data = file_object.readline() if not data: # \u0026lt;-- Break if this is the end of the file break yield data # \u0026lt;-- After calling read_large_file(), in each loop, programme will freeze here until calling next() with open(\u0026#39;world_dev_ind.csv\u0026#39;) as file: gen_file = read_large_file(file) print(next(gen_file)) print(next(gen_file)) print(next(gen_file))   CountryName,CountryCode,IndicatorName,IndicatorCode,Year,Value Arab World,ARB,\u0026quot;Adolescent fertility rate (births per 1,000 women ages 15-19)\u0026quot;,SP.ADO.TFRT,1960,133.56090740552298 Arab World,ARB,Age dependency ratio (% of working-age population),SP.POP.DPND,1960,87.7976011532547 Bind the file \u0026lsquo;world_dev_ind.csv\u0026rsquo; to file in the context manager with open(). Complete the for loop so that it iterates over the generator from the call to read_large_file() to process all the rows of the file.\n1 2 3 4 5 6 7 8 9 10 11 12 13  counts_dict = {} with open(\u0026#34;world_dev_ind.csv\u0026#34;) as file: for line in read_large_file(file): # \u0026lt;-- Each loop is a call to next() row = line.split(\u0026#39;,\u0026#39;) # \u0026lt;-- Separate each line of the CSV with a comma and generate a list first_col = row[0] if first_col in counts_dict.keys(): counts_dict[first_col] += 1 else: counts_dict[first_col] = 1 print(counts_dict)   {'CountryName': 1, 'Arab World': 80, 'Caribbean small states': 77, 'Central Europe and the Baltics': 71, 'East Asia \u0026amp; Pacific (all income levels)': 122, 'East Asia \u0026amp; Pacific (developing only)': 123, 'Euro area': 119, 'Europe \u0026amp; Central Asia (all income levels)': 109, 'Europe \u0026amp; Central Asia (developing only)': 89, 'European Union': 116, 'Fragile and conflict affected situations': 76, 'Heavily indebted poor countries (HIPC)': 99, 'High income': 131, 'High income: nonOECD': 68, 'High income: OECD': 127, 'Latin America \u0026amp; Caribbean (all income levels)': 130, 'Latin America \u0026amp; Caribbean (developing only)': 133, 'Least developed countries: UN classification': 78, 'Low \u0026amp; middle income': 138, 'Low income': 80, 'Lower middle income': 126, 'Middle East \u0026amp; North Africa (all income levels)': 89, 'Middle East \u0026amp; North Africa (developing only)': 94, 'Middle income': 138, 'North America': 123, 'OECD members': 130, 'Other small states': 63, 'Pacific island small states': 66, 'Small states': 69, 'South Asia': 36} Use pd.read_csv() to read in \u0026lsquo;ind_pop.csv\u0026rsquo; in chunks of size 10. Assign the result to df_reader. Print the first two chunks from df_reader.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import pandas as pd df_reader = pd.read_csv(\u0026#34;ind_pop.csv\u0026#34;, chunksize=10) print(next(df_reader)) print(next(df_reader)) # e.t. # t=0 # for i in df_reaedr: # \u0026lt;-- Each loop is a next() # t += 1 # print(i) # if t == 2: # break    CountryName CountryCode IndicatorName IndicatorCode Year Value 0 Arab World ARB Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 31.285 1 Caribbean small states CSS Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 31.597 2 Central Europe and the Baltics CEB Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 44.508 3 East Asia \u0026amp; Pacific (all income levels) EAS Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 22.471 4 East Asia \u0026amp; Pacific (developing only) EAP Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 16.918 5 Euro area EMU Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 62.097 6 Europe \u0026amp; Central Asia (all income levels) ECS Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 55.379 7 Europe \u0026amp; Central Asia (developing only) ECA Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 38.066 8 European Union EUU Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 61.213 9 Fragile and conflict affected situations FCS Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 17.892 CountryName CountryCode IndicatorName IndicatorCode Year Value 10 Heavily indebted poor countries (HIPC) HPC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 12.236 11 High income HIC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 62.680 12 High income: nonOECD NOC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 56.108 13 High income: OECD OEC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 64.285 14 Latin America \u0026amp; Caribbean (all income levels) LCN Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 49.285 15 Latin America \u0026amp; Caribbean (developing only) LAC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 44.863 16 Least developed countries: UN classification LDC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 9.616 17 Low \u0026amp; middle income LMY Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 21.273 18 Low income LIC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 11.498 19 Lower middle income LMC Urban population (% of total) SP.URB.TOTL.IN.ZS 1960 19.811 Use pd.read_csv() to read in the file in \u0026lsquo;ind_pop_data.csv\u0026rsquo; in chunks of size 1000. Assign the result to urb_pop_reader. Get the first DataFrame chunk from the iterable urb_pop_reader and assign this to df_urb_pop.\nSelect only the rows of df_urb_pop that have a \u0026lsquo;CountryCode\u0026rsquo; of \u0026lsquo;CEB\u0026rsquo;. Using zip(), zip together the \u0026lsquo;Total Population\u0026rsquo; and \u0026lsquo;Urban population (% of total)\u0026rsquo; columns of df_pop_ceb. Assign the resulting zip object to pops.\n1 2 3  urb_pop_reader = pd.read_csv(\u0026#34;ind_pop_data.csv\u0026#34;, chunksize=1000) df_urb_pop = next(urb_pop_reader) print(df_urb_pop.head())    CountryName CountryCode Year Total Population Urban population (% of total) 0 Arab World ARB 1960 9.250e+07 31.285 1 Caribbean small states CSS 1960 4.191e+06 31.597 2 Central Europe and the Baltics CEB 1960 9.140e+07 44.508 3 East Asia \u0026amp; Pacific (all income levels) EAS 1960 1.042e+09 22.471 4 East Asia \u0026amp; Pacific (developing only) EAP 1960 8.965e+08 16.918 1 2 3 4  df_pop_ceb = df_urb_pop[df_urb_pop[\u0026#34;CountryCode\u0026#34;]==\u0026#34;CEB\u0026#34;] pops = zip(df_pop_ceb[\u0026#39;Total Population\u0026#39;], df_pop_ceb[\u0026#39;Urban population (% of total)\u0026#39;]) pops_list = list(pops) print(pops_list)   [(91401583.0, 44.5079211390026), (92237118.0, 45.206665319194), (93014890.0, 45.866564696018), (93845749.0, 46.5340927663649), (94722599.0, 47.2087429803526)] Write a list comprehension to generate a list of values from pops_list for the new column \u0026lsquo;Total Urban Population\u0026rsquo;. The output expression should be the product of the first and second element in each tuple in pops_list. Because the 2nd element is a percentage, you also need to either multiply the result by 0.01 or divide it by 100. In addition, note that the column \u0026lsquo;Total Urban Population\u0026rsquo; should only be able to take on integer values. To ensure this, make sure you cast the output expression to an integer with int().\nCreate a scatter plot where the x-axis are values from the \u0026lsquo;Year\u0026rsquo; column and the y-axis are values from the \u0026lsquo;Total Urban Population\u0026rsquo; column.\n1 2 3 4 5 6 7 8 9 10  urb_pop_reader = pd.read_csv(\u0026#39;ind_pop_data.csv\u0026#39;, chunksize=1000) df_urb_pop = next(urb_pop_reader) df_pop_ceb = df_urb_pop[df_urb_pop[\u0026#39;CountryCode\u0026#39;] == \u0026#39;CEB\u0026#39;] pops = zip(df_pop_ceb[\u0026#39;Total Population\u0026#39;], df_pop_ceb[\u0026#39;Urban population (% of total)\u0026#39;]) pops_list = list(pops) df_pop_ceb[\u0026#39;Total Urban Population\u0026#39;] = [int(x[0]*x[1]*0.01) for x in pops_list ] df_pop_ceb.plot(kind=\u0026#34;scatter\u0026#34;, x=\u0026#34;Year\u0026#34;, y=\u0026#34;Total Urban Population\u0026#34;) plt.show()   Now let\u0026rsquo;s show the panoramic view. Initialize an empty DataFrame data using pd.DataFrame(). In the for loop, iterate over urb_pop_reader to be able to process all the DataFrame chunks in the dataset. Using the method append() of the DataFrame data, append df_pop_ceb to data.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  urb_pop_reader = pd.read_csv(\u0026#39;ind_pop_data.csv\u0026#39;, chunksize=1000) data = pd.DataFrame() for df_urb_pop in urb_pop_reader: df_pop_ceb = df_urb_pop[df_urb_pop[\u0026#39;CountryCode\u0026#39;] == \u0026#39;CEB\u0026#39;] pops = zip( df_pop_ceb[\u0026#39;Total Population\u0026#39;], df_pop_ceb[\u0026#39;Urban population (% of total)\u0026#39;] ) pops_list = list(pops) df_pop_ceb[\u0026#39;Total Urban Population\u0026#39;] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list] data = data.append(df_pop_ceb) data.plot(kind=\u0026#39;scatter\u0026#39;, x=\u0026#39;Year\u0026#39;, y=\u0026#39;Total Urban Population\u0026#39;) plt.show()   Now we encapsulate the above code into a function. Define the function plot_pop() that has two arguments: first is filename for the file to process and second is country_code for the country to be processed in the dataset. Call plot_pop() to process the data for country code \u0026lsquo;CEB\u0026rsquo; in the file \u0026lsquo;ind_pop_data.csv\u0026rsquo;. Call plot_pop() to process the data for country code \u0026lsquo;ARB\u0026rsquo; in the file \u0026lsquo;ind_pop_data.csv\u0026rsquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  def plot_pop(filename, country_code): urb_pop_reader = pd.read_csv(filename, chunksize=1000) data = pd.DataFrame() for df_urb_pop in urb_pop_reader: df_pop_ceb = df_urb_pop[df_urb_pop[\u0026#39;CountryCode\u0026#39;] == country_code] pops = zip( df_pop_ceb[\u0026#39;Total Population\u0026#39;], df_pop_ceb[\u0026#39;Urban population (% of total)\u0026#39;] ) pops_list = list(pops) df_pop_ceb[\u0026#39;Total Urban Population\u0026#39;] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list] data = data.append(df_pop_ceb) data.plot(kind=\u0026#39;scatter\u0026#39;, x=\u0026#39;Year\u0026#39;, y=\u0026#39;Total Urban Population\u0026#39;) plt.show() fn = \u0026#39;ind_pop_data.csv\u0026#39; # plot_pop(fn, \u0026#34;CEB\u0026#34;) plot_pop(fn, \u0026#34;ARB\u0026#34;)   ","date":"2019-08-16T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-ii-iterators-comprehensions-generators/","title":"Object Oriented Programming II (Iterators, Comprehensions \u0026 Generators)"},{"content":"Writing Functions Define function To define the function, We begin with the keyword def, followed by the function name; this is then followed by a set of parentheses and a colon. This piece of code is called a function header. To complete the function definition, We write the function body inside the indentation.\nThere\u0026rsquo;s an essential aspect of writing functions in Python: docstrings. Docstrings serve as documentation for your function so that anyone who reads your function\u0026rsquo;s docstring understands what your function does, without having to trace through all the code in the function definition. Function docstrings are placed in the immediate line after the function header and are placed in between triple quotation marks.\n1 2 3 4 5 6  def shout(): \u0026#34;\u0026#34;\u0026#34;Print a string with three exclamation marks\u0026#34;\u0026#34;\u0026#34; shout_word = \u0026#34;congratulations\u0026#34; + \u0026#34;!!!\u0026#34; print(shout_word) shout()   congratulations!!! You can add a parameter to the function definition in between the parentheses. When you define a function, you write parameters in the function header. When you call a function, you pass arguments into the function.\nWhat if we don\u0026rsquo;t want to print that outcome directly and instead we want to return the it and assign it to some variable? You can have your function return the new value by adding the return keyword, followed by the outcome to return.\n1 2 3 4 5 6 7  def shout(word): \u0026#34;\u0026#34;\u0026#34;Return a string with three exclamation marks\u0026#34;\u0026#34;\u0026#34; shout_word = word + \u0026#34;!!!\u0026#34; return shout_word yell = shout(\u0026#34;congratulations\u0026#34;) print(yell)   congratulations!!! Multiple parameters and return values We can imput multi parameters to the function.\n You should also change your function name and docstrings to reflect this new behavior.\n 1 2 3 4 5 6 7 8 9  def shout(word1, word2): \u0026#34;\u0026#34;\u0026#34;Concatenate strings with three exclamation marks\u0026#34;\u0026#34;\u0026#34; shout1 = word1 + \u0026#34;!!!\u0026#34; shout2 = word2 + \u0026#34;!!!\u0026#34; new_shout = shout1 + shout2 return new_shout yell = shout(\u0026#34;congratulations\u0026#34;, \u0026#34;you\u0026#34;) print(yell)   congratulations!!!you!!! You can also make your function return multiple values. You can do that by constructing objects known as tuples in your functions. In the function body, we construct a tuple consisting of the values we want the function to return ,and also we return the tuple.\n1 2 3 4 5 6 7 8 9 10  def shout_all(word1, word2): shout1 = word1 + \u0026#34;!!!\u0026#34; shout2 = word2 + \u0026#34;!!!\u0026#34; shout_words = (shout1, shout2) return shout_words yell1, yell2 = shout_all(\u0026#34;congratulations\u0026#34;, \u0026#34;you\u0026#34;) print(yell1) print(yell2)   congratulations!!! you!!! 1 2 3 4 5 6 7 8 9 10 11 12 13 14  def count_entries(df, col_name): \u0026#34;\u0026#34;\u0026#34;Return a dictionary with counts of occurrences as value for each key.\u0026#34;\u0026#34;\u0026#34; langs_count = {} col = df[col_name] for entry in col: if entry in langs_count.keys(): langs_count[entry] += 1 else: langs_count[entry] = 1 return langs_count result = count_entries(tweets_df, \u0026#34;lang\u0026#34;) print(result)   {'en': 97, 'et': 1, 'und': 2} Default arguments, variable-length arguments and scope Scope We\u0026rsquo;ll now talk about the idea of scope in the context of user-defined functions, which tells you which part of a program an object or a name may be accessed.\nGenerally, there are three types of scope:\n global scope. A name that is in the global scope means that it is defined in the main body of a script or a Python program. local scope. A name that is in a local scope means that it is defined within a function. Once the execution of a function is done, any name inside the local scope ceases to exist, which means you cannot access those names anymore outside of the function definition. built-in scope: this consists of names in the pre-defined built-ins module Python provides, such as print and sum.  The rule for referencing global variable inside the function is to search for local scope first, and then global scope if not. Notice that\n if global variable was not defined in the function body, you can refer it directly:  1 2 3 4  v = 3 def func0(): print(v) func0()   3 if global variable was defined in the function body after you call the variable, you need use global key word te declare te variable:  1 2 3 4 5 6 7  v = 3 def func1(): global v print(v) v = 4 print(v) func1()   3 4 otherwise python will report Errors:\n1 2 3 4 5 6  v = 3 def func1(): print(v) v = 4 print(v) func1()   UnboundLocalError: local variable 'v' referenced before assignment if the variable was defined in the function before you call it, python will use local variable:  1 2 3 4 5  v = 3 def func2(): v=4 print(v) func2()   4 In general, we cannot refer to a local scope outside a function, unless we declare a local scope as global using the global keyword. Notice that once you use the global keyword for a variable, any changes made to that variable within the function are reflected in the global variable. For example\n1 2 3 4 5 6 7 8 9 10 11 12 13  n = 5 def func1(): n=3 print(\u0026#34;n1:\u0026#34;, n) def func2(): global n print(\u0026#34;n2:\u0026#34;, n) n = 4 print(\u0026#34;n3:\u0026#34;, n) func1() func2() print(\u0026#34;n4:\u0026#34;, n)   n1: 3 n2: 5 n3: 4 n4: 4 1 2 3 4 5 6 7 8 9  team = \u0026#34;teen titans\u0026#34; def change_team(): \u0026#34;\u0026#34;\u0026#34;Change the value of the global variable team.\u0026#34;\u0026#34;\u0026#34; global team team = \u0026#34;justice league\u0026#34; print(team) change_team() print(team)   teen titans justice league Nested functions There are a number of good reasons to do write nested function. For example, we want a function that takes 3 numbers as parameters and performs the same function on each of them. One way would be to write out the computation 3 times.\n1 2 3 4 5 6  def func(v1, v2, v3): v1 = v1 + 5 v2 = v2 + 5 v3 = v3 + 5 return (v1, v2, v3) func(1,2,3)   (6,7,8) but this definitely does not scale if you need to perform the computation many times. What we can do instead is define an inner function within our function definition, such that\n1 2 3 4 5  def func1(v1,v2,v3): def func2(x): return x + 5 return(func2(v1), func2(v2), func2(v3)) func1(1,2,3)   (6,7,8) This is called a nested function. The syntax for the inner function is exactly the same as that for any other function.\n1 2 3 4 5 6 7 8 9  def three_shouts(word1, word2, word3): \u0026#34;\u0026#34;\u0026#34;Returns a tuple of strings concatenated with \u0026#39;!!!\u0026#39;.\u0026#34;\u0026#34;\u0026#34; def inner(word): \u0026#34;\u0026#34;\u0026#34;Returns a string concatenated with \u0026#39;!!!\u0026#39;.\u0026#34;\u0026#34;\u0026#34; return word + \u0026#39;!!!\u0026#39; return (inner(word1), inner(word2), inner(word3)) print(three_shouts(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;))    ('a!!!', 'b!!!', 'c!!!') 1 2 3 4 5 6 7 8 9 10 11 12  def echo(n): \u0026#34;\u0026#34;\u0026#34;Return the inner_echo function.\u0026#34;\u0026#34;\u0026#34; def inner_echo(word1): \u0026#34;\u0026#34;\u0026#34;Concatenate n copies of word1.\u0026#34;\u0026#34;\u0026#34; echo_word = word1 * n return echo_word return inner_echo twice = echo(2) thrice = echo(3) print(twice(\u0026#39;hello\u0026#39;), thrice(\u0026#39;hello\u0026#39;))   hellohello hellohellohello What if we have a function inner defined within another function outer and we reference a name x in the inner function? The answer is intuitive: Python searches the local scope of the function inner, then if it doesn\u0026rsquo;t find x, it searches the scope of the function outer, which is called an enclosing function because it encloses the function inner. If Python can\u0026rsquo;t find x in the scope of the enclosing function, it only then searches the global scope and then the built-in scope. This is known as the LEGB rule, where L is for local, E for enclosing, G for global and B for built-ins\n1 2 3 4 5 6 7 8 9 10 11  n = 1 # \u0026lt;-- G scope def outter(): n = 2 # \u0026lt;-- E scope def inner(): n = 3 # \u0026lt;-- L scope print(n) # \u0026lt;-- L scope inner() print(n) # \u0026lt;-- E scope outter() print(n) # \u0026lt;-- G scope   3 2 1 1 2 3 4 5 6 7 8 9 10  n = 1 # \u0026lt;-- G scope def outter(): n = 2 # \u0026lt;-- E scope def inner(): print(n) # \u0026lt;-- L scope inner() print(n) # \u0026lt;-- E scope outter() print(n) # \u0026lt;-- G scope   2 2 1 1 2 3 4 5 6 7 8 9  n = 1 # \u0026lt;-- G scope def outter(): def inner(): print(n) # \u0026lt;-- L scope inner() print(n) # \u0026lt;-- E scope outter() print(n) # \u0026lt;-- G scope   1 1 1  Notice that The E scope variable can reference the values of L and G scope variables, but cannot change the values of L and G scope variables, unless declare keyword global or nonlocol.\n Let\u0026rsquo;s now look at another important use case of nested functions. In this example, we define a function func1, which contains an inner function called func2. func1 returns the inner function func2. func1 takes an argument x and creates a function inner that returns the yth power of x.\n1 2 3 4 5 6 7  def func1(x): def func2(y): return x ** y return func2 f = func1(2) print(type(f)) f(3)   \u0026lt;class 'function'\u0026gt; 8 One interesting detail: when we call the function f, it remembers the value x=2, although the enclosing scope defined by func1 and to which x=2 is local, has finished execution. This is a subtlety referred to as a closure in Computer Science.\nRecall that you can use the keyword global in function definitions to create and change global names; similarly, in a nested function, you can use the keyword nonlocal to create and changes names in an enclosing scope. In simple terms, global: L -\u0026gt; G or global: E -\u0026gt; G; and nonlocal: L -\u0026gt; E.\n outer + inner(nonlocal)  1 2 3 4 5 6 7 8 9 10 11 12  n=0 # \u0026lt;-- G scope def func1(): n=1 # \u0026lt;-- E scope def func2(): nonlocal n # \u0026lt;== [L -\u0026gt; E] n=2 # \u0026lt;-- E scope print(\u0026#34;n1:\u0026#34;,n) # \u0026lt;-- E scope print(\u0026#34;n2:\u0026#34;,n) # \u0026lt;-- E scope func2() print(\u0026#34;n3:\u0026#34;,n) # \u0026lt;-- E scope func1() print(\u0026#34;n4:\u0026#34;,n) # \u0026lt;-- G scope   n2: 1 n1: 2 n3: 2 n4: 0 outer(global) + inner  1 2 3 4 5 6 7 8 9 10 11 12  n=0 # \u0026lt;-- G scope def func1(): global n # \u0026lt;== [E -\u0026gt; G] n=1 # \u0026lt;-- G scope def func2(): n=2 # \u0026lt;-- L scope print(\u0026#34;n1:\u0026#34;,n) # \u0026lt;-- L scope print(\u0026#34;n2:\u0026#34;,n) # \u0026lt;-- G scope func2() print(\u0026#34;n3:\u0026#34;,n) # \u0026lt;-- G scope func1() print(\u0026#34;n4:\u0026#34;,n) # \u0026lt;-- G scope   n2: 1 n1: 2 n3: 1 n4: 1 outer + inner(global)  1 2 3 4 5 6 7 8 9 10 11 12 13 14  n=0 def func1(): n=1 # \u0026lt;-- E scope def func2(): global n # \u0026lt;== [L -\u0026gt; G] print(\u0026#34;n0:\u0026#34;,n) # \u0026lt;-- G scope n=2 # \u0026lt;-- G scope print(\u0026#34;n1:\u0026#34;,n) # \u0026lt;-- G scope print(\u0026#34;n2:\u0026#34;,n) # \u0026lt;-- E scope func2() print(\u0026#34;n3:\u0026#34;,n) # \u0026lt;-- E scope func1() print(\u0026#34;n4:\u0026#34;,n) # \u0026lt;-- G scope   n2: 1 n0: 0 n1: 2 n3: 1 # \u0026lt;-- Notice, E scope n4: 2 outer(global) + inner(global)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  n=0 # \u0026lt;-- G scope def func1(): global n # \u0026lt;== [E -\u0026gt; G] n=1 # \u0026lt;-- G scope def func2(): global n # \u0026lt;== [L -\u0026gt; G] print(\u0026#34;n0:\u0026#34;,n) # \u0026lt;-- G scope n=2 # \u0026lt;-- G scope print(\u0026#34;n1:\u0026#34;,n) # \u0026lt;-- G scope print(\u0026#34;n2:\u0026#34;,n) # \u0026lt;-- G scope func2() print(\u0026#34;n3:\u0026#34;,n) # \u0026lt;-- G scope func1() print(\u0026#34;n4:\u0026#34;,n) # \u0026lt;-- G scope   n2: 1 n0: 1 n1: 2 n3: 2 n4: 2 outer(global) + inner(nonlocal)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  n=0 # \u0026lt;-- G scope def func1(): global n # \u0026lt;== [E -\u0026gt; G] n=1 # \u0026lt;-- G scope def func2(): nonlocal n # \u0026lt;== [L -\u0026gt; E] ERROR! print(\u0026#34;n0:\u0026#34;,n) n=2 print(\u0026#34;n1:\u0026#34;,n) print(\u0026#34;n2:\u0026#34;,n) func2() print(\u0026#34;n3:\u0026#34;,n) func1() print(\u0026#34;n4:\u0026#34;,n)   SyntaxError: no binding for nonlocal 'n' found This leads an error, since E scope variable n has been transform to be G scope variable, which means there is no E scope variable n, and nonlocal n cannot match n.\n1 2 3 4 5 6 7 8 9 10 11 12 13  def echo_shout(word): \u0026#34;\u0026#34;\u0026#34;Change the value of a nonlocal variable\u0026#34;\u0026#34;\u0026#34; echo_word = word * 2 print(echo_word) def shout(): \u0026#34;\u0026#34;\u0026#34;Alter a variable in the enclosing scope\u0026#34;\u0026#34;\u0026#34; nonlocal echo_word echo_word = echo_word + \u0026#34;!!!\u0026#34; shout() print(echo_word) echo_shout(\u0026#34;hello\u0026#34;)   hellohello hellohello!!! Default and flexible arguments To define a function with a default argument value, in the function header we follow the parameter of interest with an equals sign and the default argument value.\n1 2 3 4 5 6 7 8 9 10 11 12 13  # Define shout_echo def shout_echo(word1, echo=1): \u0026#34;\u0026#34;\u0026#34;Concatenate echo copies of word1 and three exclamation marks at the end of the string.\u0026#34;\u0026#34;\u0026#34; echo_word = word1 * echo shout_word = echo_word + \u0026#39;!!!\u0026#39; return shout_word no_echo = shout_echo(\u0026#34;Hey\u0026#34;) with_echo = shout_echo(\u0026#34;Hey\u0026#34;, echo=5) print(no_echo) print(with_echo)   Hey!!! HeyHeyHeyHeyHey!!! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def shout_echo(word1, echo=1, intense=False): \u0026#34;\u0026#34;\u0026#34;Concatenate echo copies of word1 and three exclamation marks at the end of the string.\u0026#34;\u0026#34;\u0026#34; echo_word = word1 * echo if intense is True: echo_word_new = echo_word.upper() + \u0026#39;!!!\u0026#39; else: echo_word_new = echo_word + \u0026#39;!!!\u0026#39; return echo_word_new with_big_echo = shout_echo(\u0026#34;Hey\u0026#34;, echo=5, intense=True) big_no_echo = shout_echo(\u0026#34;Hey\u0026#34;, intense=True) print(with_big_echo) print(big_no_echo)   HEYHEYHEYHEYHEY!!! HEY!!! In the function definition, we use the parameter *arg: this then turns all the arguments passed to a function call into a tuple called args in the function body;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  def gibberish(*args): \u0026#34;\u0026#34;\u0026#34;Concatenate strings in *args together.\u0026#34;\u0026#34;\u0026#34; hodgepodge=\u0026#34;\u0026#34; for word in args: hodgepodge += word return hodgepodge one_word = gibberish(\u0026#34;luke\u0026#34;) many_words = gibberish(\u0026#34;luke\u0026#34;, \u0026#34;leia\u0026#34;, \u0026#34;han\u0026#34;, \u0026#34;obi\u0026#34;, \u0026#34;darth\u0026#34;) ls = [\u0026#34;luke\u0026#34;, \u0026#34;leia\u0026#34;, \u0026#34;han\u0026#34;, \u0026#34;obi\u0026#34;, \u0026#34;darth\u0026#34;] many_words2 = gibberish(*ls) print(one_word) print(many_words) print(many_words2)   luke lukeleiahanobidarth lukeleiahanobidarth You can also use the parameter kwargs preceded by a double star. This turns the identifier-keyword pairs into a dictionary within the function body.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def report_status(**kwargs): \u0026#34;\u0026#34;\u0026#34;Print out the status of a movie character.\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;\\nBEGIN: REPORT\\n\u0026#34;) for key, value in kwargs.items(): print(key + \u0026#34;: \u0026#34; + value) print(\u0026#34;\\nEND REPORT\u0026#34;) report_status(name=\u0026#34;luke\u0026#34;, affiliation=\u0026#34;jedi\u0026#34;, status=\u0026#34;missing\u0026#34;) params = { \u0026#34;name\u0026#34;:\u0026#34;anakin\u0026#34;, \u0026#34;affiliation\u0026#34;:\u0026#34;sith lord\u0026#34;, \u0026#34;status\u0026#34;:\u0026#34;deceased\u0026#34; } report_status(**params)   BEGIN: REPORT name: luke affiliation: jedi status: missing END REPORT BEGIN: REPORT name: anakin affiliation: sith lord status: deceased END REPORT  Note that it is NOT the names args and kwargs that are important when using flexible arguments, but rather that they\u0026rsquo;re preceded by a single and double star, respectively.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def count_entries(df, *args): \u0026#34;\u0026#34;\u0026#34;Return a dictionary with counts of occurrences as value for each key.\u0026#34;\u0026#34;\u0026#34; cols_count = {} for col_name in args: col = df[col_name] for entry in col: if entry in cols_count.keys(): cols_count[entry] += 1 else: cols_count[entry] = 1 return cols_count result1 = count_entries(tweets_df, \u0026#34;lang\u0026#34;) result2 = count_entries(tweets_df, \u0026#34;lang\u0026#34;, \u0026#34;source\u0026#34;) print(result1) print(result2)   {'en': 97, 'et': 1, 'und': 2} {'en': 97, 'et': 1, 'und': 2, '\u0026lt;a href=\u0026quot;http://twitter.com\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter Web Client\u0026lt;/a\u0026gt;': 24, '\u0026lt;a href=\u0026quot;http://www.facebook.com/twitter\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Facebook\u0026lt;/a\u0026gt;': 1, '\u0026lt;a href=\u0026quot;http://twitter.com/download/android\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for Android\u0026lt;/a\u0026gt;': 26, '\u0026lt;a href=\u0026quot;http://twitter.com/download/iphone\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for iPhone\u0026lt;/a\u0026gt;': 33, '\u0026lt;a href=\u0026quot;http://www.twitter.com\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for BlackBerry\u0026lt;/a\u0026gt;': 2, '\u0026lt;a href=\u0026quot;http://www.google.com/\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Google\u0026lt;/a\u0026gt;': 2, '\u0026lt;a href=\u0026quot;http://twitter.com/#!/download/ipad\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Twitter for iPad\u0026lt;/a\u0026gt;': 6, '\u0026lt;a href=\u0026quot;http://linkis.com\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Linkis.com\u0026lt;/a\u0026gt;': 2, '\u0026lt;a href=\u0026quot;http://rutracker.org/forum/viewforum.php?f=93\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;newzlasz\u0026lt;/a\u0026gt;': 2, '\u0026lt;a href=\u0026quot;http://ifttt.com\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;IFTTT\u0026lt;/a\u0026gt;': 1, '\u0026lt;a href=\u0026quot;http://www.myplume.com/\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;Plume\\xa0for\\xa0Android\u0026lt;/a\u0026gt;': 1} Lambda functions and error-handling Lambda functions There\u0026rsquo;s a quicker way to write functions on the fly and these are called lambda functions because you use the keyword lambda. To do so, after the keyword lambda, we specify the names of the arguments; then we use a colon followed by the expression that specifies what we wish the function to return, such as\n1  lambda x,y: x + y   1 2  f = lambda x: x ** 2 f(3)   9 1 2 3 4  echo_word = (lambda word1, echo: word1 * echo) result = echo_word(\u0026#34;hey\u0026#34;, 5) print(result)   heyheyheyheyhey Here we introduce three useful function: map(), filter() and reduce().\nFirstly, check out the map function, which takes two arguments, a function and a sequence such as a list and applies the function over all elements of the sequence. We can pass lambda functions to map without even naming them and in this case we refer to them as anonymous functions.\n1 2 3 4 5 6  ls = [1,2,3,4,5] ls1 = map( lambda x: x ** 2, ls ) print(ls1, list(ls1))   \u0026lt;map object at 0x7fc5a95e76d0\u0026gt; [1, 4, 9, 16, 25] 1 2 3 4 5 6 7 8 9  spells = [\u0026#34;protego\u0026#34;, \u0026#34;accio\u0026#34;, \u0026#34;expecto patronum\u0026#34;, \u0026#34;legilimens\u0026#34;] shout_spells = map( lambda item: item + \u0026#34;!!!\u0026#34;, spells ) shout_spells_list = list(shout_spells) print(shout_spells_list)   ['protego!!!', 'accio!!!', 'expecto patronum!!!', 'legilimens!!!'] The function filter() offers a way to filter out elements from a list that don\u0026rsquo;t satisfy certain criteria. We now use filter() to create, from an input list of strings, a new list that contains only strings that have more than 6 characters.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  fellowship = [\u0026#39;frodo\u0026#39;, \u0026#39;samwise\u0026#39;, \u0026#39;merry\u0026#39;, \u0026#39;pippin\u0026#39;, \u0026#39;aragorn\u0026#39;, \u0026#39;boromir\u0026#39;, \u0026#39;legolas\u0026#39;, \u0026#39;gimli\u0026#39;, \u0026#39;gandalf\u0026#39;] result_f = filter( lambda x: len(x) \u0026gt; 6, fellowship ) result_m = map( lambda x: len(x) \u0026gt; 6, fellowship ) result_f_list = list(result_f) result_m_list = list(result_m) print(result_f_list) print(result_m_list)   ['samwise', 'aragorn', 'boromir', 'legolas', 'gandalf'] [False, True, False, False, True, True, True, False, True] The reduce() function is useful for performing some computation on a list and, unlike map() and filter(), returns a single value as a result. The operation rule of reduce() is to use the input function (with 2 arguments) to operate on the first and second elements in the iterator (e.g. list), and then use the function to operate the result with the third data, and finally get a result. To use reduce(), you must import it from the functools module.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from functools import reduce stark = [\u0026#39;robb\u0026#39;, \u0026#39;sansa\u0026#39;, \u0026#39;arya\u0026#39;, \u0026#39;brandon\u0026#39;, \u0026#39;rickon\u0026#39;] nums = [1,1,1,1,1,1] result_s = reduce( lambda x, y: x + y, stark ) result_n = reduce( lambda x, y: x + y, nums ) print(result_s) print(result_n)   robbsansaaryabrandonrickon 6 Error handling A error caught during execution, commonly called exceptions. The main way to catch exceptions is the try-except clause, in which Python tries to run the code following try and if it can, all is well. If it cannot due to an exception, it runs the code following except.\nWe may also wish to only catch specific type of error and let other errors pass through, in which case we would use except \u0026lt;error type\u0026gt;.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  def count_entries(df, col_name=\u0026#39;lang\u0026#39;): \u0026#34;\u0026#34;\u0026#34;Return a dictionary with counts of occurrences as value for each key.\u0026#34;\u0026#34;\u0026#34; cols_count = {} try: col = df[col_name] for entry in col: if entry in cols_count.keys(): cols_count[entry] += 1 else: cols_count[entry] = 1 return cols_count except: print(\u0026#39;The DataFrame does not have a \u0026#39; + col_name + \u0026#39; column.\u0026#39;) result1 = count_entries(tweets_df, \u0026#39;lang\u0026#39;) print(result1)   {'en': 97, 'et': 1, 'und': 2} More often than not, instead of merely printing an error message, we\u0026rsquo;ll want to actually raise an error by clause raise \u0026lt;error type\u0026gt;(\u0026quot;xxx\u0026quot;). For example\n1 2 3  a = 4 if a \u0026lt; 5: raise TypeError(\u0026#34;ddd\u0026#34;)   TypeError: ddd The other method to catch error for the last example is that\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def count_entries(df, col_name=\u0026#39;lang\u0026#39;): \u0026#34;\u0026#34;\u0026#34;Return a dictionary with counts of occurrences as value for each key.\u0026#34;\u0026#34;\u0026#34; if col_name not in df.columns: raise ValueError(\u0026#39;The DataFrame does not have a \u0026#39; + col_name + \u0026#39; column.\u0026#39;) cols_count = {} col = df[col_name] for entry in col: if entry in cols_count.keys(): cols_count[entry] += 1 else: cols_count[entry] = 1 return cols_count result1 = count_entries(tweets_df, \u0026#34;lang\u0026#34;) print(result1)    {'en': 97, 'et': 1, 'und': 2} ","date":"2019-08-13T00:00:00Z","permalink":"https://wanghaoming177.netlify.app/p/object-oriented-programming-i-function/","title":"Object Oriented Programming I (Function)"}]